{"info": {"author": "BGS Informatics", "author_email": "jostev@bgs.ac.uk", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "Intended Audience :: Information Technology", "Intended Audience :: Science/Research", "License :: OSI Approved :: GNU Lesser General Public License v3 or later (LGPLv3+)", "Natural Language :: English", "Operating System :: OS Independent", "Programming Language :: Python :: 3", "Topic :: Database", "Topic :: Scientific/Engineering :: GIS"], "description": "# etlhelper\n\n> etlhelper is a Python library to simplify data transfer between databases.\n\n`etlhelper` provides a unified way to connect to different database types (currently Oracle, PostgreSQL, SQLite and MS SQL Server).\nIt is a thin wrapper around Python's [DBAPI2](https://www.python.org/dev/peps/pep-0249/) specification.\nThe `get_rows` function returns the result of a SQL query and can be used to create simple HTTP APIs.\nThe `copy_rows` function transfers data from one database to another.\nIt is possible to apply a transform function to manipulate data in flight.\nThese tools make it simple to create easy-to-understand, lightweight, versionable and testable Extract-Transform-Load (ETL) workflows.\n\n`etlhelper` is not a tool for coordinating ETL jobs (use [Apache Airflow](https://airflow.apache.org)), for\nconverting GIS data formats (use [ogr2ogr](https://gdal.org/programs/ogr2ogr.html) or [fiona](https://pypi.org/project/Fiona/)) or an Object Relation Mapper (use [SQLAlchemy](https://www.sqlalchemy.org/)).\nHowever, it can be used in conjunction with each of these.\n\nFor an introduction to `etlhelper`, see the FOSS4GUK 2019 presentation _Open Source Spatial ETL with Python and Apache Airflow_: [video](https://www.youtube.com/watch?v=12rzUW4ps74&feature=youtu.be&t=6238) (20 mins),\n[slides](https://volcan01010.github.io/FOSS4G2019-talk).\n\n + [Installation](#installation)\n + [Quick Start](#quick-start)\n + [Recipes](#recipes)\n + [Development](#development)\n + [Reference](#reference)\n\n## Installation\n\n```bash\npip install etlhelper[oracle]\n```\n\nRequired database drivers are specified in the square brackets.  Options are:\n\n```\n[oracle]\n[mssql]\n[postgres]\n```\n\nMultiple values can be separated by commas, e.g.: `[oracle,mssql]` would install both sets of drivers.\nThe `sqlite3` driver is included within Python's Standard Library.\n\n\n### Dependencies\n\nLinux systems require additional packages to be installed on the system.\n\nDebian / Ubuntu:\n\n  + `sudo apt install libaio1` for cxOracle.\n  + `sudo apt install build-essential unixodbc-dev` for pyodbc.\n\nCentos / Fedora:\n\n  + `sudo yum install libaio` for Oracle\n  + `sudo yum install gcc gcc-c++ make python36-devel pyodbc unixODBC-devel` for pyodbc\n\n\n#### Oracle Instant Client\n\nOracle Instant Client libraries are required to connect to Oracle databases.\n`etlhelper` provides a script to install these on Linux systems from a zip file downloaded from the [Oracle website](https://www.oracle.com/technetwork/database/database-technologies/instant-client/downloads/index.html) and made available locally.\n\n\n```bash\nsetup_oracle_client /path/or/url/for/instantclient-basic-linux.x64-12.2.0.1.0.zip\nexport \"$(oracle_lib_path_export)\"\n```\n\nIf you are outside a virtual environment, the export command may be different.\nSee terminal output for details.\nRun `setup_oracle_client` again to confirm setup has worked.\n\n\n#### pyodbc for Microsoft SQL Server\n\nThe `setup_mssql_driver` tool checks that appropriate drivers are installed.\n\n```bash\nsetup_mssql_driver\n```\n\nIt provides links to installation instructions for drivers.\nThe [Dockerfile](Dockerfile) contains an example for Debian systems.\n\n\n## Quick Start\n\n#### Password Definition\n\nPasswords (e.g. Oracle password) must be specified via an environment variable.\nThis can be done on the command line via:\n\n+ `export ORACLE_PASSWORD=some-secret-password` on Linux\n+ `set ORACLE_PASSWORD=some-secret-password` on Windows\n\nOr in a Python terminal via:\n\n```python\nimport os\nos.environ['ORACLE_PASSWORD'] = 'some-secret-password'\n```\n\nNo password is required for SQLite databases.\n\n\n#### DbParams\n\nDatabase connection information is defined by `DbParams` objects.\n\n```\nfrom etlhelper import DbParams\n\nORACLEDB = DbParams(dbtype='ORACLE', host=\"localhost\", port=1521,\n                    dbname=\"mydata\", user=\"oracle_user\")\n\nPOSTGRESDB = DbParams(dbtype='PG', host=\"localhost\", port=5432,\n                      dbname=\"mydata\", user=\"postgres_user\")\n\nSQLITEDB = DbParams(dbtype='SQLITE', filename='/path/to/file.db')\n\nMSSQLDB = DbParams(dbtype='MSSQL', host=\"localhost\", port=5432,\n                   dbname=\"mydata\", user=\"mssql_user\",\n                   odbc_driver=\"ODBC Driver 17 for SQL Server\")\n```\n\nDbParams objects can also be created from environment variables using the\n`from_environment()` function.\n\n\n#### Get rows\n\nConnections are created by `connect` function.\nThe `get_rows` function returns a list of named tuples containing data as\nnative Python objects.\n\n```python\nfrom my_databases import ORACLEDB\nfrom etlhelper import connect, get_rows\n\nsql = \"SELECT * FROM src\"\n\nwith connect(ORACLEDB, \"ORA_PASSWORD\") as conn:\n    result = get_rows(sql, conn)\n```\n\nreturns\n\n```\n[Row(id=1, value=1.234, simple_text='text', utf8_text='\u00d6\u00e6\u00b0\\nz',\n     day=datetime.date(2018, 12, 7),\n     date_time=datetime.datetime(2018, 12, 7, 13, 1, 59)),\n Row(id=2, value=2.234, simple_text='text', utf8_text='\u00d6\u00e6\u00b0\\nz',\n     day=datetime.date(2018, 12, 8),\n     date_time=datetime.datetime(2018, 12, 8, 13, 1, 59)),\n Row(id=3, value=2.234, simple_text='text', utf8_text='\u00d6\u00e6\u00b0\\nz',\n     day=datetime.date(2018, 12, 9),\n     date_time=datetime.datetime(2018, 12, 9, 13, 1, 59))]\n```\n\nData are accessible via index (`row[4]`) or name (`row.day`).\n\n`dump_rows` passes each row to a function, while `iter_rows` returns\na generator for looping over results.\n\n#### Copy rows\n\nCopy rows takes the results from a SELECT query and applies them as parameters\nto an INSERT query.\nThe source and destination tables must already exist.\n\n```python\nfrom my_databases import POSTGRESDB, ORACLEDB\nfrom etlhelper import connect, copy_rows\n\nselect_sql = \"SELECT id, name FROM src\"\ninsert_sql = \"INSERT INTO dest (id, name)\n              VALUES (%s, %s)\"\n\nsrc_conn = connect(ORACLEDB, \"ORA_PASSWORD\")\ndest_conn = connect(POSTGRESDB, \"PG_PASSWORD\")\n\ncopy_rows(select_sql, src_conn, insert_sql, dest_conn)\n```\n\n#### Transform\n\nData can be transformed in-flight by applying a transform function.  This is\nany Python callable (function) that takes an iterator (e.g. list) and returns\nanother iterator.\n\n```python\nimport random\n\ndef my_transform(chunk):\n    # Append random integer (1-10), filter if <5.\n\n    new_chunk = []\n    for row in chunk:\n        external_value = random.randrange(10)\n        if external_value >= 6:\n            new_chunk.append((*row, external_value))\n\n    return new_chunk\n\ncopy_rows(select_sql, src_conn, insert_sql, dest_conn\n          transform=my_transform)\n```\n\nThe above code demonstrates that the returned chunk can have a different number\nof rows of different length.\nThe external data can result from a call to a webservice or other database.\n\nThe `iter_chunks` and `iter_rows` functions return generators.\nEach chunk or row of data is only accessed when it is required.\nUsing `yield` instead of `return` in the transform function makes it\na generator, too.\nData transformation can then be performed via [memory-efficient iterator-chains](https://dbader.org/blog/python-iterator-chains).\n\n\n#### Spatial ETL\n\nNo specific drivers are required for spatial data if they are transferred as\nWell Known Text.\n\n```python\nselect_sql_oracle = \"\"\"\n    SELECT\n      id,\n      SDO_UTIL.TO_WKTGEOMETRY(geom)\n    FROM src\n    \"\"\"\n\ninsert_sql_postgis = \"\"\"\n    INSERT INTO dest (id, geom) VALUES (\n      %s,\n      ST_Transform(ST_GeomFromWKT(%s), 27700)\n    )\n    \"\"\"\n```\n\nOther spatial operations e.g. coordinate transforms, intersections and\nbuffering can be carried out in the SQL.\nTransform functions can manipulate geometries using the [Shapely](https://pypi.org/project/Shapely/) library.\n\n\n#### ETL script example\n\nThe following is an example ETL script.\n\n```python\nfrom my_databases import ORACLEDB, POSTGRESDB\nfrom etl_helper import connect, copy_rows\n\nDELETE_SQL = \"...\"\nSELECT_SQL = \"...\"\nINSERT_SQL = \"...\"\n\ndef copy_src_to_dest():\n    with connect(ORACLEDB, \"ORA_PASSWORD\") as src_conn:\n        with connect(POSTGRESDB, \"PG_PASSWORD\") as dest_conn:\n            execute(DELETE_SQL, dest_conn)\n            copy_rows(SELECT_SQL, src_conn,\n                      INSERT_SQL, dest_conn)\n\nif __name__ == \"__main__\":\n    copy_src_to_dest()\n```\n\nThe DELETE_SQL command clears existing data prior to insertion.  This makes the\nscript idempotent.\n\n\n## Recipes\n\n`etlhelper` has other useful functions.\n\n\n#### Logging progress\n\nETLHelper does not emit log messages by default.\nTime-stamped messages indicating the number of rows processed can be enabled by\nsetting the log level to INFO.\nSetting the level to DEBUG provides information on the query that was run,\nexample data and the database connection.\n\n```python\nimport logging\nfrom etlhelper import logger\n\nlogger.setLevel(logging.INFO)\n```\n\nOutput from a call to `copy_rows` will look like:\n\n```\n2019-10-07 15:06:22,411 iter_chunks: Fetching rows\n2019-10-07 15:06:22,413 executemany: 1 rows processed\n2019-10-07 15:06:22,416 executemany: 2 rows processed\n2019-10-07 15:06:22,419 executemany: 3 rows processed\n2019-10-07 15:06:22,420 iter_chunks: 3 rows returned\n2019-10-07 15:06:22,420 executemany: 3 rows processed in total\n```\n\n\n#### Getting a SQLAlchemy engine\n\nSQLAlchemy allows you to read/write data from [Pandas](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql.html).\nIt can be installed separately with `pip install sqlalchemy`.\nFor example, to export a CSV file of data:\n\n```python\nfrom my_databases import ORACLEDB\nfrom etlhelper import get_sqlalchemy_connection_string\nfrom sqlalchemy import create_engine\n\nsqla_conn_str = get_sqlalchemy_connection_string(ORACLEDB, \"ORACLE_PASSWORD\")\nengine = create_engine(sqla_conn_str)\n\nsql = \"SELECT * FROM my_table\"\ndf = pd.read_sql(sql, engine)\ndf.to_csv('my_data.csv', header=True, index=False, float_format='%.3f')\n```\n\n\n#### Row factories\n\nA row factory can be specified to change the output style.\nFor example, to return each row as a dictionary, use the following:\n\n```python\nfrom etlhelper import connect, iter_rows\nfrom etlhelper.row_factories import dict_rowfactory\n\nconn = connect(ORACLEDB, 'ORACLE_PASSWORD')\nsql = \"SELECT * FROM my_table\"\nfor row in iter_rows(sql, conn, row_factory=dict_rowfactory):\n    print(row['id'])\n```\n\nThe `dict_rowfactory` is useful when getting data to be serialised\ninto JSON.\nWhen combined with [Hug](http://pypi.org/project/hug), an HTTP API can be\ncreated in fewer than 20 lines of code.\n\n\n#### Insert rows\n\nThe `executemany` function can be used to insert data to the database.\nLarge datasets are broken into chunks and inserted in batches to reduce the\nnumber of queries to the database that are required.\n\n```python\nfrom etlhelper import connect, executemany\n \nrows = [(1, 'value'), (2, 'another value')]\ninsert_sql = \"INSERT INTO some_table (col1, col2) VALUES (%s, %s)\"\n\nwith connect(some_db, 'SOME_DB_PASSWORD') as conn:\n    executemany(insert_sql, rows, conn)\n```\n\n## Development\n\n### Maintainers\n\nETL Helper was created by and is maintained by British Geological Survey Informatics.\n\n+ John A Stevenson ([volcan01010](https://github.com/volcan01010))\n+ Jo Walsh ([metazool](https://github.com/metazool))\n+ Declan Valters ([dvalters](https://github.com/dvalters))\n+ Colin Blackburn ([ximenesuk](https://github.com/ximenesuk))\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) for details on how to contribute to the\nsoftware.\n\n\n### Licence\n\nETL Helper is distributed under the [LGPL v3.0 licence](LICENSE).\nCopyright: \u00a9 BGS / UKRI 2019\n\n\n## References\n\n+ [PEP249 DB API2](https://www.python.org/dev/peps/pep-0249/#cursor-objects)\n+ [psycopg2](http://initd.org/psycopg/docs/cursor.html)\n+ [cx_Oracle](https://cx-oracle.readthedocs.io/en/latest/cursor.html)\n+ [pyodbc](https://pypi.org/project/pyodbc/)", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/BritishGeologicalSurvey/etlhelper", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "etlhelper", "package_url": "https://pypi.org/project/etlhelper/", "platform": "", "project_url": "https://pypi.org/project/etlhelper/", "project_urls": {"Homepage": "https://github.com/BritishGeologicalSurvey/etlhelper"}, "release_url": "https://pypi.org/project/etlhelper/0.7.6/", "requires_dist": null, "requires_python": ">=3.6", "summary": "A Python library to simplify data transfer between databases.", "version": "0.7.6"}, "last_serial": 6278617, "releases": {"0.5.4": [{"comment_text": "", "digests": {"md5": "b76bb0e28f1f74dd630f4f659920be05", "sha256": "70e23972aa3843ca2514e82384679122346e1b7408b3e174b3474b8a9a52725f"}, "downloads": -1, "filename": "etlhelper-0.5.4.zip", "has_sig": false, "md5_digest": "b76bb0e28f1f74dd630f4f659920be05", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 47428, "upload_time": "2019-09-18T23:50:37", "upload_time_iso_8601": "2019-09-18T23:50:37.194622Z", "url": "https://files.pythonhosted.org/packages/da/96/f7e0cbbe5d47e9b27635cb337cbea9075b372d149ae8fc8a59cabdab793a/etlhelper-0.5.4.zip"}], "0.5.5": [{"comment_text": "", "digests": {"md5": "ec149f2f2bc12dad6fafbd184b3639e1", "sha256": "1bac147e193245e757266859ce21f52d17d90dad68760ae6beb8452e9741d1b4"}, "downloads": -1, "filename": "etlhelper-0.5.5.zip", "has_sig": false, "md5_digest": "ec149f2f2bc12dad6fafbd184b3639e1", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 49333, "upload_time": "2019-09-27T15:04:09", "upload_time_iso_8601": "2019-09-27T15:04:09.318180Z", "url": "https://files.pythonhosted.org/packages/e6/84/897e53a054e68fe3ceccdabb169e248616d9dfb35ed6e923d66620a31acf/etlhelper-0.5.5.zip"}], "0.6.0": [{"comment_text": "", "digests": {"md5": "60c3d24553b0f35753052d7827a9ed7b", "sha256": "6a9febecf896a16b90b07e0760ad8c9e5c3d3b2d5d9b226c6dafe2fd70da74e9"}, "downloads": -1, "filename": "etlhelper-0.6.0.zip", "has_sig": false, "md5_digest": "60c3d24553b0f35753052d7827a9ed7b", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 50855, "upload_time": "2019-10-22T10:35:34", "upload_time_iso_8601": "2019-10-22T10:35:34.238784Z", "url": "https://files.pythonhosted.org/packages/7d/63/176ea458ad1c88aff6fb28ddb69c8776bf4611b3af09038c94676656cca0/etlhelper-0.6.0.zip"}], "0.7.0": [{"comment_text": "", "digests": {"md5": "35bf37a8e868e6ca4d5a1ead9d0a495e", "sha256": "6e0d2002ce4560bb96ce36a862e6297173ec942833a5116ac1d8792069f0992f"}, "downloads": -1, "filename": "etlhelper-0.7.0.zip", "has_sig": false, "md5_digest": "35bf37a8e868e6ca4d5a1ead9d0a495e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 51690, "upload_time": "2019-11-04T18:25:17", "upload_time_iso_8601": "2019-11-04T18:25:17.866961Z", "url": "https://files.pythonhosted.org/packages/fb/9f/e04ed5a3f391390a2c4ad678bfdf8d275b4f5b3f884d31fa86a61515d43b/etlhelper-0.7.0.zip"}], "0.7.4": [{"comment_text": "", "digests": {"md5": "7b1be2d86291c15ae74646c9b39bb226", "sha256": "58a10e4e8f92a9e33f331dfdf59d0aef2bc83b0ed958d8db64a5f8b2e3e8eedf"}, "downloads": -1, "filename": "etlhelper-0.7.4.zip", "has_sig": false, "md5_digest": "7b1be2d86291c15ae74646c9b39bb226", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 51776, "upload_time": "2019-12-11T10:22:20", "upload_time_iso_8601": "2019-12-11T10:22:20.958034Z", "url": "https://files.pythonhosted.org/packages/ea/50/cf12904ed2b496694831eb5f80bac3950854d91e38b54d0e1e52c1a514b9/etlhelper-0.7.4.zip"}], "0.7.5": [{"comment_text": "", "digests": {"md5": "50d6fcb25b89eea69c4406a0bf007874", "sha256": "5aae5fe488bb0fb9ac08f51f8c9a07e168ec556a17b9e2882395986076a9f6be"}, "downloads": -1, "filename": "etlhelper-0.7.5.zip", "has_sig": false, "md5_digest": "50d6fcb25b89eea69c4406a0bf007874", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 52308, "upload_time": "2019-12-11T10:51:35", "upload_time_iso_8601": "2019-12-11T10:51:35.885049Z", "url": "https://files.pythonhosted.org/packages/2c/a7/6cb6978b75a9536b688a989dfd343858e8dfed7e3d2100abafd10dbf5460/etlhelper-0.7.5.zip"}], "0.7.6": [{"comment_text": "", "digests": {"md5": "ab0276e5653d638f8ae182808c01e49d", "sha256": "9030cad2994f3eb31d0f4eb3b96b73550fc419137c7ed11575d7296fa872ca02"}, "downloads": -1, "filename": "etlhelper-0.7.6.zip", "has_sig": false, "md5_digest": "ab0276e5653d638f8ae182808c01e49d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 52308, "upload_time": "2019-12-11T11:52:03", "upload_time_iso_8601": "2019-12-11T11:52:03.427314Z", "url": "https://files.pythonhosted.org/packages/55/22/4b9f7a6cde71fc585cc24c547bc49253ea2ade1210f8a30472bb7a9e30f9/etlhelper-0.7.6.zip"}]}, "urls": [{"comment_text": "", "digests": {"md5": "ab0276e5653d638f8ae182808c01e49d", "sha256": "9030cad2994f3eb31d0f4eb3b96b73550fc419137c7ed11575d7296fa872ca02"}, "downloads": -1, "filename": "etlhelper-0.7.6.zip", "has_sig": false, "md5_digest": "ab0276e5653d638f8ae182808c01e49d", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6", "size": 52308, "upload_time": "2019-12-11T11:52:03", "upload_time_iso_8601": "2019-12-11T11:52:03.427314Z", "url": "https://files.pythonhosted.org/packages/55/22/4b9f7a6cde71fc585cc24c547bc49253ea2ade1210f8a30472bb7a9e30f9/etlhelper-0.7.6.zip"}]}