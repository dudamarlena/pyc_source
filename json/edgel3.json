{"info": {"author": "Sangeeta Kumari", "author_email": "kumari.14@osu.edu", "bugtrack_url": null, "classifiers": ["Development Status :: 2 - Pre-Alpha", "Intended Audience :: Developers", "Intended Audience :: Science/Research", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 2", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Topic :: Multimedia :: Sound/Audio :: Analysis"], "description": "# edgel3\n\n\n[![PyPI](https://img.shields.io/badge/python-2.7%2C%203.5%2C%203.6-blue.svg)](https://pypi.python.org/pypi/edgel3)\n[![MIT license](https://img.shields.io/badge/License-MIT-blue.svg)](https://choosealicense.com/licenses/mit/)\n[![Build Status](https://travis-ci.com/ksangeeta2429/edgel3.svg?branch=master)](https://travis-ci.com/ksangeeta2429/edgel3)\n[![Coverage Status](https://coveralls.io/repos/github/ksangeeta2429/edgel3/badge.svg?branch=master)](https://coveralls.io/github/ksangeeta2429/edgel3?branch=master)\n[![Documentation Status](https://readthedocs.org/projects/edgel3/badge/?version=latest)](https://edgel3.readthedocs.io/en/latest/?badge=latest)\n\nLook, Listen, and Learn (L3) [3],  a  recently  proposed  state-of-the-art  transfer learning technique, helps to train self-supervised deep audio embedding through binary Audio-Visual Correspondence. This embedding can be used to train a variety of downstream audio classification tasks which has limited data. However, with close to 4.7 million parameters, L3-Net is 18 MB in size making it infeasible for small edge devices, such as 'motes' that use a single microcontroller and limited memory to achieve long-lived self-powered operation. \n\nIn [EdgeL3](https://github.com/ksangeeta2429/Publications/raw/master/EdgeL3_Compressing_L3_Net_for_Mote_Scale.pdf) [1], we comprehensively explore the feasibility of compressing the L3-Net for mote-scale inference. We used pruning, ablation, and knowledge distillation techniques to show that the originally proposed L3-Net architecture is substantially overparameterized, not  only for AVC but for the target task of sound classification as evaluated on two popular downstream datasets, US8K and ESC50. EdgeL3, a 95.45% sparsified version of L3-Net, provides a useful reference model for approximating L3 audio embedding for transfer learning.\n\n``edgel3`` is an open-source Python library for downloading the sparsified L3 models and computing deep audio embeddings from such models. The sparse audio embedding models provided have been re-trained using two different mechanisms as described in the [paper](https://github.com/ksangeeta2429/Publications/raw/master/EdgeL3_Compressing_L3_Net_for_Mote_Scale.pdf). The code for the model and training implementation can be found [here](https://github.com/ksangeeta2429/l3embedding/tree/dcompression)\n\nDownload the original L3 model used by EdgeL3 as baseline [here](https://github.com/ksangeeta2429/l3embedding/raw/dcompression/models/cnn_l3_melspec2_recent/model_best_valid_accuracy.h5). For non-sparse models and embedding, please refer to [OpenL3](https://github.com/marl/openl3) [2]\n\n# Installing EdgeL3\n\nDependencies\n------------\n#### Tensorflow\nInstall Tensorflow (CPU-only/GPU) variant that best fits your usecase.\n\nOn most platforms, either of the following commands should properly install Tensorflow:\n\n    pip install tensorflow # CPU-only version\n    pip install tensorflow-gpu # GPU version\n\nFor more detailed information, please consult the\n[Tensorflow installation documentation](https://www.tensorflow.org/install/).\n\n#### libsndfile\nEdgeL3 depends on the `pysoundfile` module to load audio files, which depends on the non-Python library ``libsndfile``. On Windows and macOS, these will be installed via ``pip`` and you can therefore skip this step.\nHowever, on Linux this must be installed manually via your platform's package manager.\nFor Debian-based distributions (such as Ubuntu), this can be done by simply running\n\n    apt-get install libsndfile1\n\nFor more detailed information, please consult the\n[`pysoundfile` installation documentation](https://pysoundfile.readthedocs.io/en/0.9.0/#installation>).\n\n\nInstalling EdgeL3\n-----------------\nThe simplest way to install EdgeL3 is by using ``pip``, which will also install the additional required dependencies\nif needed. To install EdgeL3 using ``pip``, simply run\n\n    pip install edgel3\n\nTo install the latest version of EdgeL3 from source:\n\n1. Clone or pull the lastest version:\n\n        git clone https://github.com/ksangeeta2429/edgel3.git\n\n2. Install using pip to handle python dependencies:\n        cd edgel3\n        pip install -e .\n\n# Using EdgeL3\n\nTo help you get started with EdgeL3 please see the [tutorial](https://edgel3.readthedocs.io/en/latest/tutorial.html) and [module usage](https://edgel3.readthedocs.io/en/latest/edgel3.html).\n\n\n# References\n\nPlease cite the following papers when using EdgeL3 in your work:\n\n[1] **[EdgeL3: Compressing L3-Net for Mote-Scale Urban Noise Monitoring](https://github.com/ksangeeta2429/Publications/raw/master/EdgeL3_Compressing_L3_Net_for_Mote_Scale.pdf)** <br/>\nSangeeta Kumari, Dhrubojyoti Roy, Mark Cartwright, Juan Pablo Bello, and Anish Arora. </br>\nParallel AI and Systems for the Edge (PAISE), Rio de Janeiro, Brazil, May 2019.\n\n[2] **Look, Listen and Learn More: Design Choices for Deep Audio Embeddings** <br/>\nJason Cramer, Ho-Hsiang Wu, Justin Salamon, and Juan Pablo Bello.<br/>\nIEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP), pages 3852\u20133856, Brighton, UK, May 2019.\n\n[3] **Look, Listen and Learn**<br/>\nRelja Arandjelovi\u0107 and Andrew Zisserman<br/>\nIEEE International Conference on Computer Vision (ICCV), Venice, Italy, Oct. 2017.", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/ksangeeta2429/edgel3", "keywords": "deep audio embeddings machine listening learning tensorflow keras pruning compression", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "edgel3", "package_url": "https://pypi.org/project/edgel3/", "platform": "", "project_url": "https://pypi.org/project/edgel3/", "project_urls": {"Documentation": "https://readthedocs.org/projects/edgel3/", "Homepage": "https://github.com/ksangeeta2429/edgel3", "Source": "https://github.com/ksangeeta2429/edgel3", "Tracker": "https://github.com/ksangeeta2429/edgel3/issues"}, "release_url": "https://pypi.org/project/edgel3/0.1.0/", "requires_dist": null, "requires_python": "", "summary": "Audio embeddings based on pruned Look, Listen, and Learn (L3) models for the Edge", "version": "0.1.0"}, "last_serial": 5278396, "releases": {"0.1.0": [{"comment_text": "", "digests": {"md5": "cd4177c0d7498e95e4090c06263e2c26", "sha256": "d78209d5372ca64b20ba15d200df829cf75d6c1b910463c2bc9726e8dd56f804"}, "downloads": -1, "filename": "edgel3-0.1.0.tar.gz", "has_sig": false, "md5_digest": "cd4177c0d7498e95e4090c06263e2c26", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17932, "upload_time": "2019-05-16T16:43:32", "upload_time_iso_8601": "2019-05-16T16:43:32.399274Z", "url": "https://files.pythonhosted.org/packages/a9/5a/d85ac4b72754a79b4e294d676cd2acc631320dcf419a178391135a3004cd/edgel3-0.1.0.tar.gz"}]}, "urls": [{"comment_text": "", "digests": {"md5": "cd4177c0d7498e95e4090c06263e2c26", "sha256": "d78209d5372ca64b20ba15d200df829cf75d6c1b910463c2bc9726e8dd56f804"}, "downloads": -1, "filename": "edgel3-0.1.0.tar.gz", "has_sig": false, "md5_digest": "cd4177c0d7498e95e4090c06263e2c26", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 17932, "upload_time": "2019-05-16T16:43:32", "upload_time_iso_8601": "2019-05-16T16:43:32.399274Z", "url": "https://files.pythonhosted.org/packages/a9/5a/d85ac4b72754a79b4e294d676cd2acc631320dcf419a178391135a3004cd/edgel3-0.1.0.tar.gz"}]}