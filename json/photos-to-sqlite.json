{"info": {"author": "Simon Willison", "author_email": "", "bugtrack_url": null, "classifiers": [], "description": "# photos-to-sqlite\n\n[![PyPI](https://img.shields.io/pypi/v/photos-to-sqlite.svg)](https://pypi.org/project/photos-to-sqlite/)\n[![CircleCI](https://circleci.com/gh/dogsheep/photos-to-sqlite.svg?style=svg)](https://circleci.com/gh/dogsheep/photos-to-sqlite)\n[![License](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](https://github.com/dogsheep/photos-to-sqlite/blob/master/LICENSE)\n\nSave details of your photos to a SQLite database and upload them to S3\n\n## Installation\n\n    $ pip install photos-to-sqlite\n\n## Authentication\n\nCreate S3 credentials. This is a huge pain.\n\nRun this command and paste in your credentials:\n\n    $ photos-to-sqlite s3-auth\n\nThis will create a file called `auth.json` in your current directory containing the required values. To save the file at a different path or filename, use the `--auth=myauth.json` option.\n\n## Uploading photos\n\nRun this command to upload every photo in a specific directory to your S3 bucket:\n\n    $ photos-to-sqlite upload photos.db ~/Desktop\n\nThe command will only upload photos that have not yet been uploaded, based on their sha256 hash.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/dogsheep/photos-to-sqlite", "keywords": "", "license": "Apache License, Version 2.0", "maintainer": "", "maintainer_email": "", "name": "photos-to-sqlite", "package_url": "https://pypi.org/project/photos-to-sqlite/", "platform": "", "project_url": "https://pypi.org/project/photos-to-sqlite/", "project_urls": {"Homepage": "https://github.com/dogsheep/photos-to-sqlite"}, "release_url": "https://pypi.org/project/photos-to-sqlite/0.1a0/", "requires_dist": ["sqlite-utils (>=2.7)", "boto3 (>=1.12.41)", "pytest ; extra == 'test'"], "requires_python": "", "summary": "Save details of your photos to a SQLite database and upload them to S3", "version": "0.1a0"}, "last_serial": 7050785, "releases": {"0.1a0": [{"comment_text": "", "digests": {"md5": "bb5e72d2724f54953f8a21f1cd621e44", "sha256": "32d79f9f886ba570b6ec5cea4f19bdc6e86192d5a7348bd2c0e54f367c7e9516"}, "downloads": -1, "filename": "photos_to_sqlite-0.1a0-py3-none-any.whl", "has_sig": false, "md5_digest": "bb5e72d2724f54953f8a21f1cd621e44", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 8145, "upload_time": "2020-04-19T00:17:47", "upload_time_iso_8601": "2020-04-19T00:17:47.555902Z", "url": "https://files.pythonhosted.org/packages/78/a3/615599c7fa926b9b6efa79dfe30dfdf5c9c273fc5f61646268d54a46d961/photos_to_sqlite-0.1a0-py3-none-any.whl"}]}, "urls": [{"comment_text": "", "digests": {"md5": "bb5e72d2724f54953f8a21f1cd621e44", "sha256": "32d79f9f886ba570b6ec5cea4f19bdc6e86192d5a7348bd2c0e54f367c7e9516"}, "downloads": -1, "filename": "photos_to_sqlite-0.1a0-py3-none-any.whl", "has_sig": false, "md5_digest": "bb5e72d2724f54953f8a21f1cd621e44", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 8145, "upload_time": "2020-04-19T00:17:47", "upload_time_iso_8601": "2020-04-19T00:17:47.555902Z", "url": "https://files.pythonhosted.org/packages/78/a3/615599c7fa926b9b6efa79dfe30dfdf5c9c273fc5f61646268d54a46d961/photos_to_sqlite-0.1a0-py3-none-any.whl"}]}