{"info": {"author": "Divakar Roy", "author_email": "droygatech@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 3 - Alpha", "Intended Audience :: Developers", "License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8", "Topic :: System :: Benchmark"], "description": "benchit (BENCHmark IT!) |GitHub-License|\n========================================\n\nTools to benchmark Python solutions on runtime performance and visualize. Based on `timeit`, it primarily aims to functionally simulate the `timeit <https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-timeit>`__ behaviour and hence the name! This facilitates benchmarking on multiple datasets and solutions.\n\n\nDocumentation\n-------------\n\n|Docs|\n\n\nInstallation\n------------\n\nPull latest development release on GitHub and install in the current directory :\n\n.. code:: sh\n\n    pip install -e git+https://github.com/droyed/benchit.git@master#egg=benchit\n\n\nGetting started\n^^^^^^^^^^^^^^^\n\nConsider a setup to compare NumPy ufuncs - `sum <https://docs.scipy.org/doc/numpy/reference/generated/numpy.sum.html>`__, `prod <https://docs.scipy.org/doc/numpy/reference/generated/numpy.prod.html>`__, `max <https://docs.scipy.org/doc/numpy/reference/generated/numpy.amax.html>`__ on arrays varying in their sizes. To keep it simple, let's consider `1D` arrays. Thus, we would have :\n\n.. code-block:: python\n\n    >>> import numpy as np\n    >>> funcs = [np.sum,np.prod,np.max]\n    >>> inputs = [np.random.rand(i) for i in 10**np.arange(5)]\n\n    >>> t = benchit.timings(funcs, inputs)\n    >>> t\n    Functions       sum      prod      amax\n    Len                                    \n    1          0.000004  0.000004  0.000003\n    10         0.000004  0.000004  0.000004\n    100        0.000004  0.000004  0.000004\n    1000       0.000004  0.000007  0.000004\n    10000      0.000008  0.000022  0.000007\n\nIt's a *dataframe-like* object and as such we can plot it. It automatically adds in specs into the title area to convey all of available benchmarking info :\n\n.. code-block:: python\n\n    >>> t.plot(logy=True, logx=True)\n\n|plot1|\n\nMore realistic example\n^^^^^^^^^^^^^^^^^^^^^^\n\nLet's consider a setup where functions accept more than one argument. Let's take the case of computing `euclidean distances <https://en.wikipedia.org/wiki/Euclidean_distance>`__ between two `2D` arrays. We will feed in arrays with varying number of rows and 3 columns to represent data in 3D Cartesian coordinate system and benchmark two commonly used functions in Python.\n\n.. code-block:: python\n\n    # Setup input functions\n    >>> from sklearn.metrics.pairwise import pairwise_distances\n    >>> from scipy.spatial.distance import cdist\n    >>> fns = [cdist, pairwise_distances]\n    \n    # Setup input datasets\n    >>> import numpy as np\n    >>> in_ = {(n,3):[np.random.rand(n,3), np.random.rand(n,3)] for n in [10,100,500,1000,4000]}\n    \n    # Get benchmarking object (dataframe-like) and plot results\n    >>> t = benchit.timings(fns, in_, multivar=True)\n    >>> t.plot()\n    \n|plot2|\n\n\n\n.. |Docs| image:: https://readthedocs.org/projects/benchit/badge/?version=latest\n    :target: https://benchit.readthedocs.io/en/latest/?badge=latest\n\n.. |GitHub-License| image:: https://img.shields.io/github/license/droyed/benchit\n   :target: https://github.com/droyed/benchit/blob/master/LICENSE\n\n.. |GitHub-Releases| image:: https://img.shields.io/github/v/release/droyed/benchit\n   :target: https://github.com/droyed/benchit/releases/latest\n\n.. |plot1| image:: https://raw.githubusercontent.com/droyed/benchit/master/docs/source/singlevar_numpy_ufuncs_timings.png\n.. |plot2| image:: https://raw.githubusercontent.com/droyed/benchit/master/docs/source/multivar_euclidean_timings.png", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/droyed/benchit", "keywords": "benchmarking performance timing timeit", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "benchit", "package_url": "https://pypi.org/project/benchit/", "platform": "any", "project_url": "https://pypi.org/project/benchit/", "project_urls": {"Homepage": "https://github.com/droyed/benchit"}, "release_url": "https://pypi.org/project/benchit/0.0.1/", "requires_dist": null, "requires_python": "", "summary": "Benchmarking tools for Python", "version": "0.0.1"}, "last_serial": 7027901, "releases": {"0.0.0": [], "0.0.1": [{"comment_text": "", "digests": {"md5": "79dc2a1ff07e81f5e13a11f1a3207290", "sha256": "ab4dbc56ece2c5f56d8ff90b47e7e942627b86a276410b9ed726a0363552f8de"}, "downloads": -1, "filename": "benchit-0.0.1.tar.gz", "has_sig": false, "md5_digest": "79dc2a1ff07e81f5e13a11f1a3207290", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9499, "upload_time": "2020-04-15T22:27:33", "upload_time_iso_8601": "2020-04-15T22:27:33.547503Z", "url": "https://files.pythonhosted.org/packages/31/17/19b9e4211e2d25040f90cbde5eff1aa6325dd15940f47f3c6e8b19572214/benchit-0.0.1.tar.gz"}]}, "urls": [{"comment_text": "", "digests": {"md5": "79dc2a1ff07e81f5e13a11f1a3207290", "sha256": "ab4dbc56ece2c5f56d8ff90b47e7e942627b86a276410b9ed726a0363552f8de"}, "downloads": -1, "filename": "benchit-0.0.1.tar.gz", "has_sig": false, "md5_digest": "79dc2a1ff07e81f5e13a11f1a3207290", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9499, "upload_time": "2020-04-15T22:27:33", "upload_time_iso_8601": "2020-04-15T22:27:33.547503Z", "url": "https://files.pythonhosted.org/packages/31/17/19b9e4211e2d25040f90cbde5eff1aa6325dd15940f47f3c6e8b19572214/benchit-0.0.1.tar.gz"}]}