{"info": {"author": "aidudezzz", "author_email": "deepbots@protonmail.com", "bugtrack_url": null, "classifiers": [], "description": "# deepbots\n\nDeepbots is a simple framework which is used as \"middleware\" between the\n[Webots](https://cyberbotics.com/) robot simulator and Reinforcement Learning\nalgorithms. When it comes to Reinforcement Learning the\n[OpenAI gym](https://gym.openai.com/) environment has been established as the\nmost used interface between the actual application and the RL algorithm.\nDeepbots is a framework which follows the OpenAI gym environment interface\nlogic in order to be used by Webots applications.\n\n## How it works\n\nFirst of all let's set up a simple glossary:\n\n- `World`: Webots uses a tree structure to represent the different entities in\n  the scene. The World is the root entity which contains all the\n  entities/nodes. For example, the world contains the Supervisor and Robot\n  entities as well as other objects which might be included in the scene.\n\n- `Supervisor`: The Supervisor is an entity which has access to all other\n  entities of the world, while having no physical presence in it. For example,\n  the Supervisor knows the exact position of all the entities of the world and\n  can manipulate them. Additionally, the Supervisor has the Supervisor\n  Controller as one of its child nodes.\n\n- `Supervisor Controller`: The Supervisor Controller is a python script which\n  is responsible for the Supervisor. For example, in the Supervisor Controller\n  script the distance between two entities in the world can be calculated.\n\n- `Robot`: The Robot is an entity that represents a robot in the world. It\n  might have sensors and other active components, like motors, etc. as child\n  entities. Also, one of its children is the Robot Controller. For example,\n  [epuck](https://cyberbotics.com/doc/guide/epuck) and\n  [TIAGo](https://cyberbotics.com/doc/guide/tiago-iron) are robots.\n\n- `Robot Controller`: The Robot Controller is a python script which is\n  responsible for the Robot's movement and sensors. With the Robot Controller\n  it is possible to observe the world and act accordingly.\n- `Environment`: The Environment is the interface as described by the OpenAI\n  gym. The Environment interface has the following methods:\n\n  - `get_observations()`: Return the observations of the robot. For example,\n    metrics from sensors, a camera image etc.\n\n  - step(action): Each timestep, the agent chooses an action, and the\n    environment returns the observation, the reward and the state of the\n    problem (done or not).\n\n  - `get_reward(action)`: The reward the agent receives as a result of their\n    action.\n  - `is_done()`: Whether it\u2019s time to reset the environment. Most (but not all)\n    tasks are divided up into well-defined episodes, and done being True\n    indicates the episode has terminated. For example, if a robot has the task\n    to reach a goal, then the done condition might happen when the robot\n    \"touches\" the goal.\n  - `reset()`: Used to reset the world to the initial state.\n\nIn order to set up a task in Deepbots it is necessary to understand the\nintention of the OpenAI gym environment. According to the OpenAI gym\ndocumentation, the framework follows the classic \u201cagent-environment loop\u201d.\n\"Each timestep, the agent chooses an `action`, and the environment returns an\n`observation` and a `reward`. The process gets started by calling `reset()`,\nwhich returns an initial `observation`.\"\n\n<p align=\"center\">\n    <img src=\"https://github.com/aidudezzz/deepbots/blob/dev/doc/img/agent_env_loop.svg\">\n</p>\n\nDeepbots follows this exact agent-environment loop with the only difference\nbeing that the agent, which is responsible to choose an action, runs on the\nSupervisor and the observations are acquired by the robot. The goal of the\ndeepbots framework is to hide this communication from the user, especially from\nthose who are familiar with the OpenAI gym environment. More specifically,\n`SupervisorEnv` is the interface which is used by the Reinforcement Learning\nalgorithms and follows the OpenAI Gym environment logic. The Deepbots framework\nprovides different levels of abstraction according to the user's needs.\nMoreover, a goal of the framework is to provide different wrappers for a wide\nrange of robots. Currently, the communication between the `Supervisor` and the\n`Robot` is achieved via an `emitter` and a `receiver`.\n\n<p align=\"center\">\n    <img src=\"https://raw.githubusercontent.com/aidudezzz/deepbots/dev/doc/img/deepbots_overview.png\">\n</p>\n\nOn one hand, the `emitter` is an entity, which is provided by Webots, that\nbroadcasts messages to the world. On the other hand, the `receiver` is an\nentity that is used to receive messages from the world. Consequently, the\nagent-environment loop is transformed accordingly. Firstly, the Robot uses its\nsensors to retrieve the observation from the World and in turn uses the emitter\ncomponent to broadcast this observation. Secondly, the Supervisor receives the\nobservation via the receiver component and in turn, the agent uses it to choose\nan action. It should be noted that the observation the agent uses might be\nextended from the supervisor. For example, a model might use lidar sensors\ninstalled on the Robot, but also the euclidean distance between the Robot and\nan object. As it is expected, the Robot does not know the euclidean distance,\nonly the Supervisor can calculate it, because it has access to all entities in\nthe World.\n\n<p align=\"center\">\n    <img src=\"https://raw.githubusercontent.com/aidudezzz/deepbots/dev/doc/img/workflow_diagram.png\">\n</p>\n\n### Abstraction Levels\n\nThe deepbots framework has been created mostly for educational purposes. The\naim of the framework is to enable people to use Reinforcement Learning in\nWebots. More specifically, we can consider deepbots as a wrapper of Webots\nexposing an OpenAI gym style interface. For this reason there are multiple\nlevels of abstraction. For example, a user can choose if they want to use CSV\nemitter/receiver or if they want to make a from scratch implementation. In the\ntop level of the abstraction hierarchy is the `SupervisorEnv` which is the\nOpenAI gym interface. Below that level there is an actual implementation. This\nimplementation aims to hide the communication between the `Supervisor` and the\n`Robot`. Similarly, the `Robot` also has different abstraction levels.\nAccording to their needs, users can choose either to process the messages\nreceived from the Supervisor themselves or use the existing implementations.\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "deepbots", "package_url": "https://pypi.org/project/deepbots/", "platform": "", "project_url": "https://pypi.org/project/deepbots/", "project_urls": null, "release_url": "https://pypi.org/project/deepbots/0.0.1rc0/", "requires_dist": null, "requires_python": "", "summary": "A wrapper framework for Reinforcement Learning in Webots     simulator", "version": "0.0.1rc0"}, "last_serial": 7012585, "releases": {"0.0.1rc0": [{"comment_text": "", "digests": {"md5": "9ff54a8753dfcb61b88356eba4874d4d", "sha256": "401b34c04c40390c990bc75def7526048afbb8a07f8d73fedaab64f9688270f1"}, "downloads": -1, "filename": "deepbots-0.0.1rc0-py3-none-any.whl", "has_sig": false, "md5_digest": "9ff54a8753dfcb61b88356eba4874d4d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 23263, "upload_time": "2020-04-13T20:19:39", "upload_time_iso_8601": "2020-04-13T20:19:39.166161Z", "url": "https://files.pythonhosted.org/packages/96/de/a92a89eac4d71a2e8b9979eb3a4151e0fa7e3651e3d763d80d3672d044ff/deepbots-0.0.1rc0-py3-none-any.whl"}, {"comment_text": "", "digests": {"md5": "f49f9a7e3cd85863d4ce1804fd3a085a", "sha256": "454193ad39bbc502308ed364dde7257349a84f9dfe02a20d1fd810396f113e06"}, "downloads": -1, "filename": "deepbots-0.0.1rc0.tar.gz", "has_sig": false, "md5_digest": "f49f9a7e3cd85863d4ce1804fd3a085a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9955, "upload_time": "2020-04-13T20:19:41", "upload_time_iso_8601": "2020-04-13T20:19:41.187622Z", "url": "https://files.pythonhosted.org/packages/4a/9c/a99989da6f8aec99f8308000aa0aa325b1e852d51acb9cf8eaf59f68baeb/deepbots-0.0.1rc0.tar.gz"}]}, "urls": [{"comment_text": "", "digests": {"md5": "9ff54a8753dfcb61b88356eba4874d4d", "sha256": "401b34c04c40390c990bc75def7526048afbb8a07f8d73fedaab64f9688270f1"}, "downloads": -1, "filename": "deepbots-0.0.1rc0-py3-none-any.whl", "has_sig": false, "md5_digest": "9ff54a8753dfcb61b88356eba4874d4d", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 23263, "upload_time": "2020-04-13T20:19:39", "upload_time_iso_8601": "2020-04-13T20:19:39.166161Z", "url": "https://files.pythonhosted.org/packages/96/de/a92a89eac4d71a2e8b9979eb3a4151e0fa7e3651e3d763d80d3672d044ff/deepbots-0.0.1rc0-py3-none-any.whl"}, {"comment_text": "", "digests": {"md5": "f49f9a7e3cd85863d4ce1804fd3a085a", "sha256": "454193ad39bbc502308ed364dde7257349a84f9dfe02a20d1fd810396f113e06"}, "downloads": -1, "filename": "deepbots-0.0.1rc0.tar.gz", "has_sig": false, "md5_digest": "f49f9a7e3cd85863d4ce1804fd3a085a", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 9955, "upload_time": "2020-04-13T20:19:41", "upload_time_iso_8601": "2020-04-13T20:19:41.187622Z", "url": "https://files.pythonhosted.org/packages/4a/9c/a99989da6f8aec99f8308000aa0aa325b1e852d51acb9cf8eaf59f68baeb/deepbots-0.0.1rc0.tar.gz"}]}