{"info": {"author": "Nitesh Kumar", "author_email": "nit567esh@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.2", "Programming Language :: Python :: 3.3", "Programming Language :: Python :: 3.4", "Programming Language :: Python :: 3.5", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Topic :: Software Development :: Libraries :: Python Modules"], "description": "dsconnect - Power your data connections with python\n===================================================\n\n| 1.Overview_\n| 2.Installation_\n| 3.Usages-Guidelines_\n| 4.Examples_\n| 5.Support_\n| 6.Upcoming-Integrations_\n| 7.References_ \n\n1.Overview\n==========\n**dsconnect** is prepared for connecting multiple data source by using a single configuration file where a user can maintain a huge list of reusable connection list and can use it by calling single **conid** parameter.\nIts main features are the variety of popular data source connection capabilities. It is a single wrapper of all most popular data connection python libraries into a single library.\n\ndsconnect is purley implemented in Python.\n\n2.Installation\n==============\n| **To install the library, use below command**\n|    $ pip install dsconnect\n\n.. note::\n\n    During the installation of package please verify that all the required dependencies installed successfully, if not try to install them one by one.\n\n3.Usages-Guidelines\n===================\n| This python library need a configured input file which will include list of all datasource details.File should be in below format:-\n\n +---------+-------------+------------+--------+------------+------------+------------------+-------------+-----------------+\n |**conid**|**host**     |**dbname**  |**port**|**username**|**password**|**datasourcetype**|**conString**|**PythonLibrary**|\n +---------+-------------+------------+--------+------------+------------+------------------+-------------+-----------------+\n |1        |127.0.0.1    |employee    |5433    |livexyz     |live@123    |Redshift          |NA           |psycopg2         |\n +---------+-------------+------------+--------+------------+------------+------------------+-------------+-----------------+\n\n| Once file is prepared with all available datasource connection details, follow the below steps to get data/connect to respective datasource\n\n| **Step 1:** Load  connection details *.csv* file into pandas dataframe             \n|             >> import dsconnect as p\n|             >> <pandas dataframe name> = pandas.read_csv(<filepath>)\n|             >> con = p.config_df(df = <pandas dataframe name>)\n\n| **Step 2:** Pass query with respective conid and get result into pandas\n|             >> df = con.mysql(conid=1,sql=\"select top 10 * from employeesalary\")\n|             >> df = con.redshift(conid=2,sql=\"select top 10 * from students\")\n\n.. note::\n\n    01. Use the same header name which is provided in sample file format for more help a user can use **p.config_df_sample()** command to see structure of sample configuration file format.\n\n    02. Before using conid, verify the datatype of your conid column and pass the same in query for eg. if 1 is string then pass '1', if 1 is int then pass 1.\n\n4.Examples\n==========\nMySQL\n~~~~~~~\n| *Package Used:* mysql-connector-python\n| Eg. df = con.mysql(conid=<uniqueid>,sql=\"select top 10 * from <table>\")\n\nMS SQL Server\n~~~~~~~~~~~~~\n| *Package Used:* pyodbc\n| Eg. df = con.mssql(conid=<uniqueid>,sql=\"select top 10 * from <table>\")\n\nMS Azure SQL Database\n~~~~~~~~~~~~~~~~~~~~~\n| *Package Used:* pyodbc\n| Eg. df = con.msazuresql(conid=<uniqueid>,sql=\"select top 10 * from <table>\")\n\nOracle\n~~~~~~\n| *Package Used:* cx_Oracle\n| Eg. df = con.oracle(conid=<uniqueid>,sql=\"select top 10 * from <table>\")\n\nDB2\n~~~~~~~\n| *Package Used:* ibm_db\n| Eg. df = con.ibmdb(conid=<uniqueid>,sql=\"select top 10 * from <table>\")\n\nPostgreSQL\n~~~~~~~~~~\n| *Package Used:* psycopg2\n| Eg. df = con.postgresql(conid=<uniqueid>,sql=\"select top 10 * from <table>\")\n\nRedshift\n~~~~~~~~\n| *Package Used:* psycopg2\n| Eg. df = con.mysql(conid=<uniqueid>,sql=\"select top 10 * from <table>\")\n\nGsheet\n~~~~~~\n| *Package Used:* pygsheets\n| Eg. con = con.gsheet(conid=<uniqueid>) then proceed with pygsheets documentation with *con* as connection object.\n| **conString** column should be use to store client_secret.json path(Obtained from Google Gsheet API OAuth).\n\n +-----+----+------+----+--------+--------+--------------+---------+------------------+-------------+\n |conid|host|dbname|port|username|password|datasourcetype|conString                   |PythonLibrary|\n +-----+----+------+----+--------+--------+--------------+---------+------------------+-------------+\n |1    |NA  |NA    |NA  |NA      |NA      |Gsheet        |<D:/Test/client_secret.json>|pygsheets    |\n +-----+----+------+----+--------+--------+--------------+---------+------------------+-------------+\n\nURL Download\n~~~~~~~~~~~~\n| *Package Used:* requests\n| A user can directly pass download url.\n| Eg. p.byurl(url<download url>,targetpath=<path to store downloaded file>)\n\nSFTP\n~~~~\n| *Package Used:* pysftp\n| Eg. con = con.sftp(conid=1) then proceed with pysftp documentation with *con* as connection object.\n\n +-----+---------+------+--------+--------+--------+--------------+---------+-------------+\n |conid|host     |dbname|port    |username|password|datasourcetype|conString|PythonLibrary|\n +-----+---------+------+--------+--------+--------+--------------+---------+-------------+\n |1    |127.0.0.1|NA    |NA      |xxxxxx  |xxxxxx  |SFTP          |NA       |pysftp       |\n +-----+---------+------+--------+--------+--------+--------------+---------+-------------+\n\nAWS S3\n~~~~~~\n| *Package Used:* boto3\n| Eg. con = con.s3connect(conid=1) then proceed with boto3 documentation with *con* as connection object for S3 bucket.\n\n +-----+----+------+----+--------+--------+--------------+-------------------------------------+-------------+\n |conid|host|dbname|port|username|password|datasourcetype|conString                            |PythonLibrary|\n +-----+----+------+----+--------+--------+--------------+-------------------------------------+-------------+\n |1    |NA  |NA    |NA  |NA      |NA      |AWS S3        |{'accesskey':'XXX','secretkey':'XXX'}|boto3        |\n +-----+----+------+----+--------+--------+--------------+-------------------------------------+-------------+\n\nS3 SELECT\n~~~~~~~~~\n| *Package Used:* boto3\n| Eg. df = con.s3select(conid=1,bucket=<bucket name>,select_stmnt=<SQL expr>,output_format=<CSV/JSON>,fielddelimiter=<',','|' etc. Only applicable for csv/txt files>)\n\n\n\n5.Support\n==========\n +--------------------+------------------------------------+\n |**Operating System**|Linux/OSX/Windows                   |\n +--------------------+------------------------------------+\n |**Python Version**  |2/2.7/3/3.2/3.3/3.4/3.5/3.7 etc.    |\n +--------------------+------------------------------------+ \n\n6.Upcoming-Integrations\n=======================\n\n| Below are the list of datasources planned to add in next version of **dsconnect**\n\n| 01. Mixpanel\n| 02. ElasticSearch\n| 03. HDFS\n| 04. Hive\n| 05. Google Analytics\n| 06. Google Adwords\n| 07. Sisense BI - REST API Connect and many more.\n| 08. Dropbox\n\n7.References\n============\n| Many thanks to the developers of dependent packages. Please use the below links to get deeper knowledge about required packages:-\n\n| **PYSFTP:** https://pypi.org/project/pysftp/\n| **ORACLE:** https://pypi.org/project/cx_Oracle/\n| **MYSQL:** https://pypi.org/project/mysql-connector-python/\n| **PSYCOPG2:** https://pypi.org/project/psycopg2/\n| **PYODBC:** https://pypi.org/project/pyodbc/\n| **PYGSHEETS:** https://pypi.org/project/pygsheets/\n| **BOTO3:** https://pypi.org/project/boto3/\n| **IBM DB2:** https://pypi.org/project/ibm_db/\n\n", "description_content_type": "", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://github.com/nit567esh/dsconnect", "keywords": "MySQL,MS SQL Server,MS Azure SQL Database,Oracle,IBM-DB,PostgreSQL,Redshift,GSheets,download-url,SFTP,Pandas,CSV,JSON", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "dsconnect", "package_url": "https://pypi.org/project/dsconnect/", "platform": "", "project_url": "https://pypi.org/project/dsconnect/", "project_urls": {"Homepage": "http://github.com/nit567esh/dsconnect"}, "release_url": "https://pypi.org/project/dsconnect/0.0.1/", "requires_dist": ["pandas", "psycopg2", "pyodbc", "pygsheets", "pysftp", "boto3", "mysql-connector-python", "cx-Oracle", "ibm-db"], "requires_python": "", "summary": "Power your data connections with python", "version": "0.0.1"}, "last_serial": 4667999, "releases": {"0.0.1": [{"comment_text": "", "digests": {"md5": "a50e30854cb7a576d2d665f42ac8729c", "sha256": "cb4b7fa228d2c9481de4696b8c097690654e047bdd3af4a4f0371c0870245b89"}, "downloads": -1, "filename": "dsconnect-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "a50e30854cb7a576d2d665f42ac8729c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6639, "upload_time": "2019-01-07T09:50:36", "upload_time_iso_8601": "2019-01-07T09:50:36.873214Z", "url": "https://files.pythonhosted.org/packages/a5/1c/86b7394ff5aae65213f7aa4cd19d4e8341f6a2c46caf30ad3dc08e46467c/dsconnect-0.0.1-py3-none-any.whl"}, {"comment_text": "", "digests": {"md5": "bd5d4c903718d61ee3b187acf451fdda", "sha256": "cc9016e36d43f3aa3728cc12ddab53c45addf567158d7274a37e5756097e49ba"}, "downloads": -1, "filename": "dsconnect-0.0.1.tar.gz", "has_sig": false, "md5_digest": "bd5d4c903718d61ee3b187acf451fdda", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6029, "upload_time": "2019-01-07T09:50:38", "upload_time_iso_8601": "2019-01-07T09:50:38.911077Z", "url": "https://files.pythonhosted.org/packages/64/62/0aacc2ce8a5d72a50e74893e153033731c3320c6d896353262862013bb71/dsconnect-0.0.1.tar.gz"}]}, "urls": [{"comment_text": "", "digests": {"md5": "a50e30854cb7a576d2d665f42ac8729c", "sha256": "cb4b7fa228d2c9481de4696b8c097690654e047bdd3af4a4f0371c0870245b89"}, "downloads": -1, "filename": "dsconnect-0.0.1-py3-none-any.whl", "has_sig": false, "md5_digest": "a50e30854cb7a576d2d665f42ac8729c", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": null, "size": 6639, "upload_time": "2019-01-07T09:50:36", "upload_time_iso_8601": "2019-01-07T09:50:36.873214Z", "url": "https://files.pythonhosted.org/packages/a5/1c/86b7394ff5aae65213f7aa4cd19d4e8341f6a2c46caf30ad3dc08e46467c/dsconnect-0.0.1-py3-none-any.whl"}, {"comment_text": "", "digests": {"md5": "bd5d4c903718d61ee3b187acf451fdda", "sha256": "cc9016e36d43f3aa3728cc12ddab53c45addf567158d7274a37e5756097e49ba"}, "downloads": -1, "filename": "dsconnect-0.0.1.tar.gz", "has_sig": false, "md5_digest": "bd5d4c903718d61ee3b187acf451fdda", "packagetype": "sdist", "python_version": "source", "requires_python": null, "size": 6029, "upload_time": "2019-01-07T09:50:38", "upload_time_iso_8601": "2019-01-07T09:50:38.911077Z", "url": "https://files.pythonhosted.org/packages/64/62/0aacc2ce8a5d72a50e74893e153033731c3320c6d896353262862013bb71/dsconnect-0.0.1.tar.gz"}]}