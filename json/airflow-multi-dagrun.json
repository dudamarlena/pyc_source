{"info": {"author": "Ihor Liubymov", "author_email": "infunt@gmail.com", "bugtrack_url": null, "classifiers": [], "description": "[![Build Status](https://travis-ci.com/mastak/airflow_multi_dagrun.svg?branch=master)](https://travis-ci.com/mastak/airflow_multi_dagrun)\n\n# Multi dag run\n\nThis plugin contains operators for triggering a DAG run multiple times\nand you can dynamically specify how many DAG run instances create.\n\nIt can be useful when you have to handle a big data and you want to split it\ninto chunks and run multiple instances of the same task in parallel.\n\nWhen you see a lot launched target DAGs you can set up more workers.\nSo this makes it pretty easy to scale.\n\n## Install\n\n```bash\npip install airflow_multi_dagrun\n```\n\n## Example\n\nCode for scheduling dags\n\n```python\nimport datetime as dt\nfrom airflow import DAG\nfrom airflow.operators.dagrun_operator import DagRunOrder\nfrom airflow.operators.multi_dagrun import TriggerMultiDagRunOperator\n\n\ndef generate_dag_run():\n    for i in range(100):\n        yield DagRunOrder(payload={'index': i})\n\n\ndefault_args = {\n    'owner': 'airflow',\n    'start_date': dt.datetime(2015, 6, 1),\n}\n\n\ndag = DAG('reindex_scheduler', schedule_interval=None, default_args=default_args)\n\n\nran_dags = TriggerMultiDagRunOperator(\n    task_id='gen_target_dag_run',\n    dag=dag,\n    trigger_dag_id='example_target_dag',\n    python_callable=generate_dag_run,\n)\n```\n\nThis code will schedule dag with id `example_target_dag` 100 times and pass payload to it.\n\n\nExample of triggered dag:\n\n ```python\ndag = DAG(\n    dag_id='example_target_dag',\n    schedule_interval=None,\n    default_args={'start_date': datetime.utcnow(), 'owner': 'airflow'},\n)\n\n\ndef run_this_func(dag_run, **kwargs):\n    print(\"Chunk received: {}\".format(dag_run.conf['index']))\n\n\nchunk_handler = PythonOperator(\n    task_id='chunk_handler',\n    provide_context=True,\n    python_callable=run_this_func,\n    dag=dag\n)\n```\n\n## Run example\nThere is docker-compose config, so it requires docker to be installed: `docker`, `docker-compose`\n1. `make run` - start docker containers, init db, run airflow webserver\n2. `make down` - destroy docker containers\n\n## Contributions\nIf you have found a bug or have some idea for improvement feel free to create an issue\nor pull request.\n\n## License\nApache 2.0\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/mastak/airflow_multi_dagrun", "keywords": "", "license": "", "maintainer": "", "maintainer_email": "", "name": "airflow-multi-dagrun", "package_url": "https://pypi.org/project/airflow-multi-dagrun/", "platform": "", "project_url": "https://pypi.org/project/airflow-multi-dagrun/", "project_urls": {"Homepage": "https://github.com/mastak/airflow_multi_dagrun"}, "release_url": "https://pypi.org/project/airflow-multi-dagrun/1.2/", "requires_dist": null, "requires_python": ">=3.6.0", "summary": "MultiDagRunPlugin for airflow", "version": "1.2"}, "last_serial": 6320574, "releases": {"1.0": [{"comment_text": "", "digests": {"md5": "6a52df81e722f88a956583b7d5697466", "sha256": "cd3f4641d07f7248334d0eed61afae154d940aa96c130d7f9bfa8cab59e0e5f9"}, "downloads": -1, "filename": "airflow_multi_dagrun-1.0-py3-none-any.whl", "has_sig": false, "md5_digest": "6a52df81e722f88a956583b7d5697466", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 5622, "upload_time": "2019-12-17T20:52:14", "upload_time_iso_8601": "2019-12-17T20:52:14.551430Z", "url": "https://files.pythonhosted.org/packages/7f/64/8c5b29acb5ccf61582ca5d73c055bdfaa31dc53cc97ad0a907bc97af52f1/airflow_multi_dagrun-1.0-py3-none-any.whl"}], "1.1": [{"comment_text": "", "digests": {"md5": "544e949a46fa949631be32356f6d1126", "sha256": "fa39739ecba082dc1feb0f3c9574c62ab11fb6ec7c804bdbe909b75ac62c48e6"}, "downloads": -1, "filename": "airflow_multi_dagrun-1.1-py3-none-any.whl", "has_sig": false, "md5_digest": "544e949a46fa949631be32356f6d1126", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 6610, "upload_time": "2019-12-17T20:58:49", "upload_time_iso_8601": "2019-12-17T20:58:49.372787Z", "url": "https://files.pythonhosted.org/packages/46/32/d25181654e2e72fc6bc0d5db67a272690e933dfd81f891a1673c2a7c51cc/airflow_multi_dagrun-1.1-py3-none-any.whl"}], "1.2": [{"comment_text": "", "digests": {"md5": "05e5c19d19ca6e4448da70dd1f6e42ef", "sha256": "a2f3fd29e2afe6d78c53fa9d07ca0ccb7da0cb1d19ddaf80e8d7c7093a3b973e"}, "downloads": -1, "filename": "airflow_multi_dagrun-1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "05e5c19d19ca6e4448da70dd1f6e42ef", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 13054, "upload_time": "2019-12-17T21:13:08", "upload_time_iso_8601": "2019-12-17T21:13:08.313421Z", "url": "https://files.pythonhosted.org/packages/af/41/e60dff951d002dbf14daf601b1323dfc48c0d24d2bc4e7d19ac72b19c3f6/airflow_multi_dagrun-1.2-py3-none-any.whl"}]}, "urls": [{"comment_text": "", "digests": {"md5": "05e5c19d19ca6e4448da70dd1f6e42ef", "sha256": "a2f3fd29e2afe6d78c53fa9d07ca0ccb7da0cb1d19ddaf80e8d7c7093a3b973e"}, "downloads": -1, "filename": "airflow_multi_dagrun-1.2-py3-none-any.whl", "has_sig": false, "md5_digest": "05e5c19d19ca6e4448da70dd1f6e42ef", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 13054, "upload_time": "2019-12-17T21:13:08", "upload_time_iso_8601": "2019-12-17T21:13:08.313421Z", "url": "https://files.pythonhosted.org/packages/af/41/e60dff951d002dbf14daf601b1323dfc48c0d24d2bc4e7d19ac72b19c3f6/airflow_multi_dagrun-1.2-py3-none-any.whl"}]}