{"info": {"author": "Chris Waites", "author_email": "cwaites10@gmail.com", "bugtrack_url": null, "classifiers": ["License :: OSI Approved :: MIT License", "Operating System :: OS Independent", "Programming Language :: Python :: 3"], "description": "<img align=\"right\" width=\"300\" src=\"assets/flows.gif\">\n\n# Normalizing Flows in JAX\n\nImplementations of normalizing flows (RealNVP, GLOW, MAF) in the <a href=\"https://github.com/google/jax/\">JAX</a> deep learning framework.</p>\n\n<a href=\"https://circleci.com/gh/ChrisWaites/jax-flows\">\n    <img alt=\"Build\" src=\"https://img.shields.io/circleci/build/github/ChrisWaites/jax-flows/master\">\n</a>\n<a href=\"https://github.com/ChrisWaites/jax-flows/blob/master/LICENSE\">\n    <img alt=\"GitHub\" src=\"https://img.shields.io/github/license/ChrisWaites/jax-flows.svg?color=blue\">\n</a>\n<a href=\"https://ChrisWaites.co/jax-flows/index.html\">\n    <img alt=\"Documentation\" src=\"https://img.shields.io/website/http/ChrisWaites.co/jax-flows/index.html.svg?down_color=red&down_message=offline&up_message=online\">\n</a>\n<a href=\"https://github.com/ChrisWaites/jax-flows/releases\">\n    <img alt=\"GitHub release\" src=\"https://img.shields.io/github/release/ChrisWaites/jax-flows.svg\">\n</a>\n\n## What are normalizing flows?\n\nNormalizing flow models are _generative models_. That is, they infer the probability distribution of a given dataset. With that distribution we can do a number of interesting things, namely query the likelihood of given points as well as sample new realistic points.\n\n<!---\nHow is are these things achieved? Well, we learn a function <img src=\"https://render.githubusercontent.com/render/math?math=f_{\\theta}\"> characterized by a parameter vector <img src=\"https://render.githubusercontent.com/render/math?math=\\theta\"> with an inverse <img src=\"https://render.githubusercontent.com/render/math?math=f^{-1}_{\\theta}\">. If X is our approximated distribution and Z is some known distribution we choose (say, the multivariate normal distribution), we're simply going to define X as f_\\theta(Z).\n-->\n\n## How are things structured?\n\n### Transformations\n\nA `transformation` is a parameterized invertible function.\n\n```python\ninit_fun = flows.MADE()\n\nparams, direct_fun, inverse_fun = init_fun(rng, input_shape)\n\n# Transform some inputs\ntransformed_inputs, log_det_direct = direct_fun(params, inputs)\n\n# Reconstruct original inputs\nreconstructed_inputs, log_det_inverse = inverse_fun(params, inputs)\n\nassert np.array_equal(inputs, reconstructed_inputs)\n```\n\nWe can construct a larger meta-transformation by composing a sequence of sub-transformations using `flows.serial`. The resulting transformation adheres to the exact same interface and is indistinguishable from any other regular transformation.\n\n```python\ninit_fun = flows.serial(\n  flows.MADE(),\n  flows.BatchNorm(),\n  flows.Reverse()\n)\n\nparams, direct_fun, inverse_fun = init_fun(rng, input_shape)\n```\n\n### Distributions\n\nA `distribution` has a similarly simple interface. It is characterized by a set of parameters, a function for querying the log of the pdf at a given point, and a sampling function.\n\n```python\ninit_fun = Normal()\n\nparams, log_pdf, sample = init_fun(rng, input_shape)\n\nlog_pdfs = log_pdf(params, inputs)\n\nsamples = sample(rng, params, num_samples)\n```\n\n### Normalizing Flow Models\n\nUnder this definition, a normalizing flow model is just a `distribution`. But to retrieve one, we have to give it a transformation and another prior distribution.\n\n```python\ntransformation = flows.serial(\n  flows.MADE(),\n  flows.BatchNorm(),\n  flows.Reverse(),\n  flows.MADE(),\n  flows.BatchNorm(),\n  flows.Reverse(),\n)\n\nprior = Normal()\n\ninit_fun = flows.Flow(transformation, prior)\n\nparams, log_pdf, sample = init_fun(rng, input_shape)\n```\n\n### How do I train a model?\n\nTo train our model, we would typically define an appropriate loss function and parameter update step.\n\n```python\ndef loss(params, inputs):\n  return -log_pdf(params, inputs).mean()\n\n@jit\ndef step(i, opt_state, inputs):\n  params = get_params(opt_state)\n  return opt_update(i, grad(loss)(params, inputs), opt_state)\n```\n\nGiven these, we can go forward and execute a standard JAX training loop.\n\n```python\nbatch_size = 32\n\nitercount = itertools.count()\nfor epoch in range(num_epochs):\n  npr.shuffle(X)\n  for batch_index in range(0, len(X), batch_size):\n    opt_state = step(next(itercount), opt_state, X[batch_index:batch_index+batch_size])\n\noptimized_params = get_params(opt_state)\n```\n\nNow that we have our trained model parameters, we can query and sample as regular.\n\n```python\nlog_pdfs = log_pdf(optimized_params, inputs)\n\nsamples = sample(rng, optimized_params, num_samples)\n```\n\n_Magic!_\n\n## Interested in contributing?\n\nYay! Check out our contributing guidelines in `.github/CONTRIBUTING.md`.\n\n## Inspiration\n\nThis repository is largely modeled after the [`pytorch-flows`](https://github.com/ikostrikov/pytorch-flows) repository by [Ilya Kostrikov\n](https://github.com/ikostrikov).\n\nThe implementations are modeled after the work of the following papers.\n\n  > [Density estimation using Real NVP](https://arxiv.org/abs/1605.08803)\\\n  > Laurent Dinh, Jascha Sohl-Dickstein, Samy Bengio\\\n  > _arXiv:1605.08803_\n\n  > [Glow: Generative Flow with Invertible 1x1 Convolutions](https://arxiv.org/abs/1807.03039)\\\n  > Diederik P. Kingma, Prafulla Dhariwal\\\n  > _arXiv:1807.03039_\n\n  > [Flow++: Improving Flow-Based Generative Models\n  with Variational Dequantization and Architecture Design](https://openreview.net/forum?id=Hyg74h05tX)\\\n  > Jonathan Ho, Xi Chen, Aravind Srinivas, Yan Duan, Pieter Abbeel\\\n  > _OpenReview:Hyg74h05tX_\n\n  > [Masked Autoregressive Flow for Density Estimation](https://arxiv.org/abs/1705.07057)\\\n  > George Papamakarios, Theo Pavlakou, Iain Murray\\\n  > _arXiv:1705.07057_\n\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "http://github.com/ChrisWaites/jax-flows", "keywords": "", "license": "MIT", "maintainer": "", "maintainer_email": "", "name": "jax-flows", "package_url": "https://pypi.org/project/jax-flows/", "platform": "", "project_url": "https://pypi.org/project/jax-flows/", "project_urls": {"Homepage": "http://github.com/ChrisWaites/jax-flows"}, "release_url": "https://pypi.org/project/jax-flows/0.0.0/", "requires_dist": ["black (==19.10b0)", "flake8 (==3.7.9)", "isort (==4.3.21)", "jax (==0.1.59)", "jaxlib (==0.1.39)", "jupyter (==1.0.0)", "jupyter-client (==5.3.4)", "jupyter-console (==6.1.0)", "jupyter-core (==4.6.1)", "matplotlib (==3.1.3)", "numpy (==1.18.1)", "pytest (==5.4.1)", "scikit-learn (==0.22.1)", "scipy (==1.4.1)", "seaborn (==0.10.0)", "tqdm (==4.43.0)", "twine ; extra == 'dev'", "pytest ; extra == 'dev'", "pytest-xdist ; extra == 'dev'", "black ; extra == 'dev'", "isort ; extra == 'dev'", "flake8 ; extra == 'dev'", "recommonmark ; extra == 'docs'", "sphinx ; extra == 'docs'", "sphinx-markdown-tables ; extra == 'docs'", "sphinx-rtd-theme ; extra == 'docs'", "black ; extra == 'quality'", "isort ; extra == 'quality'", "flake8 ; extra == 'quality'", "pytest ; extra == 'testing'", "pytest-xdist ; extra == 'testing'"], "requires_python": ">=3.6.0", "summary": "Normalizing Flows for JAX", "version": "0.0.0"}, "last_serial": 6886423, "releases": {"0.0.0": [{"comment_text": "", "digests": {"md5": "56fb4bbbf2bd2824e53b2ef6f06933e7", "sha256": "e1c272a488bc794078bbdd07b5b0ec7e1b8b3af81e3b7169d54a7cbcefb15025"}, "downloads": -1, "filename": "jax_flows-0.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "56fb4bbbf2bd2824e53b2ef6f06933e7", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 8369, "upload_time": "2020-03-26T03:00:03", "upload_time_iso_8601": "2020-03-26T03:00:03.579362Z", "url": "https://files.pythonhosted.org/packages/58/53/4b8479223cdae3d998afb014f0b61b6dc695a4a0ad90c501b3edc873aafd/jax_flows-0.0.0-py3-none-any.whl"}, {"comment_text": "", "digests": {"md5": "8c52ca77a9efea7d46a80f334d7af784", "sha256": "4702adeebd56592f988c797e11ae4e0a46e51c22f9a7872f138808b1bfd9320d"}, "downloads": -1, "filename": "jax-flows-0.0.0.tar.gz", "has_sig": false, "md5_digest": "8c52ca77a9efea7d46a80f334d7af784", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 7278, "upload_time": "2020-03-26T03:00:05", "upload_time_iso_8601": "2020-03-26T03:00:05.850429Z", "url": "https://files.pythonhosted.org/packages/2a/e5/b7fbd922eb3de60f25c368c6abbf6efe479f842152411950e6e22401a908/jax-flows-0.0.0.tar.gz"}]}, "urls": [{"comment_text": "", "digests": {"md5": "56fb4bbbf2bd2824e53b2ef6f06933e7", "sha256": "e1c272a488bc794078bbdd07b5b0ec7e1b8b3af81e3b7169d54a7cbcefb15025"}, "downloads": -1, "filename": "jax_flows-0.0.0-py3-none-any.whl", "has_sig": false, "md5_digest": "56fb4bbbf2bd2824e53b2ef6f06933e7", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.0", "size": 8369, "upload_time": "2020-03-26T03:00:03", "upload_time_iso_8601": "2020-03-26T03:00:03.579362Z", "url": "https://files.pythonhosted.org/packages/58/53/4b8479223cdae3d998afb014f0b61b6dc695a4a0ad90c501b3edc873aafd/jax_flows-0.0.0-py3-none-any.whl"}, {"comment_text": "", "digests": {"md5": "8c52ca77a9efea7d46a80f334d7af784", "sha256": "4702adeebd56592f988c797e11ae4e0a46e51c22f9a7872f138808b1bfd9320d"}, "downloads": -1, "filename": "jax-flows-0.0.0.tar.gz", "has_sig": false, "md5_digest": "8c52ca77a9efea7d46a80f334d7af784", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.0", "size": 7278, "upload_time": "2020-03-26T03:00:05", "upload_time_iso_8601": "2020-03-26T03:00:05.850429Z", "url": "https://files.pythonhosted.org/packages/2a/e5/b7fbd922eb3de60f25c368c6abbf6efe479f842152411950e6e22401a908/jax-flows-0.0.0.tar.gz"}]}