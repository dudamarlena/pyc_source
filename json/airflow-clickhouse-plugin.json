{"info": {"author": "Viktor Taranenko, Anton Bryzgalov", "author_email": "viktor@samsungnext.com, tony.bryzgaloff@gmail.com", "bugtrack_url": null, "classifiers": ["Development Status :: 4 - Beta", "Environment :: Plugins", "Intended Audience :: Developers", "Programming Language :: Python :: 3.6", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8"], "description": "# Airflow ClickHouse Plugin\n\nProvides `ClickHouseHook` and `ClickHouseOperator` for [Apache Airflow][airflow] \n    based on [mymarilyn/clickhouse-driver][ch-driver].\n\n# Features\n\n1. SQL queries are templated.\n2. Can run multiple SQL queries per single `ClickHouseOperator`.\n3. Result of the last query of `ClickHouseOperator` instance is pushed to XCom.\n4. Executed queries are logged in a pretty form.\n5. Uses effective native ClickHouse TCP protocol thanks to \n    [clickhouse-driver][ch-driver-docs]. Does not support HTTP protocol.\n\n# Installation\n\n`pip install -U airflow-clickhouse-plugin`\n\n# Usage\n\nSee [examples](#examples) below.\n\n## ClickHouseOperator Reference\n\nTo import `ClickHouseOperator` use:\n    `from airflow.operators.clickhouse_operator import ClickHouseOperator`\n\nSupported kwargs:\n* `sql`: templated query (if argument is a single `str`) or queries (if iterable\n    of `str`'s).\n* `clickhouse_conn_id`: connection id. Connection schema (all properties are \n    optional, defaults correspond to the default ClickHouse configuration):\n  * `host`, default: `localhost`;\n  * `port`, default: `9000` (default native ClickHouse protocol port);\n  * `database`, default: `default`;\n  * `user`, default: `default`;\n  * `password`, default: `''` (empty).\n* `parameters`: passed to clickhouse-driver [execute method][ch-driver-execute].\n  * If multiple queries are provided via `sql` then the parameters are passed to\n      _all_ of them.\n  * Parameters are _not_ templated.\n* `database`: if present, overrides database defined by connection.\n* Other kwargs (including the required `task_id`) are inherited from Airflow \n    [BaseOperator][airflow-base-op].\n\nThe result of the _last_ query is pushed to XCom.\n\n## ClickHouseHook Reference\n\nTo import `ClickHouseHook` use:\n    `from airflow.hooks.clickhouse_hook import ClickHouseHook`\n\nSupported kwargs of constructor (`__init__` method):\n* `clickhouse_conn_id`: connection id. See connection schema above.\n* `database`: if present, overrides database defined by connection.\n\nSupports all of the methods of the Airflow [BaseHook][airflow-base-hook]\n    including:\n* `get_records(sql: str, parameters: dict=None)`: returns result of the query\n    as a list of tuples. Materializes all the records in memory.\n* `get_first(sql: str, parameters: dict=None)`: returns the first row of the\n    result. Does not load the whole dataset into memory because of using\n    [execute_iter][ch-driver-execute-iter].\n* `run(sql, parameters)`: runs a single query (specified argument of type `str`)\n    or multiple queries (if iterable of `str`). `parameters` can have any form\n    supported by [execute][ch-driver-execute] method of clickhouse-driver.\n  * If single query is run then returns its result. If multiple queries are run\n      then returns the result of the last of them.\n  * If multiple queries are given then `parameters` are passed to _all_ of them.\n  * Materializes all the records in memory (uses simple `execute` but not \n      `execute_iter`).\n    * To achieve results streaming by `execute_iter` use it directly via\n        `hook.get_conn().execute_iter(\u2026)`\n        (see [execute_iter reference][ch-driver-execute-iter]).\n  * Every `run` call uses a new connection which is closed when finished.\n* `get_conn()`: returns the underlying\n    [clickhouse_driver.Client][ch-driver-client] instance.\n* `get_pandas_df` is not implemented.\n\n## Examples\n\n### ClickHouseOperator\n\n```python\nfrom airflow import DAG\nfrom airflow.operators.clickhouse_plugin import ClickHouseOperator\nfrom airflow.operators.python_operator import PythonOperator\nfrom airflow.utils.dates import days_ago\n\nwith DAG(\n        dag_id='update_income_aggregate',\n        start_date=days_ago(2),\n) as dag:\n    ClickHouseOperator(\n        task_id='update_income_aggregate',\n        database='default',\n        sql=(\n            \"INSERT INTO aggregate \"\n                \"SELECT eventDt, sum(price * qty) AS income FROM sales \"\n                \"WHERE eventDt = '{{ ds }}' GROUP BY eventDt\",\n            \"OPTIMIZE TABLE aggregate ON CLUSTER {{ var.value.cluster_name }} \"\n                \"PARTITION toDate('{{ execution_date.format('%Y-%m-01') }}')\",\n            \"SELECT sum(income) FROM aggregate \"\n                \"WHERE eventDt BETWEEN \"\n                \"'{{ execution_date.start_of('month').to_date_string() }}'\"\n                \"AND '{{ execution_date.end_of('month').to_date_string() }}'\",\n            # result of the last query is pushed to XCom\n        ),\n        clickhouse_conn_id='clickhouse_test',\n    ) >> PythonOperator(\n        task_id='print_month_income',\n        provide_context=True,\n        python_callable=lambda task_instance, **_:\n            # pulling XCom value and printing it\n            print(task_instance.xcom_pull(task_ids='update_income_aggregate')),\n    )\n```\n\n### ClickHouseHook\n\n```python\nfrom airflow import DAG\nfrom airflow.hooks.clickhouse_hook import ClickHouseHook\nfrom airflow.hooks.mysql_hook import MySqlHook\nfrom airflow.operators.python_operator import PythonOperator\nfrom airflow.utils.dates import days_ago\n\n\ndef mysql_to_clickhouse():\n    mysql_hook = MySqlHook()\n    ch_hook = ClickHouseHook()\n    records = mysql_hook.get_records('SELECT * FROM some_mysql_table')\n    ch_hook.run('INSERT INTO some_ch_table VALUES', records)\n\n\nwith DAG(\n        dag_id='mysql_to_clickhouse',\n        start_date=days_ago(2),\n) as dag:\n    dag >> PythonOperator(\n        task_id='mysql_to_clickhouse',\n        python_callable=mysql_to_clickhouse,\n    )\n```\n\nImportant note: don't try to insert values using \n    `ch_hook.run('INSERT INTO some_ch_table VALUES (1)')` literal form.\n    clickhouse-driver [requires][ch-driver-insert] values for `INSERT` query to\n    be provided via `parameters` due to specifics of the native ClickHouse\n    protocol.\n\n# Default connection\n\nBy default the hook and operator use `connection_id='clickhouse_default'`.\n\n# Contributors\n\n* Anton Bryzgalov, [@bryzgaloff](https://github.com/bryzgaloff)\n* Viktor Taranenko, [@viktortnk](https://github.com/viktortnk)\n\n\n[airflow]: https://airflow.apache.org/\n[ch-driver]: https://github.com/mymarilyn/clickhouse-driver\n[ch-driver-docs]: https://clickhouse-driver.readthedocs.io/en/latest/\n[ch-driver-execute]: https://clickhouse-driver.readthedocs.io/en/latest/quickstart.html#selecting-data\n[airflow-base-op]: https://airflow.apache.org/docs/stable/_api/airflow/models/baseoperator/index.html\n[airflow-base-hook]: https://airflow.apache.org/docs/stable/_api/airflow/hooks/base_hook/index.html\n[ch-driver-execute-iter]: https://clickhouse-driver.readthedocs.io/en/latest/quickstart.html#streaming-results\n[ch-driver-insert]: https://clickhouse-driver.readthedocs.io/en/latest/quickstart.html#inserting-data\n[ch-driver-client]: https://clickhouse-driver.readthedocs.io/en/latest/api.html#client\n\n\n", "description_content_type": "text/markdown", "docs_url": null, "download_url": "", "downloads": {"last_day": -1, "last_month": -1, "last_week": -1}, "home_page": "https://github.com/whisklabs/airflow-clickhouse-plugin", "keywords": "clickhouse,airflow", "license": "MIT License", "maintainer": "", "maintainer_email": "", "name": "airflow-clickhouse-plugin", "package_url": "https://pypi.org/project/airflow-clickhouse-plugin/", "platform": "", "project_url": "https://pypi.org/project/airflow-clickhouse-plugin/", "project_urls": {"Homepage": "https://github.com/whisklabs/airflow-clickhouse-plugin"}, "release_url": "https://pypi.org/project/airflow-clickhouse-plugin/0.5.2/", "requires_dist": ["clickhouse-driver (==0.1.2)", "apache-airflow (==1.10.6)"], "requires_python": ">=3.6.*", "summary": "airflow-clickhouse-plugin - Airflow plugin to execute ClickHouse commands and queries", "version": "0.5.2"}, "last_serial": 6943253, "releases": {"0.5.0": [{"comment_text": "", "digests": {"md5": "944820a059a251343f9f0a1ad772856e", "sha256": "684455f57576cbc533412d56970f1569fa3f75ad73c34b33981a2424ae3c9c66"}, "downloads": -1, "filename": "airflow_clickhouse_plugin-0.5.0-py3-none-any.whl", "has_sig": false, "md5_digest": "944820a059a251343f9f0a1ad772856e", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.7.*", "size": 7393, "upload_time": "2020-03-30T09:35:52", "upload_time_iso_8601": "2020-03-30T09:35:52.281645Z", "url": "https://files.pythonhosted.org/packages/b7/0e/d62822c5e6ef38c312bc2e355420c4b2937cb846debe153989a139ce5432/airflow_clickhouse_plugin-0.5.0-py3-none-any.whl"}, {"comment_text": "", "digests": {"md5": "eaad6a1d5587278a5d2f6d40b5805740", "sha256": "9e200bf3e64e65261e64dd62a12aabe2a2c3118005bc6ee7c3c36bb31894ae36"}, "downloads": -1, "filename": "airflow-clickhouse-plugin-0.5.0.tar.gz", "has_sig": false, "md5_digest": "eaad6a1d5587278a5d2f6d40b5805740", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.7.*", "size": 6046, "upload_time": "2020-03-30T09:35:54", "upload_time_iso_8601": "2020-03-30T09:35:54.392805Z", "url": "https://files.pythonhosted.org/packages/cd/c5/f493bc10ee3cfa1dcd624985a9b1a3bc49ff33c731cf638991642757af06/airflow-clickhouse-plugin-0.5.0.tar.gz"}], "0.5.1": [{"comment_text": "", "digests": {"md5": "0df1dbb1bb52fd1a6c4ce844e7242f08", "sha256": "957018080ab8b9670f86108f416f090fc5b1eb046c7a065a171ed1e30bb7ccae"}, "downloads": -1, "filename": "airflow_clickhouse_plugin-0.5.1-py3-none-any.whl", "has_sig": false, "md5_digest": "0df1dbb1bb52fd1a6c4ce844e7242f08", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.*", "size": 8228, "upload_time": "2020-04-03T13:05:00", "upload_time_iso_8601": "2020-04-03T13:05:00.444177Z", "url": "https://files.pythonhosted.org/packages/2d/80/e0beda560c6358fa3ee8d36efac748a0eefa3e66b44509db71cb451b8d2f/airflow_clickhouse_plugin-0.5.1-py3-none-any.whl"}, {"comment_text": "", "digests": {"md5": "1e1c7ff5d34aa1b2263463741157803e", "sha256": "358a3241abeafd2bbf571769512a21d2fceccaf883cf56925f2f81982a63e523"}, "downloads": -1, "filename": "airflow-clickhouse-plugin-0.5.1.tar.gz", "has_sig": false, "md5_digest": "1e1c7ff5d34aa1b2263463741157803e", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.*", "size": 6896, "upload_time": "2020-04-03T13:05:01", "upload_time_iso_8601": "2020-04-03T13:05:01.392094Z", "url": "https://files.pythonhosted.org/packages/c1/ac/5bfb4c485742925c0b059b69160fcd49e19e717babd578d55a85715c2404/airflow-clickhouse-plugin-0.5.1.tar.gz"}], "0.5.2": [{"comment_text": "", "digests": {"md5": "4187703c0fdd05c5df813ee76b307213", "sha256": "5ea4c2d611d66be940ba486dfa3ede8f01e26a0e6e8513d66cb60d1e52cf5d3e"}, "downloads": -1, "filename": "airflow_clickhouse_plugin-0.5.2-py3-none-any.whl", "has_sig": false, "md5_digest": "4187703c0fdd05c5df813ee76b307213", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.*", "size": 8301, "upload_time": "2020-04-03T13:16:37", "upload_time_iso_8601": "2020-04-03T13:16:37.118591Z", "url": "https://files.pythonhosted.org/packages/2a/9f/130db071e61bc8426b5cd7f31e1cb9f7ae90edb5cf8d2048de60f0e9350c/airflow_clickhouse_plugin-0.5.2-py3-none-any.whl"}, {"comment_text": "", "digests": {"md5": "3ab4e32e0efbdaa5f8cfabf79c1e9927", "sha256": "0d63391519fefd474acc485cbde3a6986756154dafcce6884c4dce87791696de"}, "downloads": -1, "filename": "airflow-clickhouse-plugin-0.5.2.tar.gz", "has_sig": false, "md5_digest": "3ab4e32e0efbdaa5f8cfabf79c1e9927", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.*", "size": 7023, "upload_time": "2020-04-03T13:16:38", "upload_time_iso_8601": "2020-04-03T13:16:38.101857Z", "url": "https://files.pythonhosted.org/packages/ee/97/7f6cd4c87b0c3691be180fea0b693fb2cab2474b99a1ee490d59f7176452/airflow-clickhouse-plugin-0.5.2.tar.gz"}]}, "urls": [{"comment_text": "", "digests": {"md5": "4187703c0fdd05c5df813ee76b307213", "sha256": "5ea4c2d611d66be940ba486dfa3ede8f01e26a0e6e8513d66cb60d1e52cf5d3e"}, "downloads": -1, "filename": "airflow_clickhouse_plugin-0.5.2-py3-none-any.whl", "has_sig": false, "md5_digest": "4187703c0fdd05c5df813ee76b307213", "packagetype": "bdist_wheel", "python_version": "py3", "requires_python": ">=3.6.*", "size": 8301, "upload_time": "2020-04-03T13:16:37", "upload_time_iso_8601": "2020-04-03T13:16:37.118591Z", "url": "https://files.pythonhosted.org/packages/2a/9f/130db071e61bc8426b5cd7f31e1cb9f7ae90edb5cf8d2048de60f0e9350c/airflow_clickhouse_plugin-0.5.2-py3-none-any.whl"}, {"comment_text": "", "digests": {"md5": "3ab4e32e0efbdaa5f8cfabf79c1e9927", "sha256": "0d63391519fefd474acc485cbde3a6986756154dafcce6884c4dce87791696de"}, "downloads": -1, "filename": "airflow-clickhouse-plugin-0.5.2.tar.gz", "has_sig": false, "md5_digest": "3ab4e32e0efbdaa5f8cfabf79c1e9927", "packagetype": "sdist", "python_version": "source", "requires_python": ">=3.6.*", "size": 7023, "upload_time": "2020-04-03T13:16:38", "upload_time_iso_8601": "2020-04-03T13:16:38.101857Z", "url": "https://files.pythonhosted.org/packages/ee/97/7f6cd4c87b0c3691be180fea0b693fb2cab2474b99a1ee490d59f7176452/airflow-clickhouse-plugin-0.5.2.tar.gz"}]}