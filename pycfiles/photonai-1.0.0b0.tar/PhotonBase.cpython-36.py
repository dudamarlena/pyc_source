# uncompyle6 version 3.7.4
# Python bytecode 3.6 (3379)
# Decompiled from: Python 3.6.9 (default, Apr 18 2020, 01:56:04) 
# [GCC 8.4.0]
# Embedded file name: /home/nwinter/PycharmProjects/photon_projects/photon_core/photonai/base/PhotonBase.py
# Compiled at: 2019-09-03 11:58:55
# Size of source mod 2**32: 109023 bytes
import warnings, glob, importlib.util, inspect, os, traceback, re, zipfile, importlib, __main__, shutil, datetime, pandas as pd
from collections import OrderedDict
from copy import deepcopy
from bson.objectid import ObjectId
from sklearn.base import BaseEstimator
from sklearn.externals import joblib
from sklearn.metrics import accuracy_score
from sklearn.dummy import DummyClassifier, DummyRegressor
from sklearn.model_selection._search import ParameterGrid
from sklearn.model_selection._split import BaseCrossValidator
from .PhotonFolds import OuterFoldManager, FoldInfo
from ..photonlogger.Logger import Logger
from .Helper import PHOTONPrintHelper, PHOTONDataHelper
from ..optimization.ConfigGrid import create_global_config_dict, create_global_config_grid
from ..configuration.Register import PhotonRegister
from ..optimization.OptimizationStrategies import GridSearchOptimizer, RandomGridSearchOptimizer, TimeBoxedRandomGridSearchOptimizer
from ..optimization.SkOpt import SkOptOptimizer
from ..optimization.Hyperparameters import FloatRange, IntegerRange, Categorical, BooleanSwitch
from ..validation.ResultsDatabase import *
from ..validation.ResultsHandler import ResultsHandler
from ..validation.Validate import Scorer
from .PhotonPipeline import PhotonPipeline, CacheManager
from ..validation.Validate import TestPipeline
warnings.filterwarnings('ignore', category=DeprecationWarning)
warnings.filterwarnings('ignore', category=FutureWarning)

class PhotonNative:
    __doc__ = 'only for checking if code is meeting requirements'


class OutputSettings:
    __doc__ = "\n    Configuration class that specifies the format in which the results are saved. Results can be saved to a MongoDB\n    or a simple son-file. You can also choose whether to save predictions and/or feature importances.\n\n    Parameters\n    ----------\n    * `mongodb_connect_url` [str]:\n        Valid mongodb connection url that specifies a database for storing the results\n\n    * `save_predictions` [str, default='best']:\n        Possible options are 'best' to save only the predictions of the best configuration for every outer fold, 'all'\n        to save all predictions or 'None' to not save any predictions at all.\n\n    * `save_feature_importances` [str, default='best']:\n        Possible options are 'best' to save only the feature importances of the best configuration for every outer fold,\n        'all' to save all feature importances or 'None' to not save any at all. Feature importances can only be saved\n        if the chosen estimators have an attribute 'coef_' or 'feature_importances_'.\n\n    * `project_folder` [bool, default=True]:\n        If True, PHOTON writes a summary_file, the results of the hyperparameter optimization, the best model and the\n        console output to the filesystem into the given project folder.\n\n    * `project_folder` [str, default='']:\n        The output folder in which all files generated by the PHOTON project are saved to.\n\n    * `user_id` [str]:\n       The user name of the according PHOTON Wizard login\n\n    * `wizard_object_id` [str]:\n       The object id to map the designed pipeline in the PHOTON Wizard to the results in the PHOTON CORE Database\n\n    * `wizard_project_name` [str]:\n       How the project is titled in the PHOTON Wizard\n    "

    def __init__(self, mongodb_connect_url: str=None, save_predictions: str='best', save_feature_importances: str='best', save_output: bool=True, plots: bool=True, overwrite_results: bool=False, project_folder='', user_id: str='', wizard_object_id: str='', wizard_project_name: str=''):
        self.mongodb_connect_url = mongodb_connect_url
        self.overwrite_results = overwrite_results
        self.save_best_config_predictions, self.save_predictions = self._set_save_options(save_predictions)
        self.save_best_config_feature_importances, self.save_feature_importances = self._set_save_options(save_feature_importances)
        self.__main_file__ = __main__.__file__
        if project_folder == '':
            self.project_folder = os.path.dirname(self.__main_file__)
        else:
            self.project_folder = project_folder
        self.results_folder = None
        self.log_file = os.path.join(self.project_folder, 'photon_output.log')
        self.save_output = save_output
        self.plots = plots
        self.save_predictions_from_best_config_inner_folds = False
        self.user_id = user_id
        self.wizard_object_id = wizard_object_id
        self.wizard_project_name = wizard_project_name

    def _set_save_options(self, specifier):
        if specifier == 'best':
            save_best = True
            save_all = False
        else:
            if specifier == 'all':
                save_best = True
                save_all = True
            else:
                if specifier == 'None':
                    save_best = False
                    save_all = False
                else:
                    raise ValueError('Possible options for saving predictions or feature importances are: "best", "all", "None"')
        return (
         save_best, save_all)

    def _update_settings(self, name, timestamp):
        if self.save_output:
            if self.overwrite_results:
                self.results_folder = os.path.join(self.project_folder, name + '_results')
            else:
                self.results_folder = os.path.join(self.project_folder, name + '_results_' + timestamp)
            if not os.path.exists(self.results_folder):
                os.makedirs(self.results_folder)
            shutil.copy(self.__main_file__, os.path.join(self.results_folder, 'photon_code.py'))
            self.log_file = self._add_timestamp(self.log_file)
            Logger().set_custom_log_file(self.log_file)

    def _add_timestamp(self, file):
        return os.path.join(self.results_folder, os.path.basename(file))


class Hyperpipe(BaseEstimator):
    __doc__ = '\n    Wrapper class for machine learning pipeline, holding all pipeline elements\n    and managing the optimization of the hyperparameters\n\n    Parameters\n    ----------\n    * `name` [str]:\n        Name of hyperpipe instance\n\n    * `inner_cv` [BaseCrossValidator]:\n        Cross validation strategy to test hyperparameter configurations, generates the validation set\n\n    * `outer_cv` [BaseCrossValidator]:\n        Cross validation strategy to use for the hyperparameter search itself, generates the test set\n\n    * `optimizer` [str or object, default="grid_search"]:\n        Hyperparameter optimization algorithm\n\n        - In case a string literal is given:\n            - "grid_search": optimizer that iteratively tests all possible hyperparameter combinations\n            - "random_grid_search": a variation of the grid search optimization that randomly picks hyperparameter\n               combinations from all possible hyperparameter combinations\n            - "timeboxed_random_grid_search": randomly chooses hyperparameter combinations from the set of all\n               possible hyperparameter combinations and tests until the given time limit is reached\n               - `limit_in_minutes`: int\n\n        - In case an object is given:\n          expects the object to have the following methods:\n           - `next_config_generator`: returns a hyperparameter configuration in form of an dictionary containing\n              key->value pairs in the sklearn parameter encoding `model_name__parameter_name: parameter_value`\n           - `prepare`: takes a list of pipeline elements and their particular hyperparameters to test\n           - `evaluate_recent_performance`: gets a tested config and the respective performance in order to\n              calculate a smart next configuration to process\n\n    * `metrics` [list of metric names as str]:\n        Metrics that should be calculated for both training, validation and test set\n        Use the preimported metrics from sklearn and photonai, or register your own\n\n        - Metrics for `classification`:\n            - `accuracy`: sklearn.metrics.accuracy_score\n            - `matthews_corrcoef`: sklearn.metrics.matthews_corrcoef\n            - `confusion_matrix`: sklearn.metrics.confusion_matrix,\n            - `f1_score`: sklearn.metrics.f1_score\n            - `hamming_loss`: sklearn.metrics.hamming_loss\n            - `log_loss`: sklearn.metrics.log_loss\n            - `precision`: sklearn.metrics.precision_score\n            - `recall`: sklearn.metrics.recall_score\n        - Metrics for `regression`:\n            - `mean_squared_error`: sklearn.metrics.mean_squared_error\n            - `mean_absolute_error`: sklearn.metrics.mean_absolute_error\n            - `explained_variance`: sklearn.metrics.explained_variance_score\n            - `r2`: sklearn.metrics.r2_score\n        - Other metrics\n            - `pearson_correlation`: photon_core.framework.Metrics.pearson_correlation\n            - `variance_explained`:  photon_core.framework.Metrics.variance_explained_score\n            - `categorical_accuracy`: photon_core.framework.Metrics.categorical_accuracy_score\n\n    * `best_config_metric` [str]:\n        The metric that should be maximized or minimized in order to choose the best hyperparameter configuration\n\n    * `eval_final_performance` [bool, default=True]:\n        If the metrics should be calculated for the test set, otherwise the test set is seperated but not used\n\n    * `test_size` [float, default=0.2]:\n        the amount of the data that should be left out if no outer_cv is given and\n        eval_final_perfomance is set to True\n\n    * `set_random_seed` [bool, default=False]:\n        If True sets the random seed to 42\n\n    * `verbosity` [int, default=0]:\n        The level of verbosity, 0 is least talkative and gives only warn and error, 1 gives adds info and 2 adds debug\n\n    * `groups` [array-like, default=None]:\n        Info for advanced cross validation strategies, such as LeaveOneSiteOut-CV about the affiliation\n        of the rows in the data. Also works with continuous values and StratifiedKFoldRegression. In case a group\n        variable and a StratifiedCV is passed, the targets will be ignored and only the group variable will be used\n        for the stratification.\n\n    Attributes\n    ----------\n    * `optimum_pipe` [Pipeline]:\n        An sklearn pipeline object that is fitted to the training data according to the best hyperparameter\n        configuration found. Currently, we don\'t create an ensemble of all best hyperparameter configs over all folds.\n        We find the best config by comparing the test error across outer folds. The hyperparameter config of the best\n        fold is used as the optimal model and is then trained on the complete set.\n\n    * `best_config` [dict]:\n        Dictionary containing the hyperparameters of the best configuration.\n        Contains the parameters in the sklearn interface of model_name__parameter_name: parameter value\n\n    * `results` [MDBHyperpipe]:\n        Object containing all information about the for the performed hyperparameter search.\n        Holds the training and test metrics for all outer folds, inner folds and configurations, as well as\n        additional information.\n\n    * `elements` [list]:\n        Contains all PipelineElement or Hyperpipe objects that are added to the pipeline.\n\n    Example\n    -------\n        manager = Hyperpipe(\'test_manager\',\n                            optimizer=\'timeboxed_random_grid_search\', optimizer_params={\'limit_in_minutes\': 1},\n                            outer_cv=ShuffleSplit(test_size=0.2, n_splits=1),\n                            inner_cv=KFold(n_splits=10, shuffle=True),\n                            metrics=[\'accuracy\', \'precision\', \'recall\', "f1_score"],\n                            best_config_metric=\'accuracy\', eval_final_performance=True,\n                            verbose=2)\n\n   '

    def __init__(self, name, inner_cv: BaseCrossValidator, outer_cv=None, optimizer='grid_search', optimizer_params: dict={}, metrics=None, best_config_metric=None, eval_final_performance=True, test_size: float=0.2, calculate_metrics_per_fold: bool=True, calculate_metrics_across_folds: bool=False, set_random_seed: bool=False, verbosity=0, output_settings=None, performance_constraints=None, permutation_id: str=None, cache_folder: str=None, custom_elements_folder: str=None):
        self.name = re.sub('\\W+', '', name)
        self.permutation_id = permutation_id
        if cache_folder:
            self.cache_folder = os.path.join(cache_folder, self.name)
        else:
            self.cache_folder = None
        if not calculate_metrics_across_folds:
            if not calculate_metrics_per_fold:
                raise NotImplementedError("Apparently, you've set calculate_metrics_across_folds=False and calculate_metrics_per_fold=False. In this case PHOTON does not calculate any metrics which doesn't make any sense. Set at least one to True.")
        else:
            self.cross_validation = Hyperpipe.CrossValidation(inner_cv=inner_cv, outer_cv=outer_cv,
              eval_final_performance=eval_final_performance,
              test_size=test_size,
              calculate_metrics_per_fold=calculate_metrics_per_fold,
              calculate_metrics_across_folds=calculate_metrics_across_folds)
            self.data = Hyperpipe.Data()
            if output_settings:
                self.output_settings = output_settings
            else:
                self.output_settings = OutputSettings()
        self.verbosity = verbosity
        self.results_handler = None
        self.results = None
        self.best_config = None
        self.estimation_type = None
        self.elements = []
        self._pipe = None
        self.optimum_pipe = None
        self.preprocessing = None
        self.optimization = Hyperpipe.Optimization(metrics=metrics, best_config_metric=best_config_metric,
          optimizer_input=optimizer,
          optimizer_params=optimizer_params,
          performance_constraints=performance_constraints)
        self.optimization.sanity_check_metrics()
        register = PhotonRegister()
        if custom_elements_folder:
            register.load_custom_folder(custom_elements_folder=custom_elements_folder)
            PipelineElement.ELEMENT_DICTIONARY = PhotonRegister().get_package_info()
        self.is_final_fit = False
        if set_random_seed:
            import random
            random.seed(42)
            print('set random seed to 42')

    class CrossValidation:

        def __init__(self, inner_cv, outer_cv, eval_final_performance, test_size, calculate_metrics_per_fold, calculate_metrics_across_folds):
            self.inner_cv = inner_cv
            self.outer_cv = outer_cv
            self.eval_final_performance = eval_final_performance
            self.test_size = test_size
            self.calculate_metrics_per_fold = calculate_metrics_per_fold
            self.calculate_metrics_across_folds = calculate_metrics_across_folds
            self.outer_folds = None
            self.inner_folds = dict()

    class Data:

        def __init__(self, X=None, y=None, kwargs=None, groups=None):
            self.X = X
            self.y = y
            self.kwargs = kwargs
            self.groups = groups

    class Optimization:
        OPTIMIZER_DICTIONARY = {'grid_search':GridSearchOptimizer, 
         'random_grid_search':RandomGridSearchOptimizer, 
         'timeboxed_random_grid_search':TimeBoxedRandomGridSearchOptimizer, 
         'sk_opt':SkOptOptimizer}

        def __init__(self, optimizer_input, optimizer_params, metrics, best_config_metric, performance_constraints):
            self.optimizer_input = optimizer_input
            self.optimizer_params = optimizer_params
            self.metrics = metrics
            self.best_config_metric = best_config_metric
            self.maximize_metric = True
            self.inner_cv_callback_functions = performance_constraints

        def sanity_check_metrics(self):
            if isinstance(self.best_config_metric, list) or not isinstance(self.best_config_metric, str):
                if self.metrics is not None:
                    warning_text = 'Best Config Metric must be a single metric given as string, no list. PHOTON chose the first one from the list of metrics to calculate.'
                    self.best_config_metric = self.metrics[0]
                    Logger().warn(warning_text)
                    raise Warning(warning_text)
                else:
                    error_msg = 'No metrics were chosen. Please choose metrics to quantify your performance and set the best_config_metric so that PHOTON which optimizes for'
                    Logger().error(error_msg)
                    raise ValueError(error_msg)
                if self.best_config_metric is not None:
                    if self.metrics is None:
                        self.metrics = [
                         self.best_config_metric]
                    elif self.best_config_metric not in self.metrics:
                        self.metrics.append(self.best_config_metric)
                if self.best_config_metric is None and len(self.metrics) > 0:
                    self.best_config_metric = self.metrics[0]
                    warning_text = 'No best config metric was given, so PHOTON chose the first in the list of metrics as criteria for choosing the best configuration.'
                    Logger().warn(warning_text)
                    raise Warning(warning_text)
            elif self.metrics is None or len(self.metrics) == 0:
                metric_error_text = 'List of Metrics to calculate should not be empty'
                Logger().error(metric_error_text)
                raise ValueError(metric_error_text)

        def get_optimizer(self):
            if isinstance(self.optimizer_input, str):
                optimizer_class = self.OPTIMIZER_DICTIONARY[self.optimizer_input]
                optimizer_instance = optimizer_class(**self.optimizer_params)
                return optimizer_instance
            else:
                return self.optimizer_input

        def get_optimum_config(self, tested_configs):
            """
            Looks for the best configuration according to the metric with which the configurations are compared -> best config metric
            :param tested_configs: the list of tested configurations and their performances
            :return: MDBConfiguration that has performed best
            """
            list_of_config_vals = []
            list_of_non_failed_configs = [conf for conf in tested_configs if not conf.config_failed]
            if len(list_of_non_failed_configs) == 0:
                raise Warning('No Configs found which did not fail.')
            try:
                if len(list_of_non_failed_configs) == 1:
                    best_config_outer_fold = list_of_non_failed_configs[0]
                else:
                    for config in list_of_non_failed_configs:
                        list_of_config_vals.append(MDBHelper.get_metric(config, (FoldOperations.MEAN), (self.best_config_metric), train=False))

                    if self.maximize_metric:
                        best_config_metric_nr = np.argmax(list_of_config_vals)
                    else:
                        best_config_metric_nr = np.argmin(list_of_config_vals)
                    best_config_outer_fold = list_of_non_failed_configs[best_config_metric_nr]
                Logger().verbose('Number of tested configurations:' + str(len(tested_configs)))
                Logger().verbose('Optimizer metric: ' + self.best_config_metric + '\n' + '   --> Greater is better: ' + str(self.maximize_metric))
                Logger().info('Best config: ' + str(best_config_outer_fold.human_readable_config))
                return best_config_outer_fold
            except BaseException as e:
                Logger().error(str(e))

        def get_optimum_config_outer_folds(self, outer_folds):
            list_of_scores = list()
            for outer_fold in outer_folds:
                metrics = outer_fold.best_config.best_config_score.validation.metrics
                list_of_scores.append(metrics[self.best_config_metric])

            if self.maximize_metric:
                best_config_metric_nr = np.argmax(list_of_scores)
            else:
                best_config_metric_nr = np.argmin(list_of_scores)
            best_config = outer_folds[best_config_metric_nr].best_config
            return best_config

        def define_optimizer_metric(self):
            """
            Analyse and prepare the best config metric.
            Derive if it is better when the value increases or decreases.
            """
            if isinstance(self.best_config_metric, str):
                self.maximize_metric = Scorer.greater_is_better_distinction(self.best_config_metric)

    def _set_verbosity(self, verbosity):
        """
        Set verbosity level manually
        Returns None

        Parameters
        ----------
        * `verbosity` [Integer]:
            Verbosity level can be 0, 1, or 2.

        """
        Logger().set_verbosity(verbosity)

    def _set_persist_options(self, persist_options):
        """
        Set persist options manually
        Returns None

        Parameters
        ----------
        * `persist_options` [OutputSettings]:

        """
        self.output_settings = persist_options

    def __iadd__(self, pipe_element):
        """
        Add an element to the machine learning pipeline
        Returns self

        Parameters
        ----------
        * 'pipe_element' [PipelineElement]:
            The object to add to the machine learning pipeline, being either a transformer or an estimator.

        """
        if isinstance(pipe_element, Preprocessing):
            self.preprocessing = pipe_element
        else:
            if isinstance(pipe_element, CallbackElement):
                pipe_element.needs_y = True
                self.elements.append(pipe_element)
            else:
                if isinstance(pipe_element, PipelineElement) or issubclass(type(pipe_element), PhotonNative):
                    self.elements.append(pipe_element)
                    self._prepare_pipeline()
                else:
                    raise TypeError('Element must be of type Pipeline Element')
        return self

    def add(self, pipe_element):
        """
           Add an element to the machine learning pipeline
           Returns self

           Parameters
           ----------
           * `pipe_element` [PipelineElement or Hyperpipe]:
               The object to add to the machine learning pipeline, being either a transformer or an estimator.

           """
        self.__iadd__(pipe_element)

    def _prepare_dummy_estimator(self):
        Logger().info('Running Dummy Estimator.')
        est_type = self.estimation_type
        self.results.dummy_estimator = DummyResults()
        if est_type == 'regressor':
            self.results.dummy_estimator.strategy = 'mean'
            return DummyRegressor(strategy=(self.results.dummy_estimator.strategy))
        else:
            if est_type == 'classifier':
                self.results.dummy_estimator.strategy = 'most_frequent'
                return DummyClassifier(strategy=(self.results.dummy_estimator.strategy))
            Logger().info('Estimator does not specify whether it is a regressor or classifier. DummyEstimator step skipped.')
            return

    def _evaluate_dummy_estimator(self, fold_list):
        config_item = MDBConfig()
        config_item.inner_folds = [f for f in fold_list if f is not None]
        if len(config_item.inner_folds) > 0:
            self.results.dummy_estimator.train, self.results.dummy_estimator.test = MDBHelper.aggregate_metrics(config_item, self.optimization.metrics)

    def _prepare_result_logging(self, start_time):
        results_object_name = self.name
        self.results = MDBHyperpipe(name=results_object_name)
        self.results.hyperpipe_info = MDBHyperpipeInfo()
        if not self.cross_validation.eval_final_performance:
            self.output_settings.save_predictions_from_best_config_inner_folds = True
        self.results_handler = ResultsHandler(self.results, self.output_settings)
        self.results.computation_start_time = start_time
        self.results.hyperpipe_info.estimation_type = self.estimation_type
        if self.permutation_id is not None:
            self.results.permutation_id = self.permutation_id
        if self.output_settings:
            if hasattr(self.output_settings, 'wizard_object_id'):
                if self.output_settings.wizard_object_id:
                    self.name = self.output_settings.wizard_object_id
                    self.results.name = self.output_settings.wizard_object_id
                    self.results.wizard_object_id = ObjectId(self.output_settings.wizard_object_id)
                    self.results.wizard_system_name = self.output_settings.wizard_project_name
                    self.results.user_id = self.output_settings.user_id
        self.results.outer_folds = []
        self.results.hyperpipe_info.eval_final_performance = self.cross_validation.eval_final_performance
        self.results.hyperpipe_info.best_config_metric = self.optimization.best_config_metric
        self.results.hyperpipe_info.metrics = self.optimization.metrics

        def _format_cross_validation(cv):
            if cv:
                string = '{}('.format(cv.__class__.__name__)
                for key, val in cv.__dict__.items():
                    string += '{}={}, '.format(key, val)

                return string[:-2] + ')'
            else:
                return 'None'

        self.results.hyperpipe_info.cross_validation = {'OuterCV':_format_cross_validation(self.cross_validation.outer_cv),  'InnerCV':_format_cross_validation(self.cross_validation.inner_cv)}
        self.results.hyperpipe_info.data = {'X.shape':self.data.X.shape,  'y.shape':self.data.y.shape}
        self.results.hyperpipe_info.optimization = {'Optimizer':self.optimization.optimizer_input,  'OptimizerParams':str(self.optimization.optimizer_params), 
         'BestConfigMetric':self.optimization.best_config_metric}
        try:
            flowchart = FlowchartCreator(self.elements)
            self.results.hyperpipe_info.flowchart = flowchart.create_str()
        except:
            self.results.hyperpipe_info.flowchart = ''

    def _finalize_optimization(self):
        self.results.metrics_train, self.results.metrics_test = MDBHelper.aggregate_metrics(self.results.outer_folds, self.optimization.metrics)
        Logger().info('Finished hyperparameter optimization!')
        self.results_handler.save()
        self.best_config = self.optimization.get_optimum_config_outer_folds(self.results.outer_folds)
        self.results.best_config = self.best_config
        Logger().info('OVERALL BEST CONFIGURATION')
        Logger().info('--------------------------')
        Logger().info(self.best_config.human_readable_config)
        self.results.time_of_results = datetime.datetime.now()
        self.results.computation_completed = True
        self.results_handler.save()
        Logger().info('Saved overall best config to database ')
        self.results_handler.write_convenience_files()
        self.optimum_pipe = self._pipe
        (self.optimum_pipe.set_params)(**(self.best_config).config_dict)
        self.recursive_cache_folder_propagation(self.optimum_pipe, self.cache_folder, 'fixed_fold_id')
        self.optimum_pipe.caching = False
        if self.output_settings.save_best_config_feature_importances:
            self.disable_multiprocessing_recursively(self.optimum_pipe)
        else:
            Logger().info('Fitting best model...')
            (self.optimum_pipe.fit)((self.data.X), (self.data.y), **(self.data).kwargs)
            self.optimum_pipe._add_preprocessing(self.preprocessing)
            self.recursive_cache_folder_propagation(self.optimum_pipe, None, None)
            if self.output_settings.save_output:
                Logger().info('Saving best model...')
                try:
                    pretrained_model_filename = os.path.join(self.output_settings.results_folder, 'photon_best_model.photon')
                    PhotonModelPersistor.save_optimum_pipe(self, pretrained_model_filename)
                    Logger().info('Saved optimum pipe model to file')
                except FileNotFoundError as e:
                    Logger().info('Could not save optimum pipe model to file')
                    Logger().error(str(e))

            if self.output_settings.save_best_config_feature_importances:
                if self.output_settings.save_output:
                    Logger().info('Mapping back feature importances...')
                    feature_importances = TestPipeline.extract_feature_importances(self.optimum_pipe)
                    if not feature_importances:
                        Logger().info('No feature importances available for {}!'.format(self.optimum_pipe.elements[(-1)][0]))
                        return
                    self.results.best_config_feature_importances = feature_importances
                    backmapping, _, _ = self.optimum_pipe.inverse_transform(feature_importances, None)
                    self.results_handler.save_backmapping(filename='optimum_pipe_feature_importances_backmapped', backmapping=backmapping)

    @staticmethod
    def disable_multiprocessing_recursively(pipe):
        if isinstance(pipe, (Stack, Branch, Switch, Preprocessing)):
            if hasattr(pipe, 'nr_of_processes'):
                pipe.nr_of_processes = 1
            for child in pipe.elements:
                Hyperpipe.disable_multiprocessing_recursively(child.base_element)

        else:
            if isinstance(pipe, PhotonPipeline):
                for name, child in pipe.named_steps.items():
                    Hyperpipe.disable_multiprocessing_recursively(child)

            elif hasattr(pipe, 'nr_of_processes'):
                pipe.nr_of_processes = 1

    def _input_data_sanity_checks(self, data, targets, **kwargs):
        self.data.X = data
        self.data.y = targets
        self.data.kwargs = kwargs
        try:
            if self.data.X is None:
                raise ValueError('(Input-)data is a NoneType.')
            else:
                if self.data.y is None:
                    raise ValueError('(Input-)target is a NoneType.')
                shape_X = np.shape(self.data.X)
                shape_y = np.shape(self.data.y)
                if len(shape_y) != 1:
                    raise ValueError('Target is not one-dimensional.')
                raise shape_X[0] == shape_y[0] or IndexError('Size of targets mismatch to the size of the data: ' + str(shape_X[0]) + ' - ' + str(shape_y[0]))
        except IndexError as ie:
            Logger().error('IndexError: ' + str(ie))
            raise ie
        except ValueError as ve:
            Logger().error('ValueError: ' + str(ve))
            raise ve
        except Exception as e:
            Logger().error('Error: ' + str(e))
            raise e

        if isinstance(self.data.X, list):
            self.data.X = np.asarray(self.data.X)
        else:
            if isinstance(self.data.X, pd.DataFrame):
                self.data.X = self.data.X.to_numpy()
            if isinstance(self.data.y, list):
                self.data.y = np.asarray(self.data.y)
            elif isinstance(self.data.y, pd.Series) or isinstance(self.data.y, pd.DataFrame):
                self.data.y = self.data.y.to_numpy()
        try:
            nans_in_y = np.isnan(self.data.y)
            nr_of_nans = len(np.where(nans_in_y == 1)[0])
            if nr_of_nans > 0:
                Logger().info('You have ' + str(nr_of_nans) + ' Nans in your target vector, PHOTON erases every data item that has a Nan Target')
                self.data.X = self.data.X[(~nans_in_y)]
                self.data.y = self.data.y[(~nans_in_y)]
        except Exception as e:
            Logger().error('Removing Nans in target vector failed: ' + str(e))

        Logger().info('Hyperpipe is training with ' + str(self.data.y.shape[0]) + ' samples.')

    @staticmethod
    def prepare_caching(cache_folder):
        if cache_folder:
            if not os.path.isdir(cache_folder):
                os.makedirs(cache_folder, exist_ok=True)

    @staticmethod
    def recursive_cache_folder_propagation(element, cache_folder, inner_fold_id):
        if isinstance(element, (Switch, Stack, Preprocessing)):
            for child in element.elements:
                Hyperpipe.recursive_cache_folder_propagation(child.base_element, cache_folder, inner_fold_id)

        else:
            if isinstance(element, Branch):
                if cache_folder:
                    cache_folder = os.path.join(cache_folder, element.name)
                Hyperpipe.recursive_cache_folder_propagation(element.base_element, cache_folder, inner_fold_id)
                Hyperpipe.prepare_caching(element.base_element.cache_folder)
            elif isinstance(element, PhotonPipeline):
                element.fold_id = inner_fold_id
                element.cache_folder = cache_folder
                for name, child in element.named_steps.items():
                    Hyperpipe.recursive_cache_folder_propagation(child, cache_folder, inner_fold_id)

    def preprocess_data(self):
        if self.preprocessing is not None:
            Logger().info('Applying preprocessing.')
            (self.preprocessing.fit)((self.data.X), (self.data.y), **(self.data).kwargs)
            self.data.X, self.data.y, self.data.kwargs = (self.preprocessing.transform)((self.data.X), (self.data.y), **(self.data).kwargs)

    def _check_for_estimator(self, last_element=None):
        if not last_element:
            last_element = self.elements[(-1)]
        if isinstance(last_element, (Switch, Stack, Branch)):
            self._check_for_estimator(last_element.elements[(-1)])
        else:
            if not hasattr(last_element.base_element, '_estimator_type'):
                raise NotImplementedError("Last pipeline element has to be an estimator. Your estimator does not specify whether it is a regressor or classifier. Make sure to inherit from sklearn's ClassifierMixin or RegressorMixin or set _estimator_type explicitly.")
            estimator_type = last_element.base_element._estimator_type
            last_name = last_element.name
            self.estimation_type = estimator_type
        if not (estimator_type == 'classifier' or estimator_type == 'regressor'):
            raise NotImplementedError('Last pipeline element has to be an estimator. {} is a {}.'.format(last_name, estimator_type))

    def fit(self, data, targets, **kwargs):
        """
        Starts the hyperparameter search and/or fits the pipeline to the data and targets

        Manages the nested cross validated hyperparameter search:

        1. Filters the data according to filter strategy (1) and according to the imbalanced_data_strategy (2)
        2. requests new configurations from the hyperparameter search strategy, the optimizer,
        3. initializes the testing of a specific configuration,
        4. communicates the result to the optimizer,
        5. repeats 2-4 until optimizer delivers no more configurations to test
        6. finally searches for the best config in all tested configs,
        7. trains the pipeline with the best config and evaluates the performance on the test set

        Parameters
        ----------
         * `data` [array-like, shape=[N, D]]:
            the training and test data, where N is the number of samples and D is the number of features.

         * `targets` [array-like, shape=[N]]:
            the truth values, where N is the number of samples.

        Returns
        -------
         * 'self'
            Returns self

        """
        try:
            (self._input_data_sanity_checks)(data, targets, **kwargs)
            self._check_for_estimator()
            self.preprocess_data()
            Logger().set_verbosity(self.verbosity)
            if not self.is_final_fit:
                self.optimization.define_optimizer_metric()
                start = datetime.datetime.now()
                self._prepare_result_logging(start)
                self.output_settings._update_settings(self.name, start.strftime('%Y-%m-%d_%H-%M-%S'))
                outer_folds = FoldInfo.generate_folds(self.cross_validation.outer_cv, self.data.X, self.data.y, self.data.groups, self.cross_validation.eval_final_performance, self.cross_validation.test_size)
                self.cross_validation.outer_folds = {f.fold_id:f for f in outer_folds}
                dummy_estimator = self._prepare_dummy_estimator()
                dummy_results = []
                if self.cache_folder is not None:
                    Logger().info('Removing Cache Files')
                    CacheManager.clear_cache_files((self.cache_folder), force_all=True)
                for i, outer_f in enumerate(outer_folds):
                    Logger().info('HYPERPARAMETER SEARCH OF {0}, Outer Cross validation Fold {1}'.format(self.name, outer_f.fold_nr))
                    outer_fold_computer = OuterFoldManager((self._copy_pipeline), (self.optimization),
                      (outer_f.fold_id),
                      (self.cross_validation),
                      save_feature_importances=(self.output_settings.save_feature_importances),
                      save_predictions=(self.output_settings.save_predictions),
                      save_best_config_feature_importances=(self.output_settings.save_best_config_feature_importances),
                      save_best_config_predictions=(self.output_settings.save_best_config_predictions),
                      cache_folder=(self.cache_folder),
                      cache_updater=(self.recursive_cache_folder_propagation))
                    outer_fold = MDBOuterFold(fold_nr=(outer_f.fold_nr))
                    self.results.outer_folds.append(outer_fold)
                    outer_fold_computer.prepare_optimization(self.elements, outer_fold)
                    dummy_results.append(outer_fold_computer.fit_dummy(self.data.X, self.data.y, dummy_estimator))
                    try:
                        (outer_fold_computer.fit)((self.data.X), (self.data.y), **(self.data).kwargs)
                        self.results_handler.save()
                    finally:
                        CacheManager.clear_cache_files(self.cache_folder)

                self._evaluate_dummy_estimator(dummy_results)
                self._finalize_optimization()
                CacheManager.clear_cache_files((self.cache_folder), force_all=True)
            else:
                self.preprocess_data()
                (self._pipe.fit)((self.data.X), (self.data.y), **kwargs)
        except Exception as e:
            Logger().error(e)
            Logger().error(traceback.format_exc())
            traceback.print_exc()
            raise e

        return self

    def predict(self, data, **kwargs):
        """
        Use the optimum pipe to predict the data

        Returns
        -------
            predicted targets

        """
        if self._pipe:
            return (self.optimum_pipe.predict)(data, **kwargs)

    def predict_proba(self, data, **kwargs):
        """
        Predict probabilities

        Returns
        -------
        predicted probabilities

        """
        if self._pipe:
            return (self.optimum_pipe.predict_proba)(data, **kwargs)

    def transform(self, data, **kwargs):
        """
        Use the optimum pipe to transform the data
        """
        if self._pipe:
            X, _, _ = (self.optimum_pipe.transform)(data, y=None, **kwargs)
            return X

    def get_params(self, deep=True):
        """
        Retrieve parameters from sklearn pipeline
        """
        if self._pipe is not None:
            return self._pipe.get_params(deep)
        else:
            return

    def set_params(self, **params):
        """
        Give parameter values to the pipeline elements
        """
        if self._pipe is not None:
            (self._pipe.set_params)(**params)
        return self

    def _prepare_pipeline(self):
        """
        build sklearn pipeline from PipelineElements and
        calculate parameter grid for all combinations of pipeline element hyperparameters
        """
        pipeline_steps = []
        for item in self.elements:
            pipeline_steps.append((item.name, item))

        self._pipe = PhotonPipeline(pipeline_steps)

    def copy_me(self):
        """
        Helper function to copy an entire Hyperpipe
        :return: Hyperpipe
        """
        pipe_copy = Hyperpipe(name=(self.name), inner_cv=(self.cross_validation.inner_cv), best_config_metric=(self.optimization.best_config_metric),
          metrics=(self.optimization.metrics))
        signature = inspect.getfullargspec(self.__init__)[0]
        for attr in signature:
            if hasattr(self, attr):
                setattr(pipe_copy, attr, getattr(self, attr))

        if hasattr(self, 'preprocessing'):
            if self.preprocessing:
                preprocessing = Preprocessing()
                for element in self.preprocessing.pipeline_elements:
                    preprocessing += element.copy_me()

                pipe_copy += preprocessing
        if hasattr(self, 'elements'):
            for element in self.elements:
                pipe_copy += element.copy_me()

        return pipe_copy

    def _copy_pipeline(self):
        """
        Copy Pipeline by building a new sklearn Pipeline with Pipeline Elements

        Returns
        -------
        new sklearn Pipeline object
        """
        pipeline_steps = []
        for item in self.elements:
            cpy = item.copy_me()
            if isinstance(cpy, list):
                for new_step in cpy:
                    pipeline_steps.append((new_step.name, new_step))

            else:
                pipeline_steps.append((cpy.name, cpy))

        new_pipe = PhotonPipeline(pipeline_steps)
        return new_pipe

    def save_optimum_pipe(self, filename=None, password=None):
        if filename is None:
            filename = 'photon_' + self.name + '_best_model.p'
        PhotonModelPersistor.save_optimum_pipe(self, filename, password)

    @staticmethod
    def load_optimum_pipe(file, password=None):
        return PhotonModelPersistor.load_optimum_pipe(file, password)

    def config_to_human_readable_dict(self, specific_config):
        return PHOTONPrintHelper.config_to_human_readable_dict(self._pipe, specific_config)

    def inverse_transform_pipeline(self, hyperparameters: dict, data, targets, data_to_inverse):
        """
        Inverse transform data for a pipeline with specific hyperparameter configuration

        1. Copy Sklearn Pipeline,
        2. Set Parameters
        3. Fit Pipeline to data and targets
        4. Inverse transform data with that pipeline

        Parameters
        ----------
        * `hyperparameters` [dict]:
            The concrete configuration settings for the pipeline elements
        * `data` [array-like]:
            The training data to which the pipeline is fitted
        * `targets` [array-like]:
            The truth values for training
        * `data_to_inverse` [array-like]:
            The data that should be inversed after training

        Returns
        -------
        Inversed data as array
        """
        copied_pipe = self._copy_pipeline()
        (copied_pipe.set_params)(**hyperparameters)
        copied_pipe.fit(data, targets)
        return copied_pipe.inverse_transform(data_to_inverse)


class DataFilter(BaseEstimator):
    __doc__ = '\n    Helper Class to split the data e.g. for stacking.\n    '

    def __init__(self, indices):
        self.name = 'DataFilter'
        self.hyperparameters = {}
        self.indices = indices
        self.needs_covariates = False
        self.needs_y = False

    def fit(self, X, y=None, **kwargs):
        return self

    def transform(self, X, y=None, **kwargs):
        """
        Returns only part of the data, column-wise filtered by self.indices
        """
        return (
         X[:, self.indices], y, kwargs)


class PipelineElement(BaseEstimator):
    __doc__ = '\n    Photon wrapper class for any transformer or predictor element in the pipeline.\n\n    1. Saves the hyperparameters that are to be tested and creates a grid of all hyperparameter configurations\n    2. Enables fast and rapid instantiation of pipeline elements per string identifier,\n         e.g \'svc\' creates an sklearn.svm.SVC object.\n    3. Attaches a "disable" switch to every element in the pipeline in order to test a complete disable\n\n\n    Parameters\n    ----------\n    * `name` [str]:\n       A string literal encoding the class to be instantiated\n    * `hyperparameters` [dict]:\n       Which values/value range should be tested for the hyperparameter.\n       In form of "Hyperparameter_name: [array of parameter values to be tested]"\n    * `test_disabled` [bool]:\n        If the hyperparameter search should evaluate a complete disabling of the element\n    * `disabled` [bool]:\n        If true, the element is currently disabled and does nothing except return the data it received\n    * `kwargs` [dict]:\n        Any parameters that should be passed to the object to be instantiated, default parameters\n\n    '
    ELEMENT_DICTIONARY = PhotonRegister().get_package_info()

    def __init__(self, name, hyperparameters: dict=None, test_disabled: bool=False, disabled: bool=False, base_element=None, batch_size=0, **kwargs):
        """
        Takes a string literal and transforms it into an object of the associated class (see PhotonCore.JSON)

        Returns
        -------
        instantiated class object
        """
        if hyperparameters is None:
            hyperparameters = {}
        else:
            if base_element is None:
                if name in PipelineElement.ELEMENT_DICTIONARY:
                    try:
                        desired_class_info = PipelineElement.ELEMENT_DICTIONARY[name]
                        desired_class_home = desired_class_info[0]
                        desired_class_name = desired_class_info[1]
                        imported_module = importlib.import_module(desired_class_home)
                        desired_class = getattr(imported_module, desired_class_name)
                        self.base_element = desired_class(**kwargs)
                    except AttributeError as ae:
                        Logger().error('ValueError: Could not find according class:' + str(PipelineElement.ELEMENT_DICTIONARY[name]))
                        raise ValueError('Could not find according class:', PipelineElement.ELEMENT_DICTIONARY[name])

                else:
                    Logger().error('Element not supported right now:' + name)
                    raise NameError('Element not supported right now:', name)
            else:
                self.base_element = base_element
            self.is_transformer = hasattr(self.base_element, 'transform')
            self.is_estimator = hasattr(self.base_element, 'predict')
            self.kwargs = kwargs
            self.current_config = None
            self.batch_size = batch_size
            self.name = name
            self.test_disabled = test_disabled
            self._sklearn_disabled = self.name + '__disabled'
            self._hyperparameters = hyperparameters
            self._check_hyper(BaseEstimator)
            if len(hyperparameters) > 0:
                key_0 = next(iter(hyperparameters))
                if self.name not in key_0:
                    self.hyperparameters = hyperparameters
            else:
                self.hyperparameters = hyperparameters
            self.disabled = disabled
            if hasattr(self.base_element, 'needs_y'):
                self.needs_y = self.base_element.needs_y
            else:
                self.needs_y = False
            if hasattr(self.base_element, 'needs_covariates'):
                self.needs_covariates = self.base_element.needs_covariates
            else:
                self.needs_covariates = False

    def _check_hyper(self, BaseEstimator):
        not_supp_hyper = list(set([key.split('__')[(-1)] for key in self._hyperparameters.keys() if key.split('__')[(-1)] != 'disabled']) - set(BaseEstimator.get_params(self.base_element).keys()))
        if not_supp_hyper:
            Logger().error('ValueError: Set of hyperparameters are not valid, check hyperparameters:' + str(not_supp_hyper))
            raise ValueError('ValueError: Set of hyperparameters are not valid, check hyperparameters:' + str(not_supp_hyper))

    def copy_me(self):
        if self.name in self.ELEMENT_DICTIONARY:
            copy = PipelineElement((self.name), (self.hyperparameters), **self.kwargs)
        else:
            copy = (PipelineElement.create)(self.name, self.base_element, hyperparameters=self.hyperparameters, **self.kwargs)
        if self.current_config is not None:
            (copy.set_params)(**self.current_config)
        return copy

    @classmethod
    def create(cls, name, base_element, hyperparameters: dict, test_disabled=False, disabled=False, **kwargs):
        """
        Takes an instantiated object and encapsulates it into the PHOTON structure,
        add the disabled function and attaches information about the hyperparameters that should be tested
        """
        return PipelineElement(name, hyperparameters, test_disabled, disabled, base_element=base_element, **kwargs)

    @property
    def hyperparameters(self):
        return self._hyperparameters

    @hyperparameters.setter
    def hyperparameters(self, value: dict):
        self.generate_sklearn_hyperparameters(value)

    @property
    def feature_importances_(self):
        if hasattr(self.base_element, 'feature_importances_'):
            return self.base_element.feature_importances_

    @property
    def coef_(self):
        if hasattr(self.base_element, 'coef_'):
            return self.base_element.coef_

    def generate_config_grid(self):
        config_dict = create_global_config_dict([self])
        if len(config_dict) > 0:
            if self.test_disabled:
                config_dict.pop(self._sklearn_disabled)
            config_list = list(ParameterGrid(config_dict))
            if self.test_disabled:
                for item in config_list:
                    item[self._sklearn_disabled] = False

                config_list.append({self._sklearn_disabled: True})
                if len(config_list) < 2:
                    config_list.append({self._sklearn_disabled: False})
            return config_list
        else:
            return []

    def generate_sklearn_hyperparameters(self, value: dict):
        """
        Generates a dictionary according to the sklearn convention of element_name__parameter_name: parameter_value
        """
        self._hyperparameters = {}
        for attribute, value_list in value.items():
            self._hyperparameters[self.name + '__' + attribute] = value_list

        if self.test_disabled:
            self._hyperparameters[self._sklearn_disabled] = [
             False, True]

    def get_params(self, deep: bool=True):
        """
        Forwards the get_params request to the wrapped base element
        """
        return self.base_element.get_params(deep)

    def set_params(self, **kwargs):
        """
        Forwards the set_params request to the wrapped base element
        Takes care of the disabled parameter which is additionally attached by the PHOTON wrapper
        """
        self.current_config = kwargs
        if self._sklearn_disabled in kwargs:
            self.disabled = kwargs[self._sklearn_disabled]
            del kwargs[self._sklearn_disabled]
        else:
            if 'disabled' in kwargs:
                self.disabled = kwargs['disabled']
                del kwargs['disabled']
        (self.base_element.set_params)(**kwargs)
        return self

    def fit(self, X, y=None, **kwargs):
        """
        Calls the fit function of the base element

        Returns
        ------
        self
        """
        if not self.disabled:
            obj = self.base_element
            arg_list = inspect.signature(obj.fit)
            if len(arg_list.parameters) > 2:
                vals = arg_list.parameters.values()
                kwargs_param = list(vals)[(-1)]
                if kwargs_param.kind == kwargs_param.VAR_KEYWORD:
                    (obj.fit)(X, y, **kwargs)
                    return self
            obj.fit(X, y)
        return self

    def __batch_predict(self, delegate, X, **kwargs):
        if not isinstance(X, list) and not isinstance(X, np.ndarray):
            Logger().warn('Cannot do batching on a single entity.')
            return delegate(X, **kwargs)
        else:
            processed_y = None
            nr = PHOTONDataHelper.find_n(X)
            batch_idx = 0
            for start, stop in PHOTONDataHelper.chunker(nr, self.batch_size):
                batch_idx += 1
                Logger().debug(self.name + ' is predicting batch nr ' + str(batch_idx))
                X_batched, y_batched, kwargs_dict_batched = PHOTONDataHelper.split_data(X, None, kwargs, start, stop)
                y_pred = delegate(X_batched, **kwargs_dict_batched)
                processed_y = PHOTONDataHelper.stack_results(y_pred, processed_y)

            return processed_y

    def __predict(self, X, **kwargs):
        if not self.disabled:
            if hasattr(self.base_element, 'predict'):
                return (self.adjusted_predict_call)((self.base_element.predict), X, **kwargs)
            Logger().error('BaseException. base Element should have function predict.')
            raise BaseException('base Element should have function predict.')
        else:
            return X

    def predict(self, X, **kwargs):
        """
        Calls predict function on the base element.
        """
        if self.batch_size == 0:
            return (self._PipelineElement__predict)(X, **kwargs)
        else:
            return (self._PipelineElement__batch_predict)((self._PipelineElement__predict), X, **kwargs)

    def predict_proba(self, X, **kwargs):
        if self.batch_size == 0:
            return (self._PipelineElement__predict_proba)(X, **kwargs)
        else:
            return self._PipelineElement__batch_predict((self._PipelineElement__predict_proba)(X, **kwargs))

    def __predict_proba(self, X, **kwargs):
        """
        Predict probabilities
        base element needs predict_proba() function, otherwise throw
        base exception.
        """
        if not self.disabled:
            if hasattr(self.base_element, 'predict_proba'):
                return (self.adjusted_predict_call)((self.base_element.predict_proba), X, **kwargs)
            return
        else:
            return X

    def __transform(self, X, y=None, **kwargs):
        if not self.disabled:
            if hasattr(self.base_element, 'transform'):
                return (self.adjusted_delegate_call)((self.base_element.transform), X, y, **kwargs)
            if hasattr(self.base_element, 'predict'):
                return (
                 (self.predict)(X, **kwargs), y, kwargs)
            Logger().error('BaseException: transform-predict-mess')
            raise BaseException('transform-predict-mess')
        else:
            return (
             X, y, kwargs)

    def transform(self, X, y=None, **kwargs):
        """
        Calls transform on the base element.

        IN CASE THERE IS NO TRANSFORM METHOD, CALLS PREDICT.
        This is used if we are using an estimator as a preprocessing step.
        """
        if self.batch_size == 0:
            return (self._PipelineElement__transform)(X, y, **kwargs)
        else:
            return (self._PipelineElement__batch_transform)(X, y, **kwargs)

    def inverse_transform(self, X, y=None, **kwargs):
        if hasattr(self.base_element, 'inverse_transform'):
            X, y, kwargs = (self.adjusted_delegate_call)((self.base_element.inverse_transform), X, y, **kwargs)
        return (
         X, y, kwargs)

    def __batch_transform(self, X, y=None, **kwargs):
        if not isinstance(X, list) and not isinstance(X, np.ndarray):
            Logger().warn('Cannot do batching on a single entity.')
            return (self._PipelineElement__transform)(X, y, **kwargs)
        else:
            processed_X = None
            processed_y = None
            processed_kwargs = dict()
            nr = PHOTONDataHelper.find_n(X)
            batch_idx = 0
            for start, stop in PHOTONDataHelper.chunker(nr, self.batch_size):
                batch_idx += 1
                Logger().debug(self.name + ' is transforming batch nr ' + str(batch_idx))
                X_batched, y_batched, kwargs_dict_batched = PHOTONDataHelper.split_data(X, y, kwargs, start, stop)
                X_new, y_new, kwargs_new = (self.adjusted_delegate_call)((self.base_element.transform), X_batched, y_batched, **kwargs_dict_batched)
                processed_X, processed_y, processed_kwargs = PHOTONDataHelper.join_data(processed_X, X_new, processed_y, y_new, processed_kwargs, kwargs_new)

            return (processed_X, processed_y, processed_kwargs)

    def adjusted_delegate_call(self, delegate, X, y, **kwargs):
        if self.needs_y:
            if isinstance(self, (Switch, Branch, Preprocessing)):
                X, y, kwargs = delegate(X, y, **kwargs)
            elif y is not None:
                if self.needs_covariates:
                    X, y, kwargs = delegate(X, y, **kwargs)
                else:
                    X, y = delegate(X, y)
        else:
            if self.needs_covariates:
                X, kwargs = delegate(X, **kwargs)
            else:
                X = delegate(X)
        return (
         X, y, kwargs)

    def adjusted_predict_call(self, delegate, X, **kwargs):
        if self.needs_covariates:
            return delegate(X, **kwargs)
        else:
            return delegate(X)

    def score(self, X_test, y_test):
        """
        Calls the score function on the base element:
        Returns a goodness of fit measure or a likelihood of unseen data:
        """
        return self.base_element.score(X_test, y_test)

    def prettify_config_output(self, config_name: str, config_value, return_dict: bool=False):
        """Make hyperparameter combinations human readable """
        if config_name == 'disabled':
            if config_value is False:
                if return_dict:
                    return {'disabled': False}
                else:
                    return 'disabled = False'
        else:
            if return_dict:
                return {config_name: config_value}
            else:
                return config_name + '=' + str(config_value)


class Branch(PipelineElement):
    __doc__ = '\n     A substream of pipeline elements that is encapsulated e.g. for parallelization\n\n     Parameters\n     ----------\n        * `name` [str]:\n            Name of the encapsulated item and/or summary of the encapsulated element`s functions\n\n        '

    def __init__(self, name):
        super().__init__(name, {}, test_disabled=False, disabled=False, base_element=True)
        self.needs_y = True
        self.needs_covariates = True
        self.elements = []
        self.has_hyperparameters = True
        self.skip_caching = True
        self.fix_fold_id = False
        self.do_not_delete_cache_folder = False

    def fit(self, X, y=None, **kwargs):
        return (super().fit)(X, y, **kwargs)

    def transform(self, X, y=None, **kwargs):
        return (super().transform)(X, y, **kwargs)

    def predict(self, X, **kwargs):
        return (super().predict)(X, **kwargs)

    def __iadd__(self, pipe_element):
        """
        Add an element to the sub pipeline
        Returns self

        Parameters
        ----------
        * `pipe_element` [PipelineElement or Hyperpipe]:
            The object to add, being either a transformer or an estimator.

        """
        self.elements.append(pipe_element)
        self._prepare_pipeline()
        return self

    def add(self, pipe_element):
        """
           Add an element to the sub pipeline
           Returns self

           Parameters
           ----------
           * `pipe_element` [PipelineElement or Hyperpipe]:
               The object to add, being either a transformer or an estimator.

           """
        self.__iadd__(pipe_element)

    def _prepare_pipeline(self):
        """ Generates sklearn pipeline with all underlying elements """
        pipeline_steps = []
        for item in self.elements:
            pipeline_steps.append((item.name, item))
            if hasattr(item, 'hyperparameters'):
                self._hyperparameters[item.name] = item.hyperparameters

        if self.has_hyperparameters:
            self.generate_sklearn_hyperparameters()
        new_pipe = PhotonPipeline(pipeline_steps)
        new_pipe._fix_fold_id = self.fix_fold_id
        new_pipe._do_not_delete_cache_folder = self.do_not_delete_cache_folder
        self.base_element = new_pipe

    def copy_me(self):
        new_copy_of_me = self.__class__(self.name)
        for item in self.elements:
            if hasattr(item, 'copy_me'):
                copy_item = item.copy_me()
            else:
                copy_item = deepcopy(item)
            new_copy_of_me += copy_item

        if self.current_config is not None:
            (new_copy_of_me.set_params)(**self.current_config)
        return new_copy_of_me

    @property
    def hyperparameters(self):
        return self._hyperparameters

    @hyperparameters.setter
    def hyperparameters(self, value):
        """
        Setting hyperparameters does not make sense, only the items that added can be optimized, not the container (self)
        """
        pass

    def generate_config_grid(self):
        if self.has_hyperparameters:
            tmp_grid = create_global_config_grid(self.elements, self.name)
            return tmp_grid
        else:
            return []

    def generate_sklearn_hyperparameters(self):
        """
        Generates a dictionary according to the sklearn convention of element_name__parameter_name: parameter_value
        """
        self._hyperparameters = {}
        for element in self.elements:
            for attribute, value_list in element.hyperparameters.items():
                self._hyperparameters[self.name + '__' + attribute] = value_list

    def _check_hyper(self, BaseEstimator):
        pass


class Preprocessing(Branch):
    __doc__ = '\n        If a preprocessing pipe is added to a PHOTON Hyperpipe, all transformers are applied to the data ONCE\n        BEFORE cross validation starts in order to prepare the data.\n        Every added element should be a transformer PipelineElement.\n    '

    def __init__(self):
        super().__init__('Preprocessing')
        self.has_hyperparameters = False
        self.needs_y = True
        self.needs_covariates = True
        self.name = 'Preprocessing'

    def __iadd__(self, pipe_element):
        """
        Add an element to the sub pipeline
        Returns self

        Parameters
        ----------
        * `pipe_element` [PipelineElement]:
            The transformer object to add.

        """
        if hasattr(pipe_element, 'transform'):
            if len(pipe_element.hyperparameters) > 0:
                raise ValueError('A preprocessing transformer must not have any hyperparameter because it is not part of the optimization and cross validation procedure')
            self.elements.append(pipe_element)
            self._prepare_pipeline()
        else:
            raise ValueError('Pipeline Element must have transform function')
        return self

    def predict(self, data, **kwargs):
        raise Warning('There is no predict function of the preprocessing pipe, it is a transformer only.')


class Stack(PipelineElement):
    __doc__ = '\n    Creates a vertical stacking/parallelization of pipeline items.\n\n    The object acts as single pipeline element and encapsulates several vertically stacked other pipeline elements, each\n    child receiving the same input data. The data is iteratively distributed to all children, the results are collected\n    and horizontally concatenated.\n\n    '

    def __init__(self, name, elements=None, voting=False):
        """
        Creates a new Stack element.
        Collects all possible hyperparameter combinations of the children

        Parameters
        ----------
        * `name` [str]:
            Give the pipeline element a name
        * `elements` [list, optional]:
            List of pipeline elements that should run in parallel
        * `voting` [bool]:
            If true, the predictions of the encapsulated pipeline elements are joined to a single prediction
        """
        super(Stack, self).__init__(name, hyperparameters={}, test_disabled=False, disabled=False, base_element=True)
        self._hyperparameters = {}
        self.elements = list()
        self.voting = voting
        if elements is not None:
            for item_to_stack in elements:
                self.__iadd__(item_to_stack)

        self.needs_y = False
        self.needs_covariates = True

    def __iadd__(self, item):
        """
        Adds a new element to the stack.
        Generates sklearn hyperparameter names in order to set the item's hyperparameters in the optimization process.

        * `item` [PipelineElement or Branch or Hyperpipe]:
            The Element that should be stacked and will run in a vertical parallelization in the original pipe.
        """
        self.check_if_needs_y(item)
        self.elements.append(item)
        if not isinstance(item, Hyperpipe):
            tmp_dict = dict(item.hyperparameters)
            for key, element in tmp_dict.items():
                self._hyperparameters[self.name + '__' + key] = tmp_dict[key]

        return self

    def check_if_needs_y(self, item):
        if isinstance(item, (Branch, Stack, Switch)):
            for child_item in item.elements:
                self.check_if_needs_y(child_item)

        elif isinstance(item, PipelineElement):
            if item.needs_y:
                raise NotImplementedError('Elements in Stack must not transform y because the number of samples in every element of the stack might differ. Then, it will not be possible to concatenate those data and target matrices. Please use the transformer that is using y before or after the stack.')

    def add(self, item):
        self.__iadd__(item)

    @property
    def hyperparameters(self):
        return self._hyperparameters

    @hyperparameters.setter
    def hyperparameters(self, value):
        """
        Setting hyperparameters does not make sense, only the items that added can be optimized, not the container (self)
        """
        pass

    def generate_config_grid(self):
        tmp_grid = create_global_config_grid(self.elements, self.name)
        return tmp_grid

    def get_params(self, deep=True):
        all_params = {}
        for element in self.elements:
            all_params[element.name] = element.get_params(deep)

        return all_params

    def set_params(self, **kwargs):
        """
        Find the particular child and distribute the params to it
        """
        spread_params_dict = {}
        for k, val in kwargs.items():
            splitted_k = k.split('__')
            item_name = splitted_k[0]
            if item_name not in spread_params_dict:
                spread_params_dict[item_name] = {}
            dict_entry = {'__'.join(splitted_k[1:]): val}
            spread_params_dict[item_name].update(dict_entry)

        for name, params in spread_params_dict.items():
            for element in self.elements:
                if element.name == name:
                    (element.set_params)(**params)

        return self

    def fit(self, X, y=None, **kwargs):
        """
        Calls fit iteratively on every child
        """
        for element in self.elements:
            (element.fit)(X, y, **kwargs)

        return self

    def predict(self, X, **kwargs):
        """
        Iteratively calls predict on every child.
        """
        predicted_data = np.array([])
        for element in self.elements:
            element_transform = (element.predict)(X, **kwargs)
            predicted_data = Stack.stack_data(predicted_data, element_transform)

        if self.voting:
            if hasattr(predicted_data, 'shape'):
                if len(predicted_data.shape) > 1:
                    predicted_data = np.mean(predicted_data, axis=1).astype(int)
        return (
         predicted_data, kwargs)

    def predict_proba(self, X, y=None, **kwargs):
        """
        Predict probabilities for every pipe element and
        stack them together. Alternatively, do voting instead.
        """
        predicted_data = np.array([])
        for element in self.elements:
            element_transform = element.predict_proba(X)
            predicted_data = Stack.stack_data(predicted_data, element_transform)

        if self.voting:
            if hasattr(predicted_data, 'shape'):
                if len(predicted_data.shape) > 1:
                    predicted_data = np.mean(predicted_data, axis=1).astype(int)
        return predicted_data

    def transform(self, X, y=None, **kwargs):
        """
        Calls transform on every child.

        If the encapsulated child is a hyperpipe, also calls predict on the last element in the pipeline.
        """
        transformed_data = np.array([])
        for element in self.elements:
            element_transform, _, _ = (element.transform)(X, y, **kwargs)
            transformed_data = Stack.stack_data(transformed_data, element_transform)

        return (transformed_data, y, kwargs)

    def copy_me(self):
        ps = Stack((self.name), voting=(self.voting))
        for element in self.elements:
            new_element = element.copy_me()
            ps += new_element

        ps.base_element = self.base_element
        return ps

    @classmethod
    def stack_data(cls, a, b):
        """
        Helper method to horizontally join the outcome of each child

        Parameters
        ----------
        * `a` [ndarray]:
            The existing matrix
        * `b` [ndarray]:
            The matrix that is to be attached horizontally

        Returns
        -------
        New matrix, that is a and b horizontally joined

        """
        if a is None or isinstance(a, np.ndarray) and a.size == 0:
            a = b
        elif a.ndim == 1:
            if b.ndim == 1:
                a = np.column_stack((a, b))
        else:
            if b.ndim == 1:
                b = np.reshape(b, (b.shape[0], 1))
            a = np.concatenate((a, b), axis=1)
        return a

    def score(self, X_test, y_test):
        """
        Calculate accuracy for predictions made with this object.
        This function should probably never be called.

        """
        predicted = self.predict(X_test)
        return accuracy_score(y_test, predicted)

    def inverse_transform(self, X, y, **kwargs):
        raise NotImplementedError('Inverse Transform is not yet implemented for a Stacking Element in PHOTON')

    def _check_hyper(self, BaseEstimator):
        pass


class Switch(PipelineElement):
    __doc__ = "\n    This class encapsulates several pipeline elements that belong at the same step of the pipeline,\n    competing for being the best choice.\n\n    If for example you want to find out if preprocessing A or preprocessing B is better at this position in the pipe.\n    Or you want to test if a tree outperforms the good old SVM.\n\n    ATTENTION: This class is a construct that may be convenient but is not suitable for any complex optimizations.\n    Currently it only works for grid_search and the derived optimization strategies.\n    USE THIS ONLY FOR RAPID PROTOTYPING AND PRELIMINARY RESULTS\n\n    The class acts as if it is a single entity. Tt joins the hyperparamater combinations of each encapsulated element to\n    a single, big combination grid. Each hyperparameter combination from that grid gets a number. Then the Switch\n    object publishes the numbers to be chosen as the object's hyperparameter. When a new number is chosen from the\n    optimizer, it internally activates the belonging element and sets the element's parameter to the hyperparameter\n    combination. In that way, each of the elements is tested in all its configurations at the same position in the\n    pipeline. From the outside, the process and the optimizer only sees one parameter of the Switch, that is\n    the an integer indicating which item of the hyperparameter combination grid is currently active.\n\n    "

    def __init__(self, name: str, elements: list=None):
        """
        Creates a new Switch object and generated the hyperparameter combination grid

        Parameters
        ----------
        * `name` [str]:
            How the element is called in the pipeline
        * `elements` [list, optional]:
            The competing pipeline elements
        * `_estimator_type:
            Used for validation purposes, either classifier or regressor

        """
        self.name = name
        self.sklearn_name = self.name + '__current_element'
        self._hyperparameters = {}
        self._current_element = (1, 1)
        self.pipeline_element_configurations = []
        self._estimator_type = 'regressor'
        self.base_element = None
        self.disabled = False
        self.test_disabled = False
        self.batch_size = 0
        self.needs_y = True
        self.needs_covariates = True
        self.is_estimator = True
        self.is_transformer = True
        self.elements_dict = {}
        if elements:
            self.elements = elements
            self.is_transformer, self.is_estimator = self.check_if_estimator_or_transformer(elements[(-1)])
            self.generate_private_config_grid()
            for p_element in elements:
                self.elements_dict[p_element.name] = p_element

        else:
            self.elements = []

    def check_if_estimator_or_transformer(self, pipeline_element):
        if isinstance(pipeline_element, Branch):
            return self.check_if_estimator_or_transformer(pipeline_element.elements[(-1)])
        else:
            if isinstance(pipeline_element, Switch):
                return self.check_if_estimator_or_transformer(pipeline_element.elements[0])
            if isinstance(pipeline_element, Stack):
                return self.check_if_estimator_or_transformer(pipeline_element.elements[0])
            if isinstance(pipeline_element, PipelineElement):
                if hasattr(pipeline_element, 'is_estimator'):
                    return (not pipeline_element.is_estimator, pipeline_element.is_estimator)
                else:
                    return (False, True)

    def __iadd__(self, pipeline_element):
        """
        Add a new estimator or transformer object to the switch container. All items change positions during testing.

        Parameters
        ----------
        * `pipeline_element` [PipelineElement]:
            Item that should be tested against other competing elements at that position in the pipeline.
        """
        self.is_transformer, self.is_estimator = self.check_if_estimator_or_transformer(pipeline_element)
        self.elements.append(pipeline_element)
        if pipeline_element.name not in self.elements_dict:
            self.elements_dict[pipeline_element.name] = pipeline_element
        else:
            error_msg = 'Already added a pipeline element with that name to the pipeline switch ' + self.name
            Logger().error(error_msg)
            raise Exception(error_msg)
        self.generate_private_config_grid()
        return self

    def add(self, pipeline_element):
        """
        Add a new estimator or transformer object to the switch container. All items change positions during testing.

        Parameters
        ----------
        * `pipeline_element` [PipelineElement]:
            Item that should be tested against other competing elements at that position in the pipeline.
        """
        self.__iadd__(pipeline_element)

    @property
    def hyperparameters(self):
        return self._hyperparameters

    @hyperparameters.setter
    def hyperparameters(self, value):
        pass

    def generate_private_config_grid(self):
        self.pipeline_element_configurations = []
        hyperparameters = []
        for i, pipe_element in enumerate(self.elements):
            element_configurations = pipe_element.generate_config_grid()
            final_configuration_list = []
            if len(element_configurations) == 0:
                final_configuration_list.append({})
            for dict_item in element_configurations:
                final_configuration_list.append(dict(dict_item))

            self.pipeline_element_configurations.append(final_configuration_list)
            hyperparameters += [(i, nr) for nr in range(len(final_configuration_list))]

        self._hyperparameters = {self.sklearn_name: hyperparameters}

    @property
    def current_element(self):
        return self._current_element

    @current_element.setter
    def current_element(self, value):
        self._current_element = value
        self.base_element = self.elements[self.current_element[0]]

    def get_params(self, deep: bool=True):
        if self.base_element:
            return self.base_element.get_params(deep)
        else:
            return {}

    def set_params(self, **kwargs):
        """
        The optimization process sees the amount of possible combinations and chooses one of them.
        Then this class activates the belonging element and prepared the element with the particular chosen configuration.

        """
        config_nr = None
        config = None
        if self.sklearn_name in kwargs:
            config_nr = kwargs[self.sklearn_name]
        elif 'current_element' in kwargs:
            config_nr = kwargs['current_element']
        else:
            if config_nr is None:
                if kwargs is not None:
                    config = kwargs
                    for kwargs_key, kwargs_value in kwargs.items():
                        first_element_name = kwargs_key.split('__')[0]
                        self.base_element = self.elements_dict[first_element_name]
                        break

            else:
                if not isinstance(config_nr, (tuple, list)):
                    Logger().error('ValueError: current_element must be of type Tuple')
                    raise ValueError('current_element must be of type Tuple')
                self.current_element = config_nr
                config = self.pipeline_element_configurations[config_nr[0]][config_nr[1]]
        if config:
            unnamed_config = {}
            for config_key, config_value in config.items():
                key_split = config_key.split('__')
                unnamed_config['__'.join(key_split[1:])] = config_value

            (self.base_element.set_params)(**unnamed_config)
        return self

    def copy_me(self):
        ps = Switch(self.name)
        for element in self.elements:
            new_element = element.copy_me()
            ps += new_element

        ps.base_element = self.base_element
        return ps

    def prettify_config_output(self, config_name, config_value, return_dict=False):
        """
        Makes the sklearn configuration dictionary human readable

        Returns
        -------
        * `prettified_configuration_string` [str]:
            configuration as prettified string or configuration as dict with prettified keys
        """
        if isinstance(config_value, tuple):
            output = self.pipeline_element_configurations[config_value[0]][config_value[1]]
            if not output:
                if return_dict:
                    return {self.elements[config_value[0]].name: None}
                else:
                    return self.elements[config_value[0]].name
            else:
                if return_dict:
                    return output
                else:
                    return str(output)
        else:
            return super(Switch, self).prettify_config_output(config_name, config_value)

    def predict_proba(self, X, **kwargs):
        """
        Predict probabilities
        base element needs predict_proba() function, otherwise throw
        base exception.
        """
        if not self.disabled:
            if hasattr(self.base_element.base_element, 'predict_proba'):
                return self.base_element.predict_proba(X)
            return
        else:
            return X

    def _check_hyper(self, BaseEstimator):
        pass

    def inverse_transform(self, X, y=None, **kwargs):
        if hasattr(self.base_element, 'inverse_transform'):
            X, y, kwargs = (self.adjusted_delegate_call)((self.base_element.inverse_transform), X, y, **kwargs)
        return (
         X, y, kwargs)


class CallbackElement(PhotonNative):

    def __init__(self, name, delegate_function, method_to_monitor='transform'):
        self.needs_covariates = True
        self.needs_y = True
        self.name = name
        self.delegate_function = delegate_function
        self.method_to_monitor = method_to_monitor
        self.hyperparameters = {}
        self.is_transformer = True
        self.is_estimator = False

    def fit(self, X, y=None, **kwargs):
        if self.method_to_monitor == 'fit':
            (self.delegate_function)(X, y, **kwargs)
        return self

    def transform(self, X, y=None, **kwargs):
        if self.method_to_monitor == 'transform':
            (self.delegate_function)(X, y, **kwargs)
        return (
         X, y, kwargs)

    def copy_me(self):
        return self.__class__(self.name, self.delegate_function, self.method_to_monitor)

    def inverse_transform(self, X, y=None, **kwargs):
        return (
         X, y, kwargs)


class PhotonModelPersistor:

    @staticmethod
    def save_optimum_pipe(hyperpipe, file, password=None):
        """
        Save optimal pipeline only. Complete hyperpipe will no not be saved.

        Parameters
        ----------
        * 'file' [str]:
            File path as string specifying file to save pipeline to
        * 'password' [str]:
            Password used to encrypt the pipeline file

        """

        def save_element(element, element_number, element_name, folder, wrapper_files):
            filename = '_optimum_pipe_' + str(element_number) + '_' + element_name
            element_identifier.append({'element_name':element_name,  'filename':filename})
            if hasattr(element, 'base_element'):
                base_element = element.base_element
            else:
                base_element = element
            if hasattr(base_element, 'save'):
                base_element.save(os.path.join(folder, filename))
                element_identifier[(-1)]['mode'] = 'custom'
                element_identifier[(-1)]['wrapper_script'] = os.path.basename(inspect.getfile(base_element.__class__))
                wrapper_files.append(inspect.getfile(base_element.__class__))
                element_identifier[(-1)]['test_disabled'] = element.test_disabled
                element_identifier[(-1)]['disabled'] = element.disabled
                element_identifier[(-1)]['hyperparameters'] = element.hyperparameters
            else:
                try:
                    joblib.dump(element, (os.path.join(folder, filename) + '.pkl'), compress=1)
                    element_identifier[(-1)]['mode'] = 'pickle'
                except:
                    raise NotImplementedError('Custom pipeline element must implement .save() method or allow pickle.')

            return wrapper_files

        element_number = 0
        element_identifier = list()
        folder = os.path.splitext(file)[0]
        file = os.path.splitext(file)[0] + '.photon'
        if os.path.exists(folder):
            Logger().warn('The file you specified already exists as a folder.')
        else:
            os.makedirs(folder)
        wrapper_files = list()
        for name, element in hyperpipe.optimum_pipe.elements:
            wrapper_files = save_element(element, element_number, name, folder, wrapper_files)
            element_number += 1

        with open(os.path.join(folder, '_optimum_pipe_blueprint.pkl'), 'wb') as (f):
            pickle.dump(element_identifier, f)
        files = glob.glob(os.path.join(folder, '_optimum_pipe_*'))
        if password is not None:
            import pyminizip
            pyminizip.compress(files, file, password)
        else:
            with zipfile.ZipFile(file, 'w') as (myzip):
                for f in files:
                    myzip.write(f, os.path.basename(f))
                    os.remove(f)

                for f in wrapper_files:
                    myzip.write(f, os.path.splitext(os.path.basename(f))[0] + '.py')

        os.removedirs(folder)

    @staticmethod
    def load_optimum_pipe(file, password=None):
        """
        Load optimal pipeline.

        Parameters
        ----------
        * `file` [str]:
            File path specifying .photon file to load optimal pipeline from

        Returns
        -------
        sklearn Pipeline with all trained photon_pipelines
        """
        if file.endswith('.photon'):
            archive_name = os.path.splitext(file)[0]
            folder = archive_name
            zf = zipfile.ZipFile(file)
            zf.extractall(folder, pwd=password)
        else:
            raise FileNotFoundError('Specify .photon file that holds PHOTON optimum pipe.')
        with open(os.path.join(folder, '_optimum_pipe_blueprint.pkl'), 'rb') as (f):
            setup_info = pickle.load(f)
            element_list = list()
            for element_info in setup_info:
                if element_info['mode'] == 'custom':
                    spec = importlib.util.spec_from_file_location(element_info['element_name'], os.path.join(folder, element_info['wrapper_script']))
                    imported_module = importlib.util.module_from_spec(spec)
                    spec.loader.exec_module(imported_module)
                    base_element = getattr(imported_module, element_info['element_name'])
                    custom_element = PipelineElement(name=(element_info['element_name']), base_element=(base_element()), hyperparameters=(element_info['hyperparameters']),
                      test_disabled=(element_info['test_disabled']),
                      disabled=(element_info['disabled']))
                    custom_element.base_element.load(os.path.join(folder, element_info['filename']))
                    element_list.append((element_info['element_name'], custom_element))
                else:
                    loaded_pipeline_element = joblib.load(os.path.join(folder, element_info['filename'] + '.pkl'))
                    if not hasattr(loaded_pipeline_element, 'needs_y'):
                        if hasattr(loaded_pipeline_element.base_element, 'needs_y'):
                            loaded_pipeline_element.needs_y = loaded_pipeline_element.base_element.needs_y
                        else:
                            loaded_pipeline_element.needs_y = False
                    if not hasattr(loaded_pipeline_element, 'needs_covariates'):
                        if hasattr(loaded_pipeline_element.base_element, 'needs_covariates'):
                            loaded_pipeline_element.needs_covariates = loaded_pipeline_element.base_element.needs_covariates
                        else:
                            loaded_pipeline_element.needs_covariates = False
                    loaded_pipeline_element.is_transformer = hasattr(loaded_pipeline_element.base_element, 'transform')
                    loaded_pipeline_element.is_estimator = hasattr(loaded_pipeline_element.base_element, 'predict')
                    element_list.append((element_info['element_name'], loaded_pipeline_element))

            from shutil import rmtree
            rmtree(folder, ignore_errors=True)
        return PhotonPipeline(element_list)


class FlowchartCreator(object):

    def __init__(self, pipeline_elements):
        self.pipeline_elements = pipeline_elements
        self.chart_str = ''

    def create_str(self):
        header_layout = ''
        header_relate = ''
        old_element = ''
        for pipeline_element in self.pipeline_elements:
            header_layout = header_layout + '[' + pipeline_element.name + ']'
            if old_element:
                header_relate = header_relate + '[' + old_element + ']' + '->' + '[' + pipeline_element.name + ']\n'
            old_element = pipeline_element.name

        self.chart_str = 'Layout:\n' + header_layout + '\nRelate:\n' + header_relate + '\n'
        for pipeline_element in self.pipeline_elements:
            self.chart_str = self.chart_str + self.recursive_element(pipeline_element, '')

        return self.chart_str

    @staticmethod
    def format_cross_validation(cv):
        if cv:
            string = '{}('.format(cv.__class__.__name__)
            for key, val in cv.__dict__.items():
                string += '{}={}, '.format(key, val)

            return string[:-2] + ')'
        else:
            return 'None'

    @staticmethod
    def format_optimizer(optimizer):
        return (optimizer.optimizer_input, optimizer.optimizer_params, optimizer.metrics, optimizer.best_config_metric)

    def format_kwargs(self, kwargs):
        pass

    @staticmethod
    def format_hyperparameter(hyperparameter):
        if isinstance(hyperparameter, IntegerRange):
            return 'IntegerRange(start: {},\n                                   stop: {}, \n                                   step: {}, \n                                   range_type: {})'.format(hyperparameter.start, hyperparameter.stop, hyperparameter.step, hyperparameter.range_type)
        else:
            if isinstance(hyperparameter, FloatRange):
                return 'FloatRange(start: {},\n                                   stop: {}, \n                                   step: {}, \n                                   range_type: {})'.format(hyperparameter.start, hyperparameter.stop, hyperparameter.step, hyperparameter.range_type)
            if isinstance(hyperparameter, Categorical):
                return str(hyperparameter.values)
            return str(hyperparameter)

    def recursive_element(self, pipe_element, parent):
        string = ''
        if isinstance(pipe_element, Stack):
            if parent == '':
                string = '[' + pipe_element.name + ']:\n' + 'Layout:\n'
            else:
                string = '[' + parent[1:] + '.' + pipe_element.name + ']:\n' + 'Layout:\n'
            for pelement in list(pipe_element.elements):
                string = string + '[' + pelement.name + ']|\n'

            string = string + '\n'
            for pelement in list(pipe_element.elements):
                string = string + '\n' + self.recursive_element(pelement, parent=(parent + '.' + pipe_element.name))

        else:
            if isinstance(pipe_element, Switch):
                if parent == '':
                    string = '[' + pipe_element.name + ']:\n' + 'Layout:\n'
                else:
                    string = '[' + parent[1:] + '.' + pipe_element.name + ']:\n' + 'Layout:\n'
                for pelement in pipe_element.elements:
                    string = string + '[' + pelement.name + ']\n'

                string = string + '\n'
                string = string + '\n' + 'Relate:\n'
                old_element = ''
                for pelement in pipe_element.elements:
                    if old_element:
                        string = string + '[' + old_element + ']' + '<:-:>' + '[' + pelement.name + ']\n'
                    old_element = pelement.name
                    string = string + '\n'

                for pelement in pipe_element.elements:
                    string = string + '\n' + self.recursive_element(pelement, parent=(parent + '.' + pipe_element.name))

            else:
                if isinstance(pipe_element, Branch):
                    if parent == '':
                        string = '[' + pipe_element.name + ']:\n' + 'Layout:\n'
                    else:
                        string = '[' + parent[1:] + '.' + pipe_element.name + ']:\n' + 'Layout:\n'
                    for pelement in pipe_element.elements:
                        string = string + '[' + pelement.name + ']'

                    string = string + '\n' + 'Relate:\n'
                    old_element = ''
                    for pelement in pipe_element.elements:
                        if old_element:
                            string = string + '[' + old_element + ']' + '->' + '[' + pelement.name + ']\n'
                        old_element = pelement.name
                        string = string + '\n'

                    for pelement in pipe_element.elements:
                        string = string + '\n' + self.recursive_element(pelement, parent=(parent + '.' + pipe_element.name))

                else:
                    if isinstance(pipe_element, PipelineElement):
                        if parent == '':
                            string = '[' + pipe_element.name + ']:\n' + 'Define:\n'
                        else:
                            string = '[' + parent[1:] + '.' + pipe_element.name + ']:\n' + 'Define:\n'
                        hyperparameters = None
                        kwargs = None
                        if hasattr(pipe_element, 'hyperparameters'):
                            hyperparameters = pipe_element.hyperparameters
                            for name, parameter in pipe_element.hyperparameters.items():
                                string += '{}: {}\n'.format(name.split('__')[(-1)], self.format_hyperparameter(parameter))

                        if hasattr(pipe_element, 'kwargs'):
                            kwargs = pipe_element.kwargs
                            for name, parameter in pipe_element.kwargs.items():
                                string += '{}: {}\n'.format(name.split('__')[(-1)], self.format_hyperparameter(parameter))

                        if not kwargs:
                            if not hyperparameters:
                                string += 'default\n'
        return string