# uncompyle6 version 3.7.4
# Python bytecode 2.7 (62211)
# Decompiled from: Python 3.6.9 (default, Apr 18 2020, 01:56:04) 
# [GCC 8.4.0]
# Embedded file name: build/bdist.linux-x86_64/egg/insights/parsers/tests/test_openshift_get.py
# Compiled at: 2020-03-25 13:10:41
from insights.parsers import openshift_get
from insights.tests import context_wrap
import datetime, doctest
OC_GET_POD = ('\napiVersion: v1\nitems:\n- apiVersion: v1\n  kind: Pod\n  metadata:\n    annotations:\n      openshift.io/scc: anyuid\n    creationTimestamp: 2017-02-10T16:33:46Z\n    labels:\n      name: hello-openshift\n    name: hello-pod\n    namespace: default\n  spec:\n    containers:\n    - image: openshift/hello-openshift\n      imagePullPolicy: IfNotPresent\n      name: hello-openshift\n      ports:\n      - containerPort: 8080\n        protocol: TCP\n      resources: {}\n      securityContext:\n        capabilities:\n          drop:\n          - MKNOD\n          - SYS_CHROOT\n        privileged: false\n        seLinuxOptions:\n          level: s0:c5,c0\n      terminationMessagePath: /dev/termination-log\n      volumeMounts:\n      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount\n        name: default-token-yk69f\n        readOnly: true\n    dnsPolicy: ClusterFirst\n    host: node2.ose.com\n    imagePullSecrets:\n    - name: default-dockercfg-h7sl1\n    nodeName: node2.ose.com\n    restartPolicy: Always\n    securityContext:\n      seLinuxOptions:\n        level: s0:c5,c0\n    serviceAccount: default\n    serviceAccountName: default\n    terminationGracePeriodSeconds: 30\n    volumes:\n    - name: default-token-yk69f\n      secret:\n        secretName: default-token-yk69f\n  status:\n    conditions:\n    - lastProbeTime: null\n      lastTransitionTime: 2017-02-10T16:33:46Z\n      status: "True"\n      type: Initialized\n    containerStatuses:\n    - containerID: docker://a172a6945e207c0fd1c391cad31ccb76bc8323f3f024a50b5ba287034302853f\n      image: openshift/hello-openshift\n      imageID: docker-pullable://docker.io/openshift/hello-openshift@sha256:9b1b29dc4ed029220b2d87fce57fab43f450fa6521ab86f22ddbc5ecc978752a\n      lastState:\n        terminated:\n          containerID: docker://9ea5647da89302437630e96728f9f65593c07d0e65a1b275854fcb4c738c8c46\n          exitCode: 2\n          finishedAt: 2017-02-13T18:59:47Z\n          reason: Error\n          startedAt: 2017-02-10T16:33:56Z\n      name: hello-openshift\n      ready: true\n      restartCount: 1\n      state:\n        running:\n          startedAt: 2017-02-13T19:00:49Z\n    hostIP: 10.66.208.105\n    phase: Running\n    podIP: 10.1.0.3\n    startTime: 2017-02-10T16:33:46Z\n- apiVersion: v1\n  kind: Pod\n  metadata:\n    annotations:\n      kubernetes.io/created-by: |\n        {"kind":"SerializedReference","apiVersion":"v1","reference":{"kind":"ReplicationController","namespace":"zjj-project","name":"router-1-1","uid":"12c1a374-f75a-11e6-80d0-001a4a0100d2","apiVersion":"v1","resourceVersion":"1638409"}}\n      openshift.io/deployment-config.latest-version: "1"\n      openshift.io/deployment-config.name: router-1\n      openshift.io/deployment.name: router-1-1\n      openshift.io/scc: hostnetwork\n    creationTimestamp: 2017-02-20T10:48:14Z\n    generateName: router-1-1-\n    labels:\n      deployment: router-1-1\n      deploymentconfig: router-1\n      router: router-1\n    name: router-1-1-w27o2\n  spec:\n    containers:\n    - env:\n      - name: DEFAULT_CERTIFICATE_DIR\n        value: /etc/pki/tls/private\n      - name: ROUTER_EXTERNAL_HOST_HOSTNAME\n      - name: ROUTER_EXTERNAL_HOST_HTTPS_VSERVER\n      - name: ROUTER_EXTERNAL_HOST_HTTP_VSERVER\n      - name: ROUTER_EXTERNAL_HOST_INSECURE\n        value: "false"\n      - name: ROUTER_EXTERNAL_HOST_PARTITION_PATH\n      - name: ROUTER_EXTERNAL_HOST_PASSWORD\n      - name: ROUTER_EXTERNAL_HOST_PRIVKEY\n        value: /etc/secret-volume/router.pem\n      - name: ROUTER_EXTERNAL_HOST_USERNAME\n      - name: ROUTER_SERVICE_HTTPS_PORT\n        value: "443"\n      - name: ROUTER_SERVICE_HTTP_PORT\n        value: "80"\n      - name: ROUTER_SERVICE_NAME\n        value: router-1\n      - name: ROUTER_SERVICE_NAMESPACE\n        value: zjj-project\n      - name: ROUTER_SUBDOMAIN\n      - name: STATS_PASSWORD\n        value: password\n      - name: STATS_PORT\n        value: "1936"\n      - name: STATS_USERNAME\n        value: admin\n      image: openshift3/ose-haproxy-router:v3.3.1.7\n      imagePullPolicy: IfNotPresent\n      livenessProbe:\n        failureThreshold: 3\n        httpGet:\n          host: localhost\n          path: /healthz\n          port: 1936\n          scheme: HTTP\n        initialDelaySeconds: 10\n        periodSeconds: 10\n        successThreshold: 1\n        timeoutSeconds: 1\n      name: router\n      ports:\n      - containerPort: 80\n        hostPort: 80\n        protocol: TCP\n      - containerPort: 443\n        hostPort: 443\n        protocol: TCP\n      - containerPort: 1936\n        hostPort: 1936\n        name: stats\n        protocol: TCP\n      readinessProbe:\n        failureThreshold: 3\n        httpGet:\n          host: localhost\n          path: /healthz\n          port: 1936\n          scheme: HTTP\n        initialDelaySeconds: 10\n        periodSeconds: 10\n        successThreshold: 1\n        timeoutSeconds: 1\n      resources:\n        requests:\n          cpu: 100m\n          memory: 256Mi\n      securityContext:\n        capabilities:\n          drop:\n          - KILL\n          - MKNOD\n          - SETGID\n          - SETUID\n          - SYS_CHROOT\n        privileged: false\n        runAsUser: 1000070000\n        seLinuxOptions:\n          level: s0:c8,c7\n      terminationMessagePath: /dev/termination-log\n      volumeMounts:\n      - mountPath: /etc/pki/tls/private\n        name: server-certificate\n        readOnly: true\n      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount\n        name: router-token-0j7an\n        readOnly: true\n    dnsPolicy: ClusterFirst\n    host: node1.ose.com\n    hostNetwork: true\n    imagePullSecrets:\n    - name: router-dockercfg-dlu6n\n    nodeName: node1.ose.com\n    restartPolicy: Always\n    securityContext:\n      fsGroup: 1000070000\n      seLinuxOptions:\n        level: s0:c8,c7\n      supplementalGroups:\n      - 1000070000\n    serviceAccount: router\n    serviceAccountName: router\n    terminationGracePeriodSeconds: 30\n    volumes:\n    - name: server-certificate\n      secret:\n        secretName: router-1-certs\n    - name: router-token-0j7an\n      secret:\n        secretName: router-token-0j7an\n  status:\n    conditions:\n    - lastProbeTime: null\n      lastTransitionTime: 2017-02-20T10:48:14Z\n      status: "True"\n      type: Initialized\n    containerStatuses:\n    - containerID: docker://aa4348a647e0f3186e70a0ce9837f84a25060b4daebab370c1fc093cf8af3349\n      image: openshift3/ose-haproxy-router:v3.3.1.7\n      imageID: docker-pullable://registry.access.redhat.com/openshift3/ose-haproxy-router@sha256:f2f75cfd2b828c3143ca8022e26593a7491ca040dab6d6472472ed040d1c1b83\n      lastState: {}\n      name: router\n      ready: true\n      restartCount: 0\n      state:\n        running:\n          startedAt: 2017-02-20T10:48:16Z\n    hostIP: 10.66.208.229\n    phase: Running\n    podIP: 10.66.208.229\n    startTime: 2017-02-20T10:48:14Z\nkind: List\nmetadata: {}\n').strip()
OC_GET_SERVICE = ('\napiVersion: v1\nitems:\n- apiVersion: v1\n  kind: Service\n  metadata:\n    creationTimestamp: 2016-12-27T03:24:03Z\n    labels:\n      component: apiserver\n      provider: kubernetes\n    name: kubernetes\n    namespace: default\n    resourceVersion: "9"\n    selfLink: /api/v1/namespaces/default/services/kubernetes\n    uid: ea9d8fb4-cbe3-11e6-b3c1-001a4a0100d2\n  spec:\n    clusterIP: 172.30.0.1\n    portalIP: 172.30.0.1\n    ports:\n    - name: https\n      port: 443\n      protocol: TCP\n      targetPort: 443\n    - name: dns\n      port: 53\n      protocol: UDP\n      targetPort: 8053\n    - name: dns-tcp\n      port: 53\n      protocol: TCP\n      targetPort: 8053\n    sessionAffinity: ClientIP\n    type: ClusterIP\n  status:\n    loadBalancer: {}\n- apiVersion: v1\n  kind: Service\n  metadata:\n    annotations:\n      service.alpha.openshift.io/serving-cert-secret-name: router-1-certs\n      service.alpha.openshift.io/serving-cert-signed-by: openshift-service-serving-signer@1480042702\n    creationTimestamp: 2017-02-20T10:48:11Z\n    labels:\n      router: router-1\n    name: router-1\n    namespace: zjj-project\n    resourceVersion: "1638401"\n    selfLink: /api/v1/namespaces/zjj-project/services/router-1\n    uid: 12bdf634-f75a-11e6-80d0-001a4a0100d2\n  spec:\n    clusterIP: 172.30.210.0\n    portalIP: 172.30.210.0\n    ports:\n    - name: 80-tcp\n      port: 80\n      protocol: TCP\n      targetPort: 80\n    - name: 443-tcp\n      port: 443\n      protocol: TCP\n      targetPort: 443\n    - name: 1936-tcp\n      port: 1936\n      protocol: TCP\n      targetPort: 1936\n    selector:\n      router: router-1\n    sessionAffinity: None\n    type: ClusterIP\n  status:\n    loadBalancer: {}\nkind: List\nmetadata: {}\n').strip()
OC_GET_CONFIGMAP = ('\napiVersion: v1\nitems:\n- apiVersion: v1\n  data:\n    node-config.yaml: |\n      apiVersion: v1\n      authConfig:\n        authenticationCacheSize: 1000\n        authenticationCacheTTL: 5m\n        authorizationCacheSize: 1000\n        authorizationCacheTTL: 5m\n      dnsBindAddress: 127.0.0.1:53\n      dnsDomain: cluster.local\n      dnsIP: 0.0.0.0\n      dnsNameservers: null\n      dnsRecursiveResolvConf: /etc/origin/node/resolv.conf\n      dockerConfig:\n        dockerShimRootDirectory: /var/lib/dockershim\n        dockerShimSocket: /var/run/dockershim.sock\n        execHandlerName: native\n      enableUnidling: true\n      imageConfig:\n        format: registry.access.redhat.com/openshift3/ose-${component}:${version}\n        latest: false\n      iptablesSyncPeriod: 30s\n      kind: NodeConfig\n      kubeletArguments:\n        bootstrap-kubeconfig:\n        - /etc/origin/node/bootstrap.kubeconfig\n        cert-dir:\n        - /etc/origin/node/certificates\n        cloud-config:\n        - /etc/origin/cloudprovider/openstack.conf\n        cloud-provider:\n        - openstack\n        container-runtime:\n        - remote\n        container-runtime-endpoint:\n        - /var/run/crio/crio.sock\n        enable-controller-attach-detach:\n        - \'true\'\n        feature-gates:\n        - RotateKubeletClientCertificate=true,RotateKubeletServerCertificate=true\n        image-service-endpoint:\n        - /var/run/crio/crio.sock\n        node-labels:\n        - node-role.kubernetes.io/infra=true,node-role.kubernetes.io/master=true,node-role.kubernetes.io/compute=true\n        pod-manifest-path:\n        - /etc/origin/node/pods\n        rotate-certificates:\n        - \'true\'\n        runtime-request-timeout:\n        - 10m\n      masterClientConnectionOverrides:\n        acceptContentTypes: application/vnd.kubernetes.protobuf,application/json\n        burst: 40\n        contentType: application/vnd.kubernetes.protobuf\n        qps: 20\n      masterKubeConfig: node.kubeconfig\n      networkConfig:\n        mtu: 1450\n        networkPluginName: redhat/openshift-ovs-networkpolicy\n      servingInfo:\n        bindAddress: 0.0.0.0:10250\n        bindNetwork: tcp4\n        clientCA: client-ca.crt\n      volumeConfig:\n        localQuota:\n          perFSGroup: null\n      volumeDirectory: /var/lib/origin/openshift.local.volumes\n    volume-config.yaml: |\n      apiVersion: kubelet.config.openshift.io/v1\n      kind: VolumeConfig\n      localQuota:\n        perFSGroup: 512Mi\n  kind: ConfigMap\n  metadata:\n    creationTimestamp: 2018-08-07T14:56:15Z\n    name: node-config-all-in-one\n    namespace: openshift-node\n    resourceVersion: "1057"\n    selfLink: /api/v1/namespaces/openshift-node/configmaps/node-config-all-in-one\n    uid: 0856aa7e-9a52-11e8-b4f0-fa163e0d4482\n- apiVersion: v1\n  data:\n    fluent.conf: |\n      # This file is the fluentd configuration entrypoint. Edit with care.\n\n      @include configs.d/openshift/system.conf\n\n      # In each section below, pre- and post- includes don\'t include anything initially;\n      # they exist to enable future additions to openshift conf as needed.\n\n      ## sources\n      ## ordered so that syslog always runs last...\n      @include configs.d/openshift/input-pre-*.conf\n      @include configs.d/dynamic/input-docker-*.conf\n      @include configs.d/dynamic/input-syslog-*.conf\n      @include configs.d/openshift/input-post-*.conf\n      ##\n\n      <label @INGRESS>\n      ## filters\n        @include configs.d/openshift/filter-pre-*.conf\n        @include configs.d/openshift/filter-retag-journal.conf\n        @include configs.d/openshift/filter-k8s-meta.conf\n        @include configs.d/openshift/filter-kibana-transform.conf\n        @include configs.d/openshift/filter-k8s-flatten-hash.conf\n        @include configs.d/openshift/filter-k8s-record-transform.conf\n        @include configs.d/openshift/filter-syslog-record-transform.conf\n        @include configs.d/openshift/filter-viaq-data-model.conf\n        @include configs.d/openshift/filter-post-*.conf\n      ##\n      </label>\n\n      <label @OUTPUT>\n      ## matches\n        @include configs.d/openshift/output-pre-*.conf\n        @include configs.d/openshift/output-operations.conf\n        @include configs.d/openshift/output-applications.conf\n        # no post - applications.conf matches everything left\n      ##\n      </label>\n    secure-forward.conf: |\n      # <store>\n      # @type secure_forward\n\n      # self_hostname ${hostname}\n      # shared_key <SECRET_STRING>\n\n      # secure yes\n      # enable_strict_verification yes\n\n      # ca_cert_path /etc/fluent/keys/your_ca_cert\n      # ca_private_key_path /etc/fluent/keys/your_private_key\n        # for private CA secret key\n      # ca_private_key_passphrase passphrase\n\n      # <server>\n        # or IP\n      #   host server.fqdn.example.com\n      #   port 24284\n      # </server>\n      # <server>\n        # ip address to connect\n      #   host 203.0.113.8\n        # specify hostlabel for FQDN verification if ipaddress is used for host\n      #   hostlabel server.fqdn.example.com\n      # </server>\n      # </store>\n    throttle-config.yaml: |\n      # Logging example fluentd throttling config file\n\n      #example-project:\n      #  read_lines_limit: 10\n      #\n      #.operations:\n      #  read_lines_limit: 100\n  kind: ConfigMap\n  metadata:\n    creationTimestamp: 2018-08-07T15:36:51Z\n    name: logging-fluentd\n    namespace: openshift-logging\n    resourceVersion: "8922"\n    selfLink: /api/v1/namespaces/openshift-logging/configmaps/logging-fluentd\n    uid: b4b8f35c-9a57-11e8-b5ba-fa163e0d4482\nkind: List\nmetadata:\n  resourceVersion: ""\n  selfLink: ""\n').strip()
OC_GET_BC = ('\napiVersion: v1\nitems:\n- apiVersion: v1\n  kind: BuildConfig\n  metadata:\n    annotations:\n      openshift.io/generated-by: OpenShiftWebConsole\n    creationTimestamp: 2017-11-28T09:02:19Z\n    labels:\n      app: tom\n    name: tom\n    namespace: ci\n    resourceVersion: "8922062"\n    selfLink: /oapi/v1/namespaces/ci/buildconfigs/tom\n    uid: d6a0364c-d41a-11e7-aef1-001a4a010222\n  spec:\n    nodeSelector: null\n    output:\n      to:\n        kind: ImageStreamTag\n        name: tom:latest\n    postCommit: {}\n    resources:\n      limits:\n        cpu: "1"\n        memory: 512m\n      requests:\n        cpu: 100m\n        memory: 256m\n    runPolicy: Serial\n    source:\n      contextDir: tomcat-websocket-chat\n      git:\n        ref: master\n        uri: https://github.com/jboss-openshift/openshift-quickstarts.git\n      type: Git\n    strategy:\n      sourceStrategy:\n        from:\n          kind: ImageStreamTag\n          name: jboss-webserver30-tomcat7-openshift:1.3\n          namespace: openshift\n      type: Source\n    triggers:\n    - generic:\n        secret: 222545c18370f300\n      type: Generic\n    - github:\n        secret: a75ac7b89f8afc22\n      type: GitHub\n    - imageChange:\n        lastTriggeredImageID: registry.access.redhat.com/jboss-webserver-3/webserver30-tomcat7-openshift@sha256:6ee8de68a744d820e249f784b5ba41d059f91a5554fce47c7e0b998aa88c97cb\n      type: ImageChange\n    - type: ConfigChange\n  status:\n    lastVersion: 2\n- apiVersion: v1\n  kind: BuildConfig\n  metadata:\n    annotations:\n      openshift.io/generated-by: OpenShiftWebConsole\n    creationTimestamp: 2017-11-28T09:05:26Z\n    labels:\n      app: mybank\n    name: mybank\n    namespace: mybank\n    resourceVersion: "8961033"\n    selfLink: /oapi/v1/namespaces/mybank/buildconfigs/mybank\n    uid: 46711668-d41b-11e7-aef1-001a4a010222\n  spec:\n    nodeSelector: null\n    output:\n      to:\n        kind: ImageStreamTag\n        name: mybank:latest\n    postCommit: {}\n    resources:\n      limits:\n        cpu: "1"\n        memory: 512m\n      requests:\n        cpu: 100m\n        memory: 256M\n    runPolicy: Serial\n    source:\n      git:\n        ref: master\n        uri: https://github.com/shzhou12/mybank-demo-maven\n      type: Git\n    strategy:\n      sourceStrategy:\n        from:\n          kind: ImageStreamTag\n          name: jboss-eap70-openshift:1.5\n          namespace: openshift\n      type: Source\n    triggers:\n    - generic:\n        secret: 3bf9b0f9eda5bcc3\n      type: Generic\n    - github:\n        secret: a1cea7fe7310d6df\n      type: GitHub\n    - imageChange:\n        lastTriggeredImageID: registry.access.redhat.com/jboss-eap-7/eap70-openshift@sha256:b1b664a9b6f797d530bf12c29123947c1feb4590336ecc9d118b3f2e44000524\n      type: ImageChange\n    - type: ConfigChange\n  status:\n    lastVersion: 11\nkind: List\nmetadata: {}\nresourceVersion: ""\nselfLink: ""\n').strip()
OC_GET_DC = ('\napiVersion: v1\nitems:\n- apiVersion: v1\n  kind: DeploymentConfig\n  metadata:\n    creationTimestamp: 2017-02-14T15:21:51Z\n    generation: 3\n    labels:\n      docker-registry: default\n    name: docker-registry\n    namespace: openshift\n    resourceVersion: "1439616"\n    selfLink: /oapi/v1/namespaces/openshift/deploymentconfigs/docker-registry\n    uid: 4f1cf726-f2c9-11e6-8c0e-001a4a0100d2\n  spec:\n    replicas: 1\n    selector:\n      docker-registry: default\n    strategy:\n      resources: {}\n      rollingParams:\n        intervalSeconds: 1\n        maxSurge: 25%\n        maxUnavailable: 25%\n        timeoutSeconds: 600\n        updatePeriodSeconds: 1\n      type: Rolling\n    template:\n      metadata:\n        creationTimestamp: null\n        labels:\n          docker-registry: default\n      spec:\n        containers:\n        - env:\n          - name: REGISTRY_HTTP_ADDR\n            value: :5000\n          - name: REGISTRY_HTTP_NET\n            value: tcp\n          - name: REGISTRY_HTTP_SECRET\n            value: mysupersecrethttpsecret\n          - name: REGISTRY_MIDDLEWARE_REPOSITORY_OPENSHIFT_ENFORCEQUOTA\n            value: "false"\n          image: registry.access.redhat.com/openshift3/ose-docker-registry\n          imagePullPolicy: Always\n          livenessProbe:\n            failureThreshold: 3\n            httpGet:\n              path: /healthz\n              port: 5000\n              scheme: HTTP\n            initialDelaySeconds: 10\n            periodSeconds: 10\n            successThreshold: 1\n            timeoutSeconds: 5\n          name: registry\n          ports:\n          - containerPort: 5000\n            protocol: TCP\n          readinessProbe:\n            failureThreshold: 3\n            httpGet:\n              path: /healthz\n              port: 5000\n              scheme: HTTP\n            periodSeconds: 10\n            successThreshold: 1\n            timeoutSeconds: 5\n          resources:\n            requests:\n              cpu: 100m\n              memory: 256Mi\n          securityContext:\n            privileged: false\n          terminationMessagePath: /dev/termination-log\n          volumeMounts:\n          - mountPath: /registry\n            name: registry-storage\n        dnsPolicy: ClusterFirst\n        terminationGracePeriodSeconds: 30\n        volumes:\n        - name: registry-storage\n          persistentVolumeClaim:\n            claimName: registry-claim-test1\n    test: false\n    triggers:\n    - type: ConfigChange\n  status:\n    availableReplicas: 1\n    details:\n      causes:\n      - type: ConfigChange\n      message: caused by a config change\n    latestVersion: 3\n    observedGeneration: 3\n    replicas: 1\n    updatedReplicas: 1\n- apiVersion: v1\n  kind: DeploymentConfig\n  metadata:\n    creationTimestamp: 2017-02-20T10:48:11Z\n    generation: 1\n    labels:\n      router: router-1\n    name: router-1\n    namespace: zjj-project\n    resourceVersion: "1638435"\n    selfLink: /oapi/v1/namespaces/zjj-project/deploymentconfigs/router-1\n    uid: 12b9b90f-f75a-11e6-80d0-001a4a0100d2\n  spec:\n    replicas: 1\n    selector:\n      router: router-1\n    strategy:\n      resources: {}\n      rollingParams:\n        intervalSeconds: 1\n        maxSurge: 0\n        maxUnavailable: 25%\n        timeoutSeconds: 600\n        updatePercent: -25\n        updatePeriodSeconds: 1\n      type: Rolling\n    template:\n      metadata:\n        creationTimestamp: null\n        labels:\n          router: router-1\n      spec:\n        containers:\n        - env:\n          - name: DEFAULT_CERTIFICATE_DIR\n            value: /etc/pki/tls/private\n          - name: ROUTER_EXTERNAL_HOST_HOSTNAME\n          - name: ROUTER_EXTERNAL_HOST_HTTPS_VSERVER\n          - name: ROUTER_EXTERNAL_HOST_HTTP_VSERVER\n          - name: ROUTER_EXTERNAL_HOST_INSECURE\n            value: "false"\n          - name: ROUTER_EXTERNAL_HOST_PARTITION_PATH\n          - name: ROUTER_EXTERNAL_HOST_PASSWORD\n          - name: ROUTER_EXTERNAL_HOST_PRIVKEY\n            value: /etc/secret-volume/router.pem\n          - name: ROUTER_EXTERNAL_HOST_USERNAME\n          - name: ROUTER_SERVICE_HTTPS_PORT\n            value: "443"\n          - name: ROUTER_SERVICE_HTTP_PORT\n            value: "80"\n          - name: ROUTER_SERVICE_NAME\n            value: router-1\n          - name: ROUTER_SERVICE_NAMESPACE\n            value: zjj-project\n          - name: ROUTER_SUBDOMAIN\n          - name: STATS_PASSWORD\n            value: password\n          - name: STATS_PORT\n            value: "1936"\n          - name: STATS_USERNAME\n            value: admin\n          image: openshift3/ose-haproxy-router:v3.3.1.7\n          imagePullPolicy: IfNotPresent\n          livenessProbe:\n            failureThreshold: 3\n            httpGet:\n              host: localhost\n              path: /healthz\n              port: 1936\n              scheme: HTTP\n            initialDelaySeconds: 10\n            periodSeconds: 10\n            successThreshold: 1\n            timeoutSeconds: 1\n          name: router\n          ports:\n          - containerPort: 1936\n            hostPort: 1936\n            name: stats\n            protocol: TCP\n          readinessProbe:\n            failureThreshold: 3\n            httpGet:\n              host: localhost\n              path: /healthz\n              port: 1936\n              scheme: HTTP\n            initialDelaySeconds: 10\n            periodSeconds: 10\n            successThreshold: 1\n            timeoutSeconds: 1\n          resources:\n            requests:\n              cpu: 100m\n              memory: 256Mi\n          terminationMessagePath: /dev/termination-log\n          volumeMounts:\n          - mountPath: /etc/pki/tls/private\n            name: server-certificate\n            readOnly: true\n        dnsPolicy: ClusterFirst\n        volumes:\n        - name: server-certificate\n          secret:\n            secretName: router-1-certs\n    test: false\n    triggers:\n    - type: ConfigChange\n  status:\n    availableReplicas: 1\n    details:\n      causes:\n      - type: ConfigChange\n      message: caused by a config change\n    latestVersion: 1\n    observedGeneration: 1\n    replicas: 1\n    updatedReplicas: 1\nkind: List\nmetadata: {}\n').strip()
OC_GET_ROLEBINDING = ('\napiVersion: v1\nitems:\n- apiVersion: v1\n  groupNames: null\n  kind: RoleBinding\n  metadata:\n    creationTimestamp: 2017-03-07T09:00:56Z\n    name: admin\n    namespace: foo\n    resourceVersion: "11803596"\n    selfLink: /oapi/v1/namespaces/foo/rolebindings/admin\n    uid: 93256034-0314-11e7-b98e-001a4a0101f0\n  roleRef:\n    name: admin\n  subjects:\n  - kind: SystemUser\n    name: system:admin\n  userNames:\n  - system:admin\n- apiVersion: v1\n  groupNames: null\n  kind: RoleBinding\n  metadata:\n    creationTimestamp: 2017-03-07T09:00:56Z\n    name: system:image-builders\n    namespace: foo\n    resourceVersion: "11803603"\n    selfLink: /oapi/v1/namespaces/foo/rolebindings/system:image-builders\n    uid: 93709567-0314-11e7-b98e-001a4a0101f0\n  roleRef:\n    name: system:image-builder\n  subjects:\n  - kind: ServiceAccount\n    name: builder\n    namespace: foo\n  userNames:\n  - system:serviceaccount:foo:builder\n- apiVersion: v1\n  groupNames: null\n  kind: RoleBinding\n  metadata:\n    creationTimestamp: null\n    name: myrole\n    namespace: foo\n    resourceVersion: "415"\n    selfLink: /oapi/v1/namespaces/foo/rolebindings/myrole\n  roleRef:\n    name: myrole\n    namespace: foo\n  subjects: null\n  userNames: null\nkind: List\nmetadata: {}\n').strip()
OC_GET_PROJECT = ('\napiVersion: v1\nitems:\n- apiVersion: v1\n  kind: Project\n  metadata:\n    annotations:\n      openshift.io/description: ""\n      openshift.io/display-name: ""\n      openshift.io/requester: testuser\n      openshift.io/sa.scc.mcs: s0:c8,c2\n      openshift.io/sa.scc.supplemental-groups: 1000060000/10000\n      openshift.io/sa.scc.uid-range: 1000060000/10000\n    creationTimestamp: 2017-02-13T03:01:30Z\n    name: zjj-project\n    resourceVersion: "11040756"\n    selfLink: /oapi/v1/projects/zjj-project\n    uid: b83cdc59-f198-11e6-b98e-001a4a0101f0\n  spec:\n    finalizers:\n    - openshift.io/origin\n    - kubernetes\n  status:\n    phase: Active\n- apiVersion: v1\n  kind: Project\n  metadata:\n    annotations:\n      openshift.io/description: ""\n      openshift.io/display-name: ""\n      openshift.io/requester: testuser\n      openshift.io/sa.scc.mcs: s0:c11,c0\n      openshift.io/sa.scc.supplemental-groups: 1000110000/10000\n      openshift.io/sa.scc.uid-range: 1000110000/10000\n    creationTimestamp: 2016-12-27T07:49:13Z\n    name: test\n    resourceVersion: "9401953"\n    selfLink: /oapi/v1/projects/test\n    uid: f5f2a52c-cc08-11e6-8b9b-001a4a0101f0\n  spec:\n    finalizers:\n    - openshift.io/origin\n    - kubernetes\n  status:\n    phase: Active\nkind: List\nmetadata: {}\n').strip()
OC_GET_ROLE = ('\napiVersion: v1\nitems:\n- apiVersion: v1\n  kind: Role\n  metadata:\n    creationTimestamp: 2016-08-30T16:13:03Z\n    name: shared-resource-viewer\n    namespace: openshift\n    resourceVersion: "94"\n    selfLink: /oapi/v1/namespaces/openshift/roles/shared-resource-viewer\n    uid: a10c3f88-6ecc-11e6-83c6-001a4a0101f0\n  rules:\n  - apiGroups: null\n    attributeRestrictions: null\n    resources:\n    - imagestreamimages\n    - imagestreamimports\n    - imagestreammappings\n    - imagestreams\n    - imagestreamtags\n    - templates\n    verbs:\n    - get\n    - list\n  - apiGroups: null\n    attributeRestrictions: null\n    resources:\n    - imagestreams/layers\n    verbs:\n    - get\nkind: List\nmetadata: {}\n').strip()
OC_GET_ROUTE = ('\napiVersion: v1\nitems:\n- apiVersion: v1\n  kind: Route\n  metadata:\n    creationTimestamp: 2018-02-23T04:26:01Z\n    name: docker-registry\n    namespace: default\n    resourceVersion: "4166"\n    selfLink: /oapi/v1/namespaces/default/routes/docker-registry\n    uid: a72a9680-1851-11e8-82e4-001a4a0102eb\n  spec:\n    host: docker-registry-default.router.default.svc.cluster.local\n    tls:\n      termination: passthrough\n    to:\n      kind: Service\n      name: docker-registry\n      weight: 100\n    wildcardPolicy: None\n  status:\n    ingress:\n    - conditions:\n      - lastTransitionTime: 2018-02-23T06:24:02Z\n        status: "True"\n        type: Admitted\n      host: docker-registry-default.router.default.svc.cluster.local\n      routerName: router\n      wildcardPolicy: None\nkind: List\nmetadata: {}\nresourceVersion: ""\nselfLink: ""\n').strip()
OC_GET_PV = ('\napiVersion: v1\nitems:\n- apiVersion: v1\n  kind: PersistentVolume\n  metadata:\n    annotations:\n      pv.kubernetes.io/bound-by-controller: "yes"\n    creationTimestamp: 2017-03-09T15:23:17Z\n    name: registry-volume\n    resourceVersion: "745"\n    selfLink: /api/v1/persistentvolumes/registry-volume\n    uid: 52394d79-04dc-11e7-ab1f-001a4a0101d2\n  spec:\n    accessModes:\n    - ReadWriteMany\n    capacity:\n      storage: 5Gi\n    claimRef:\n      apiVersion: v1\n      kind: PersistentVolumeClaim\n      name: registry-claim\n      namespace: default\n      resourceVersion: "743"\n      uid: 52c44068-04dc-11e7-ab1f-001a4a0101d2\n    nfs:\n      path: /exports/registry\n      server: master.ose33.com\n    persistentVolumeReclaimPolicy: Retain\n  status:\n    phase: Bound\n- apiVersion: v1\n  kind: PersistentVolume\n  metadata:\n    creationTimestamp: 2017-04-05T10:44:54Z\n    name: registry-volume-zjj\n    resourceVersion: "934892"\n    selfLink: /api/v1/persistentvolumes/registry-volume-zjj\n    uid: e7519f6c-19ec-11e7-ab1f-001a4a0101d2\n  spec:\n    accessModes:\n    - ReadWriteMany\n    capacity:\n      storage: 10Gi\n    nfs:\n      path: /nfs\n      server: 10.66.208.147\n    persistentVolumeReclaimPolicy: Recycle\n  status:\n    phase: Available\nkind: List\nmetadata: {}\n').strip()
OC_GET_PVC = ('\napiVersion: v1\nitems:\n- apiVersion: v1\n  kind: PersistentVolumeClaim\n  metadata:\n    annotations:\n      pv.kubernetes.io/bind-completed: "yes"\n      pv.kubernetes.io/bound-by-controller: "yes"\n    creationTimestamp: 2017-03-09T15:23:18Z\n    name: registry-claim\n    namespace: default\n    resourceVersion: "747"\n    selfLink: /api/v1/namespaces/default/persistentvolumeclaims/registry-claim\n    uid: 52c44068-04dc-11e7-ab1f-001a4a0101d2\n  spec:\n    accessModes:\n    - ReadWriteMany\n    resources:\n      requests:\n        storage: 5Gi\n    volumeName: registry-volume\n  status:\n    accessModes:\n    - ReadWriteMany\n    capacity:\n      storage: 5Gi\n    phase: Bound\n- apiVersion: v1\n  kind: PersistentVolumeClaim\n  metadata:\n    annotations:\n      pv.kubernetes.io/bind-completed: "yes"\n    creationTimestamp: 2017-04-12T18:40:43Z\n    name: registry-claim-test1\n    namespace: default\n    resourceVersion: "1084833"\n    selfLink: /api/v1/namespaces/default/persistentvolumeclaims/registry-claim-test1\n    uid: 89169428-1faf-11e7-b236-001a4a0101d2\n  spec:\n    accessModes:\n    - ReadWriteMany\n    resources:\n      requests:\n        storage: 5Gi\n    volumeName: registry-volume-zjj\n  status:\n    accessModes:\n    - ReadWriteMany\n    capacity:\n      storage: 10Gi\n    phase: Bound\nkind: List\nmetadata: {}\n').strip()
OC_GET_ENDPOINTS = ('\napiVersion: v1\nitems:\n- apiVersion: v1\n  kind: Endpoints\n  metadata:\n    creationTimestamp: 2017-06-15T05:53:47Z\n    name: gluster-cluster\n    namespace: default\n    resourceVersion: "35151"\n    selfLink: /api/v1/namespaces/default/endpoints/gluster-cluster\n    uid: ffaf2c59-518e-11e7-a93b-001a4a01010c\n  subsets:\n  - addresses:\n    - ip: 10.64.221.124\n    - ip: 10.64.221.126\n    ports:\n    - port: 1\n      protocol: TCP\n- apiVersion: v1\n  kind: Endpoints\n  metadata:\n    creationTimestamp: 2017-06-14T05:55:59Z\n    name: kubernetes\n    namespace: default\n    resourceVersion: "449"\n    selfLink: /api/v1/namespaces/default/endpoints/kubernetes\n    uid: 240884a8-50c6-11e7-aae8-001a4a01010c\n  subsets:\n  - addresses:\n    - ip: 10.66.219.113\n    ports:\n    - name: https\n      port: 8443\n      protocol: TCP\n    - name: dns-tcp\n      port: 8053\n      protocol: TCP\n    - name: dns\n      port: 8053\n      protocol: UDP\n- apiVersion: v1\n  kind: Endpoints\n  metadata:\n    creationTimestamp: 2017-06-14T07:32:51Z\n    labels:\n      app: registry-console\n      createdBy: registry-console-template\n      name: registry-console\n    name: registry-console\n    namespace: default\n    resourceVersion: "2858"\n    selfLink: /api/v1/namespaces/default/endpoints/registry-console\n    uid: ac78a94e-50d3-11e7-aae8-001a4a01010c\n  subsets:\n  - addresses:\n    - ip: 10.128.0.3\n      nodeName: node1.ose35.com\n      targetRef:\n        kind: Pod\n        name: registry-console-1-jckp2\n        namespace: default\n        resourceVersion: "2854"\n        uid: d5baeab5-50d3-11e7-aae8-001a4a01010c\n    ports:\n    - name: registry-console\n      port: 9090\n      protocol: TCP\nkind: List\nmetadata: {}\nresourceVersion: ""\nselfLink: ""\n').strip()
OC_GET_NODE = ('\napiVersion: v1\nitems:\n- apiVersion: v1\n  kind: Node\n  metadata:\n    annotations:\n      volumes.kubernetes.io/controller-managed-attach-detach: "true"\n    creationTimestamp: 2018-01-09T02:04:15Z\n    labels:\n      beta.kubernetes.io/arch: amd64\n      beta.kubernetes.io/os: linux\n      kubernetes.io/hostname: master37\n      openshift-infra: apiserver\n    name: master37\n    namespace: ""\n    resourceVersion: "4414367"\n    selfLink: /api/v1/nodes/master37\n    uid: 64ce06a1-f4e1-11e7-aa53-001a4a0102af\n  spec:\n    externalID: master37\n    unschedulable: true\n  status:\n    addresses:\n    - address: 10.66.208.248\n      type: InternalIP\n    - address: master37\n      type: Hostname\n    allocatable:\n      cpu: "8"\n      memory: 20587320Ki\n      pods: "80"\n    capacity:\n      cpu: "8"\n      memory: 20689720Ki\n      pods: "80"\n    conditions:\n    - lastHeartbeatTime: 2018-02-02T09:46:46Z\n      lastTransitionTime: 2018-01-09T02:04:15Z\n      message: kubelet has sufficient disk space available\n      reason: KubeletHasSufficientDisk\n      status: "False"\n      type: OutOfDisk\n    - lastHeartbeatTime: 2018-02-02T09:46:46Z\n      lastTransitionTime: 2018-01-09T02:04:15Z\n      message: kubelet has sufficient memory available\n      reason: KubeletHasSufficientMemory\n      status: "False"\n      type: MemoryPressure\n    - lastHeartbeatTime: 2018-02-02T09:46:46Z\n      lastTransitionTime: 2018-01-09T02:04:15Z\n      message: kubelet has no disk pressure\n      reason: KubeletHasNoDiskPressure\n      status: "False"\n      type: DiskPressure\n    daemonEndpoints:\n      kubeletEndpoint:\n        Port: 10250\n    images:\n    - names:\n      - registry.access.redhat.com/openshift3/ose@sha256:c4fe334182030e0878a462998aef2ae48536eb8966c570ddb2710a11b8e9ac82\n      - registry.access.redhat.com/openshift3/ose:v3.7\n      sizeBytes: 1059063314\n    - names:\n      - registry.access.redhat.com/openshift3/ose-service-catalog@sha256:e06e609d21f1df6ff396a4d95caade01149e3ee706490b9665708fd95ba84ad0\n      - registry.access.redhat.com/openshift3/ose-service-catalog:v3.7\n      sizeBytes: 268789707\n    - names:\n      - registry.access.redhat.com/openshift3/ose-pod@sha256:5b397b3fd1bb98e53e829b8938f853364d3ff85d85f2e011fae3f67757e9cf96\n      - registry.access.redhat.com/openshift3/ose-pod:v3.7.14\n      sizeBytes: 208847376\n    nodeInfo:\n      architecture: amd64\n      bootID: e998fc70-8d7d-47ac-81c6-72a662c68424\n      containerRuntimeVersion: docker://1.12.6\n      kernelVersion: 3.10.0-693.11.6.el7.x86_64\n      kubeProxyVersion: v1.7.6+a08f5eeb62\n      kubeletVersion: v1.7.6+a08f5eeb62\n      machineID: 897d22c8a60d434b9b5857ffa80064e4\n      operatingSystem: linux\n      osImage: Employee SKU\n      systemUUID: 897D22C8-A60D-434B-9B58-57FFA80064E4\n').strip()
OC_GET_RC = ('\napiVersion: v1\nitems:\n- apiVersion: v1\n  kind: ReplicationController\n  metadata:\n    annotations:\n      openshift.io/deployer-pod.name: jenkins-1-deploy\n      openshift.io/deployment-config.latest-version: "1"\n      openshift.io/deployment-config.name: jenkins\n      openshift.io/deployment.phase: Complete\n      openshift.io/deployment.replicas: "1"\n      openshift.io/deployment.status-reason: image change\n    creationTimestamp: 2017-11-28T08:24:39Z\n    generation: 2\n    labels:\n      app: jenkins-ephemeral\n      openshift.io/deployment-config.name: jenkins\n      template: jenkins-ephemeral-template\n    name: jenkins-1\n    namespace: ci\n    resourceVersion: "9998736"\n    selfLink: /api/v1/namespaces/ci/replicationcontrollers/jenkins-1\n    uid: 93a12b07-d415-11e7-aef1-001a4a010222\n  spec:\n    replicas: 1\n    selector:\n      deployment: jenkins-1\n      deploymentconfig: jenkins\n      name: jenkins\n    template:\n      metadata:\n        annotations:\n          openshift.io/deployment-config.latest-version: "1"\n          openshift.io/deployment-config.name: jenkins\n          openshift.io/deployment.name: jenkins-1\n          openshift.io/generated-by: OpenShiftNewApp\n        creationTimestamp: null\n        labels:\n          app: jenkins-ephemeral\n          deployment: jenkins-1\n          deploymentconfig: jenkins\n          name: jenkins\n      spec:\n        containers:\n        - env:\n          - name: JENKINS_PASSWORD\n            value: welcome1\n          - name: KUBERNETES_MASTER\n            value: https://kubernetes.default:443\n          - name: KUBERNETES_TRUST_CERTIFICATES\n            value: "true"\n          - name: JNLP_SERVICE_NAME\n            value: jenkins-jnlp\n          name: jenkins\n          readinessProbe:\n            failureThreshold: 3\n            httpGet:\n              path: /login\n              port: 8080\n              scheme: HTTP\n            initialDelaySeconds: 3\n            periodSeconds: 10\n            successThreshold: 1\n            timeoutSeconds: 3\n          resources:\n            limits:\n              memory: 512Mi\n          securityContext:\n            capabilities: {}\n            privileged: false\n          terminationMessagePath: /dev/termination-log\n          volumeMounts:\n          - mountPath: /var/lib/jenkins\n            name: jenkins-data\n        dnsPolicy: ClusterFirst\n        restartPolicy: Always\n        securityContext: {}\n        serviceAccount: jenkins\n        serviceAccountName: jenkins\n        terminationGracePeriodSeconds: 30\n        volumes:\n        - emptyDir: {}\n          name: jenkins-data\n  status:\n    availableReplicas: 1\n    fullyLabeledReplicas: 1\n    observedGeneration: 2\n    readyReplicas: 1\n    replicas: 1\n').strip()
OC_GET_EVENT = ('\napiVersion: v1\nitems:\n- apiVersion: v1\n  count: 5613\n  firstTimestamp: 2018-01-12T02:38:19Z\n  involvedObject:\n    apiVersion: v1\n    fieldPath: spec.containers{busybox}\n    kind: Pod\n    name: busybox\n    namespace: ci\n    resourceVersion: "10897114"\n    uid: 69f22749-f1da-11e7-989a-001a4a010222\n  kind: Event\n  lastTimestamp: 2018-02-02T09:49:42Z\n  message: pulling image "busybox"\n  metadata:\n    creationTimestamp: 2018-01-12T02:38:19Z\n    name: busybox.1508ef957b1935a4\n    namespace: ci\n    resourceVersion: "12356614"\n    selfLink: /api/v1/namespaces/ci/events/busybox.1508ef957b1935a4\n    uid: a648ed7c-f741-11e7-989a-001a4a010222\n  reason: Pulling\n  source:\n    component: kubelet\n    host: node2\n  type: Normal\n- apiVersion: v1\n  count: 1\n  firstTimestamp: 2018-02-05T01:55:35Z\n  involvedObject:\n    apiVersion: v1\n    kind: Pod\n    name: ruby-ex-2-htczn\n    namespace: test-ruby\n    resourceVersion: "4892941"\n    uid: a82ecd0f-0a17-11e8-97fa-001a4a0102af\n  kind: Event\n  lastTimestamp: 2018-02-05T01:55:35Z\n  message: Successfully assigned ruby-ex-2-htczn to node237\n  metadata:\n    creationTimestamp: 2018-02-05T01:55:35Z\n    name: ruby-ex-2-htczn.15104b2e14a7ffc7\n    namespace: test-ruby\n    resourceVersion: "4892946"\n    selfLink: /api/v1/namespaces/test-ruby/events/ruby-ex-2-htczn.15104b2e14a7ffc7\n    uid: a831518d-0a17-11e8-97fa-001a4a0102af\n  reason: Scheduled\n  source:\n    component: default-scheduler\n  type: Normal\n- apiVersion: v1\n  count: 1\n  firstTimestamp: 2018-02-05T01:55:35Z\n  involvedObject:\n    apiVersion: v1\n    kind: ReplicationController\n    name: ruby-ex-2\n    namespace: test-ruby\n    resourceVersion: "4892939"\n    uid: a57f2d52-0a17-11e8-97fa-001a4a0102af\n  kind: Event\n  lastTimestamp: 2018-02-05T01:55:35Z\n  message: \'Created pod: ruby-ex-2-htczn\'\n  metadata:\n    creationTimestamp: 2018-02-05T01:55:35Z\n    name: ruby-ex-2.15104b2e13fcd0ca\n    namespace: test-ruby\n    resourceVersion: "4892945"\n    selfLink: /api/v1/namespaces/test-ruby/events/ruby-ex-2.15104b2e13fcd0ca\n    uid: a82fc0ed-0a17-11e8-97fa-001a4a0102af\n  reason: SuccessfulCreate\n  source:\n    component: replication-controller\n  type: Normal\n- apiVersion: v1\n  count: 1\n  firstTimestamp: 2018-02-05T01:55:31Z\n  involvedObject:\n    apiVersion: apps.openshift.io\n    kind: DeploymentConfig\n    name: ruby-ex\n    namespace: test-ruby\n    resourceVersion: "4892911"\n    uid: dafbf582-04a4-11e8-97fa-001a4a0102af\n  kind: Event\n  lastTimestamp: 2018-02-05T01:55:31Z\n  message: Created new replication controller "ruby-ex-2" for version 2\n  metadata:\n    creationTimestamp: 2018-02-05T01:55:31Z\n    name: ruby-ex.15104b2d079675f7\n    namespace: test-ruby\n    resourceVersion: "4892913"\n    selfLink: /api/v1/namespaces/test-ruby/events/ruby-ex.15104b2d079675f7\n    uid: a580c543-0a17-11e8-97fa-001a4a0102af\n  reason: DeploymentCreated\n  source:\n    component: deploymentconfig-controller\n  type: Normal\nkind: List\nmetadata:\n  resourceVersion: ""\n  selfLink: ""\n').strip()
OC_GET_EGRESS_NETWORK_POLICY = ('\napiVersion: v1\nitems:\n- apiVersion: v1\n  kind: EgressNetworkPolicy\n  metadata:\n    creationTimestamp: 2018-01-29T03:31:59Z\n    name: policy-test\n    namespace: test-ruby\n    resourceVersion: "3649310"\n    selfLink: /oapi/v1/namespaces/test-ruby/egressnetworkpolicies/policy-test\n    uid: f6b065cc-04a4-11e8-97fa-001a4a0102af\n  spec:\n    egress:\n    - to:\n        dnsName: www.baidu.com\n      type: Allow\n    - to:\n        cidrSelector: 0.0.0.0/0\n      type: Deny\nkind: List\nmetadata:\n  resourceVersion: ""\n  selfLink: ""\n').strip()
OC_GET_BUILD = '\napiVersion: v1\nitems:\n- apiVersion: build.openshift.io/v1\n  kind: Build\n  metadata:\n    annotations:\n      openshift.io/build-config.name: sample-app\n      openshift.io/build.number: "2"\n      openshift.io/build.pod-name: sample-app-2-build\n    creationTimestamp: 2018-05-08T13:25:35Z\n    labels:\n      app: sample-app\n      buildconfig: sample-app\n      openshift.io/build-config.name: sample-app\n      openshift.io/build.start-policy: Serial\n    name: sample-app-2\n    namespace: default\n    ownerReferences:\n    - apiVersion: build.openshift.io/v1\n      controller: true\n      kind: BuildConfig\n      name: sample-app\n      uid: 014c30d6-52c3-11e8-8f2a-001a4a16016f\n    resourceVersion: "38277"\n    selfLink: /apis/build.openshift.io/v1/namespaces/default/builds/sample-app-2\n    uid: 4a656a4e-52c3-11e8-8f2a-001a4a16016f\n  spec:\n    nodeSelector: null\n    output:\n      pushSecret:\n        name: builder-dockercfg-hwnx4\n      to:\n        kind: ImageStreamTag\n        name: sample-app:latest\n    postCommit: {}\n    resources: {}\n    serviceAccount: builder\n    source:\n      git:\n        uri: https://example.com/mfojtik/sample-app.git\n      type: Git\n    strategy:\n      sourceStrategy:\n        from:\n          kind: DockerImage\n          name: registry.access.example.com/rhscl/ruby-24-rhel7@sha256:da812edc2a0c0c8c28854daeb7629c733dcc5672c33d44f920ea8f1f2d6a058d\n      type: Source\n    triggeredBy:\n    - message: Manually triggered\n  status:\n    config:\n      kind: BuildConfig\n      name: sample-app\n      namespace: default\n    output: {}\n    outputDockerImageReference: docker-registry.example.svc:5000/default/sample-app:latest\n    phase: Pending\nkind: List\nmetadata:\n  resourceVersion: ""\n  selfLink: ""\n'

def test_oc_get_pod_yml():
    result = openshift_get.OcGetPod(context_wrap(OC_GET_POD))
    assert result.data['items'][0]['metadata']['annotations']['openshift.io/scc'] == 'anyuid'
    ct = result.data['items'][0]['metadata']['creationTimestamp'].replace(tzinfo=None)
    assert ct == datetime.datetime(2017, 2, 10, 16, 33, 46, tzinfo=None)
    assert result.data['items'][0]['spec']['host'] == 'node2.ose.com'
    assert result.get('items')[0]['spec']['host'] == 'node2.ose.com'
    assert result.pods['router-1-1-w27o2']['metadata']['labels']['deploymentconfig'] == 'router-1'
    return


def test_oc_get_service_yml():
    result = openshift_get.OcGetService(context_wrap(OC_GET_SERVICE))
    assert result.data['items'][0]['kind'] == 'Service'
    assert result.data['items'][0]['spec']['clusterIP'] == '172.30.0.1'
    assert result.data['items'][0]['metadata']['name'] == 'kubernetes'
    assert result.data['items'][1]['metadata']['name'] == 'router-1'
    assert result.data['items'][1]['spec']['ports'][0]['port'] == 80
    assert result.data['kind'] == 'List'
    assert result.data['metadata'] == {}
    assert result.get('items')[0]['spec']['clusterIP'] == '172.30.0.1'
    assert 'zjj-project' in result.data['items'][1]['metadata']['namespace']
    assert result.services['router-1']['metadata']['resourceVersion'] == '1638401'


def test_oc_get_configmap_yml():
    result = openshift_get.OcGetConfigmap(context_wrap(OC_GET_CONFIGMAP))
    assert result.data['items'][0]['kind'] == 'ConfigMap'
    assert result.data['items'][0]['metadata']['name'] == 'node-config-all-in-one'


def test_oc_get_bc_yml():
    result = openshift_get.OcGetBc(context_wrap(OC_GET_BC))
    assert result['items'][0]['kind'] == 'BuildConfig'
    assert result['items'][1]['metadata']['name'] == 'mybank'
    assert result.build_configs['mybank']['status']['lastVersion'] == 11
    assert result.build_configs['tom']['metadata']['namespace'] == 'ci'


def test_oc_get_dc_yml():
    result = openshift_get.OcGetDc(context_wrap(OC_GET_DC))
    assert result.data['items'][0]['kind'] == 'DeploymentConfig'
    assert result.data['items'][0]['metadata']['generation'] == 3
    assert result.get('items')[0]['metadata']['generation'] == 3
    assert result.deployment_configs['router-1']['metadata']['namespace'] == 'zjj-project'


def test_oc_get_rolebinding_yml():
    result = openshift_get.OcGetRolebinding(context_wrap(OC_GET_ROLEBINDING))
    assert result.data['items'][0]['kind'] == 'RoleBinding'
    assert result.data['items'][0]['metadata']['resourceVersion'] == '11803596'
    assert result.get('items')[0]['metadata']['resourceVersion'] == '11803596'
    assert result.rolebindings['myrole']['roleRef']['namespace'] == 'foo'


def test_oc_get_project_yml():
    result = openshift_get.OcGetProject(context_wrap(OC_GET_PROJECT))
    assert result.data['items'][0]['kind'] == 'Project'
    assert result.data['items'][0]['metadata']['resourceVersion'] == '11040756'
    assert result.get('items')[0]['metadata']['resourceVersion'] == '11040756'
    assert result.projects['test']['status']['phase'] == 'Active'


def test_oc_get_role_yml():
    result = openshift_get.OcGetRole(context_wrap(OC_GET_ROLE))
    assert result.data['items'][0]['kind'] == 'Role'
    assert result.data['items'][0]['metadata']['resourceVersion'] == '94'
    assert result.get('items')[0]['metadata']['resourceVersion'] == '94'
    assert result.roles['shared-resource-viewer']['metadata']['uid'] == 'a10c3f88-6ecc-11e6-83c6-001a4a0101f0'


def test_oc_get_pv_yml():
    result = openshift_get.OcGetPv(context_wrap(OC_GET_PV))
    assert result.data['items'][0]['kind'] == 'PersistentVolume'
    assert result.data['items'][0]['metadata']['name'] == 'registry-volume'
    assert result.get('items')[0]['metadata']['name'] == 'registry-volume'
    assert result.persistent_volumes['registry-volume-zjj']['spec']['capacity']['storage'] == '10Gi'


def test_oc_get_pvc_yml():
    result = openshift_get.OcGetPvc(context_wrap(OC_GET_PVC))
    assert result.data['items'][0]['kind'] == 'PersistentVolumeClaim'
    assert result.data['items'][0]['metadata']['name'] == 'registry-claim'
    assert result.get('items')[0]['metadata']['name'] == 'registry-claim'
    assert result.persistent_volume_claims['registry-claim-test1']['spec']['volumeName'] == 'registry-volume-zjj'


def test_oc_get_endpoints_yml():
    result = openshift_get.OcGetEndPoints(context_wrap(OC_GET_ENDPOINTS))
    assert result.data['items'][0]['kind'] == 'Endpoints'
    assert result.data['items'][0]['metadata']['name'] == 'gluster-cluster'
    assert result.get('items')[0]['metadata']['name'] == 'gluster-cluster'
    assert result.endpoints['kubernetes']['subsets'][0]['addresses'][0]['ip'] == '10.66.219.113'


def test_oc_get_node():
    result = openshift_get.OcGetNode(context_wrap(OC_GET_NODE))
    assert result.data['items'][0]['kind'] == 'Node'
    assert result.data['items'][0]['metadata']['name'] == 'master37'
    assert result.get('items')[0]['metadata']['uid'] == '64ce06a1-f4e1-11e7-aa53-001a4a0102af'
    assert result.nodes['master37']['spec']['unschedulable'] is True


def test_oc_get_rc():
    result = openshift_get.OcGetRc(context_wrap(OC_GET_RC))
    assert result.data['items'][0]['kind'] == 'ReplicationController'
    assert result.data['items'][0]['metadata']['selfLink'] == '/api/v1/namespaces/ci/replicationcontrollers/jenkins-1'
    assert result.get('items')[0]['spec']['replicas'] == 1
    assert result.replication_controllers['jenkins-1']['spec']['selector']['deployment'] == 'jenkins-1'


def test_oc_get_event():
    result = openshift_get.OcGetEvent(context_wrap(OC_GET_EVENT))
    assert result.data['items'][0]['kind'] == 'Event'
    assert result.data['items'][2]['involvedObject']['kind'] == 'ReplicationController'
    assert result.get('items')[1]['message'] == 'Successfully assigned ruby-ex-2-htczn to node237'
    assert result.events['busybox.1508ef957b1935a4']['type'] == 'Normal'


def test_oc_get_egressnetworkpolicy_yml():
    result = openshift_get.OcGetEgressNetworkPolicy(context_wrap(OC_GET_EGRESS_NETWORK_POLICY))
    assert result.data['items'][0]['kind'] == 'EgressNetworkPolicy'
    ct = result.data['items'][0]['metadata']['creationTimestamp'].replace(tzinfo=None)
    assert ct == datetime.datetime(2018, 1, 29, 3, 31, 59, tzinfo=None)
    assert result.get('items')[0]['metadata']['name'] == 'policy-test'
    assert result.egress_network_policies['policy-test']['spec']['egress'][0]['to']['dnsName'] == 'www.baidu.com'
    return


def test_oc_get_services_doc_example():
    env = {'OcGetService': openshift_get.OcGetService, 
       'setting_dic': openshift_get.OcGetService(context_wrap(OC_GET_SERVICE))}
    failed, total = doctest.testmod(openshift_get, globs=env)
    assert failed == 0


def test_oc_get_route():
    result = openshift_get.OcGetRoute(context_wrap(OC_GET_ROUTE))
    assert result.data['items'][0]['kind'] == 'Route'
    assert result.data['items'][0]['metadata']['name'] == 'docker-registry'
    assert result.get('items')[0]['spec']['host'] == 'docker-registry-default.router.default.svc.cluster.local'
    assert result.routes['docker-registry']['spec']['wildcardPolicy'] == 'None'


def test_oc_get_build():
    result = openshift_get.OcGetBuild(context_wrap(OC_GET_BUILD))
    assert result.data['items'][0]['kind'] == 'Build'
    assert result.data['items'][0]['metadata']['annotations']['openshift.io/build.pod-name'] == 'sample-app-2-build'
    assert result.get('items')[0]['status']['phase'] == 'Pending'
    assert result.started_builds['sample-app-2']['status']['config']['kind'] == 'BuildConfig'