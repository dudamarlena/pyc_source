# uncompyle6 version 3.7.4
# Python bytecode 2.7 (62211)
# Decompiled from: Python 3.6.9 (default, Apr 18 2020, 01:56:04) 
# [GCC 8.4.0]
# Embedded file name: build/bdist.linux-x86_64/egg/toil_vg/vg_config.py
# Compiled at: 2018-11-03 15:09:40
"""
vg_config.py: Default configuration values all here (and only here), as well as logic
for reading and generating config files.

"""
from __future__ import print_function
import argparse, sys, os, os.path, errno, random, subprocess, shutil, itertools, glob, tarfile, doctest, re, json, collections, time, timeit, logging, logging.handlers, SocketServer, struct, socket, threading, string, urlparse, getpass, pdb, textwrap, yaml
from toil_vg.vg_common import require, test_docker
default_config = textwrap.dedent('\n# Toil VG Pipeline configuration file (created by toil-vg generate-config)\n# This configuration file is formatted in YAML. Simply write the value (at least one space) after the colon.\n# Edit the values in the configuration file and then rerun the pipeline: "toil-vg run"\n# \n# URLs can take the form: "/", "s3://"\n# Local inputs follow the URL convention: "/full/path/to/input.txt"\n# S3 URLs follow the convention: "s3://bucket/directory/file.txt"\n#\n# Comments (beginning with #) do not need to be removed. \n# Command-line options take priority over parameters in this file.  \n######################################################################################################################\n\n###########################################\n### Toil resource tuning                ###\n\n# These parameters must be adjusted based on data and cluster size\n# when running on anything other than single-machine mode\n\n# TODO: Reduce number of parameters here.  Seems fine grained, especially for disk/mem\n# option to spin off config files for small/medium/large datasets?   \n\n# The following parameters assign resources to small helper jobs that typically don\'t do \n    # do any computing outside of toil overhead.  Generally do not need to be changed. \nmisc-cores: 1\nmisc-mem: \'1G\'\nmisc-disk: \'1G\'\n\n# Resources allotted for vg construction.\nconstruct-cores: 1\nconstruct-mem: \'4G\'\nconstruct-disk: \'2G\'\n\n# Resources allotted for xg indexing.\nxg-index-cores: 1\nxg-index-mem: \'4G\'\nxg-index-disk: \'2G\'\n\n# Resources allotted for xg indexing by chromosome (used for GBWT).\ngbwt-index-cores: 1\ngbwt-index-mem: \'4G\'\ngbwt-index-disk: \'2G\'\ngbwt-index-preemptable: \'True\'\n\n# Resources allotted for gcsa pruning.  Note that the vg mod commands used in\n# this stage generally cannot take advantage of more than one thread\nprune-cores: 1\nprune-mem: \'4G\'\nprune-disk: \'2G\'\n\n# Resources allotted gcsa indexing\ngcsa-index-cores: 1\ngcsa-index-mem: \'4G\'\ngcsa-index-disk: \'2G\'\ngcsa-index-preemptable: \'True\'\n\n# Resources allotted for snarl indexing.\nsnarl-index-cores: 1\nsnarl-index-mem: \'4G\'\nsnarl-index-disk: \'2G\'\n\n# Resources for BWA indexing.\nbwa-index-cores: 1\nbwa-index-mem: \'4G\'\nbwa-index-disk: \'2G\'\n\n# Resources for fastq splitting and gam merging\n# Important to assign as many cores as possible here for large fastq inputs\nfq-split-cores: 1\nfq-split-mem: \'4G\'\nfq-split-disk: \'2G\'\n\n# Number of threads to use for Rocksdb GAM indexing\n# Generally, this should be kept low as speedup drops off radically \n# after a few threads.\ngam-index-cores: 1\n\n# Resources for *each* vg map job\n# the number of vg map jobs is controlled by reads-per-chunk (below)\nalignment-cores: 1\nalignment-mem: \'4G\'\nalignment-disk: \'2G\'\n\n# Resources for chunking up a graph/gam for calling (and merging)\n# typically take xg for whoe grpah, and gam for a chromosome,\n# and split up into chunks of call-chunk-size (below)\ncall-chunk-cores: 1\ncall-chunk-mem: \'4G\'\ncall-chunk-disk: \'2G\'\n\n# Resources for calling each chunk (currently includes augment/call/genotype)\ncalling-cores: 1\ncalling-mem: \'4G\'\ncalling-disk: \'2G\'\n\n# Resources for vcfeval\nvcfeval-cores: 1\nvcfeval-mem: \'4G\'\nvcfeval-disk: \'2G\'\n\n# Resources for vg sim\nsim-cores: 2\nsim-mem: \'4G\'\nsim-disk: \'2G\'\n\n###########################################\n### Arguments Shared Between Components ###\n# Use output store instead of toil for all intermediate files (use only for debugging)\nforce-outstore: False\n\n# Toggle container support.  Valid values are Docker / Singularity / None\n# (commenting out or Null values equivalent to None)\ncontainer: ' + ('Docker' if test_docker() else 'None') + "\n\n#############################\n### Docker Tool Arguments ###\n\n## Docker Tool List ##\n##   Locations of docker images. \n##   If empty or commented, then the tool will be run directly from the command line instead\n##   of through docker. \n\n# Docker image to use for vg\nvg-docker: 'quay.io/vgteam/vg:v1.11.0-0-gea4aaded-t241-run'\n\n# Docker image to use for bcftools\nbcftools-docker: 'vandhanak/bcftools:1.3.1'\n\n# Docker image to use for tabix\ntabix-docker: 'vandhanak/bcftools:1.3.1'\n\n# Docker image to use for samtools\nsamtools-docker: 'quay.io/ucsc_cgl/samtools:latest'\n\n# Docker image to use for bwa\nbwa-docker: 'quay.io/ucsc_cgl/bwa:latest'\n\n# Docker image to use for jq\njq-docker: 'devorbitus/ubuntu-bash-jq-curl'\n\n# Docker image to use for rtg\nrtg-docker: 'realtimegenomics/rtg-tools:3.8.4'\n\n# Docker image to use for pigz\npigz-docker: 'quay.io/glennhickey/pigz:latest'\n\n# Docker image to use to run R scripts\nr-docker: 'rocker/tidyverse:3.5.1'\n\n# Docker image to use for vcflib\nvcflib-docker: 'quay.io/biocontainers/vcflib:1.0.0_rc1--0'\n\n# Docker image to use for Freebayes\nfreebayes-docker: 'maxulysse/freebayes:1.2.5'\n\n# Docker image to use for Platypus\nplatypus-docker: 'quay.io/biocontainers/platypus-variant:0.8.1.1--htslib1.7_1'\n\n# Docker image to use for hap.py\nhappy-docker: 'donfreed12/hap.py:v0.3.9'\n\n# Docker image to use for bedtools\nbedtools-docker: 'quay.io/biocontainers/bedtools:2.27.0--1'\n\n# Docker image to use for bedops\nbedops-docker: 'quay.io/biocontainers/bedops:2.4.35--0'\n\n##########################\n### vg_index Arguments ###\n\n# Name of index output files.  ex <name>.xg, <name>.gcsa etc. \nindex-name: 'genome'\n\n# Options to pass to vg prune.\n# (limit to general parameters, currently -k, -e, s.  \n# Rest decided by toil-vg via other options like prune-mode)\nprune-opts: []\n\n# Options to pass to vg gcsa indexing\ngcsa-opts: []\n\n########################\n### vg_map Arguments ###\n\n# Toggle whether reads are split into chunks\nsingle-reads-chunk: False\n\n# Number of reads per chunk to use when splitting up fastq.\n# (only applies if single-reads-chunk is False)\n# Each chunk will correspond to a vg map job\nreads-per-chunk: 10000000\n\n# Core arguments for vg mapping (do not include file names or -t/--threads)\n# Note -i/--interleaved will be ignored. use the --interleaved option \n# on the toil-vg command line instead\nmap-opts: []\n\n# Core arguments for vg multipath mapping (do not include file names or -t/--threads)\nmpmap-opts: ['--single-path-mode']\n\n#########################\n### vg_call Arguments ###\n# Overlap option that is passed into make_chunks and call_chunk\noverlap: 2000\n\n# Chunk size\ncall-chunk-size: 2000000\n\n# Context expansion used for graph chunking\nchunk_context: 50\n\n# Options to pass to vg filter when running vg call. (do not include file names or -t/--threads)\nfilter-opts: ['-r', '0.9', '-fu', '-s', '1000', '-m', '1', '-q', '15', '-D', '999']\n\n# Options to pass to vg augment. (do not include any file names or -t/--threads or -a/--augmentation-mode)\naugment-opts: ['-q', '10']\n\n# Options to pass to vg call. (do not include file/contig/sample names or -t/--threads)\ncall-opts: []\n\n# Options to pass to vg genotype. (do not include file/contig/sample names or -t/--threads)\ngenotype-opts: []\n\n# Use vg genotype instead of vg call\ngenotype: False\n\n#########################\n### vcfeval Arguments ###\n# Options to pass to rgt vcfeval. (do not include filenaems or threads or BED)\nvcfeval-opts: ['--ref-overlap', '--vcf-score-field', 'QUAL']\n\n#########################\n### sim and mapeval Arguments ###\n# Options to pass to vg sim (should not include -x, -n, -s or -a)\nsim-opts: ['--read-length', '150', '--frag-len', '570', '--frag-std-dev', '165', '--sub-rate', '0.01', '--indel-rate', '0.002']\n\n# Options to pass to bwa\nbwa-opts: []\n\n")
whole_genome_config = textwrap.dedent('\n# Toil VG Pipeline configuration file (created by toil-vg generate-config)\n# This configuration file is formatted in YAML. Simply write the value (at least one space) after the colon.\n# Edit the values in the configuration file and then rerun the pipeline: "toil-vg run"\n# \n# URLs can take the form: "/", "s3://"\n# Local inputs follow the URL convention: "/full/path/to/input.txt"\n# S3 URLs follow the convention: "s3://bucket/directory/file.txt"\n#\n# Comments (beginning with #) do not need to be removed. \n# Command-line options take priority over parameters in this file.  \n######################################################################################################################\n\n###########################################\n### Toil resource tuning                ###\n\n# These parameters must be adjusted based on data and cluster size\n# when running on anything other than single-machine mode\n\n# TODO: Reduce number of parameters here.  Seems fine grained, especially for disk/mem\n# option to spin off config files for small/medium/large datasets?   \n\n# The following parameters assign resources to small helper jobs that typically don\'t do \n    # do any computing outside of toil overhead.  Generally do not need to be changed. \nmisc-cores: 1\nmisc-mem: \'1G\'\nmisc-disk: \'1G\'\n\n# Resources allotted for vg construction.\nconstruct-cores: 1\nconstruct-mem: \'32G\'\nconstruct-disk: \'32G\'\n\n# Resources allotted for xg indexing.\nxg-index-cores: 16\nxg-index-mem: \'200G\'\nxg-index-disk: \'100G\'\n\n# Resources allotted for xg indexing by chromosome (used for GBWT).\ngbwt-index-cores: 4\ngbwt-index-mem: \'50G\'\ngbwt-index-disk: \'100G\'\ngbwt-index-preemptable: \'False\'\n\n# Resources allotted for gcsa pruning.  Note that the vg mod commands used in\n# this stage generally cannot take advantage of more than one thread\nprune-cores: 2\nprune-mem: \'60G\'\nprune-disk: \'60G\'\n\n# Resources allotted gcsa indexing\ngcsa-index-cores: 16\ngcsa-index-mem: \'110G\'\ngcsa-index-disk: \'2200G\'\ngcsa-index-preemptable: \'False\'\n\n# Resources alloted to snarl indexing\nsnarl-index-cores: 1\nsnarl-index-mem: \'200G\'\nsnarl-index-disk: \'100G\'\n\n# Resources for BWA indexing.\nbwa-index-cores: 1\nbwa-index-mem: \'40G\'\nbwa-index-disk: \'40G\'\n\n# Resources for fastq splitting and gam merging\n# Important to assign as many cores as possible here for large fastq inputs\nfq-split-cores: 32\nfq-split-mem: \'4G\'\nfq-split-disk: \'200G\'\n\n# Number of threads to use for Rocksdb GAM indexing\n# Generally, this should be kept low as speedup drops off radically \n# after a few threads.\ngam-index-cores: 6\n\n# Resources for *each* vg map job\n# the number of vg map jobs is controlled by reads-per-chunk (below)\nalignment-cores: 32\nalignment-mem: \'100G\'\nalignment-disk: \'100G\'\n\n# Resources for chunking up a graph/gam for calling (and merging)\n# typically take xg for whoe grpah, and gam for a chromosome,\n# and split up into chunks of call-chunk-size (below)\ncall-chunk-cores: 8\ncall-chunk-mem: \'100G\'\ncall-chunk-disk: \'100G\'\n\n# Resources for calling each chunk (currently includes augment/call/genotype)\ncalling-cores: 4\ncalling-mem: \'64G\'\ncalling-disk: \'16G\'\n\n# Resources for vcfeval\nvcfeval-cores: 32\nvcfeval-mem: \'64G\'\nvcfeval-disk: \'64G\'\n\n# Resources for vg sim\nsim-cores: 2\nsim-mem: \'20G\'\nsim-disk: \'200G\'\n\n###########################################\n### Arguments Shared Between Components ###\n# Use output store instead of toil for all intermediate files (use only for debugging)\nforce-outstore: False\n\n# Toggle container support.  Valid values are Docker / Singularity / None\n# (commenting out or Null values equivalent to None)\ncontainer: ' + ('Docker' if test_docker() else 'None') + "\n\n#############################\n### Docker Tool Arguments ###\n\n## Docker Tool List ##\n##   Locations of docker images. \n##   If empty or commented, then the tool will be run directly from the command line instead\n##   of through docker. \n\n# Docker image to use for vg\nvg-docker: 'quay.io/vgteam/vg:v1.11.0-0-gea4aaded-t241-run'\n\n# Docker image to use for bcftools\nbcftools-docker: 'vandhanak/bcftools:1.3.1'\n\n# Docker image to use for tabix\ntabix-docker: 'vandhanak/bcftools:1.3.1'\n\n# Docker image to use for samtools\nsamtools-docker: 'quay.io/ucsc_cgl/samtools:latest'\n\n# Docker image to use for bwa\nbwa-docker: 'quay.io/ucsc_cgl/bwa:latest'\n\n# Docker image to use for jq\njq-docker: 'devorbitus/ubuntu-bash-jq-curl'\n\n# Docker image to use for rtg\nrtg-docker: 'realtimegenomics/rtg-tools:3.8.4'\n\n# Docker image to use for pigz\npigz-docker: 'quay.io/glennhickey/pigz:latest'\n\n# Docker image to use to run R scripts\nr-docker: 'rocker/tidyverse:3.5.1'\n\n# Docker image to use for vcflib\nvcflib-docker: 'quay.io/biocontainers/vcflib:1.0.0_rc1--0'\n\n# Docker image to use for Freebayes\nfreebayes-docker: 'maxulysse/freebayes:1.2.5'\n\n# Docker image to use for Platypus\nplatypus-docker: 'quay.io/biocontainers/platypus-variant:0.8.1.1--htslib1.7_1'\n\n# Docker image to use for hap.py\nhappy-docker: 'donfreed12/hap.py:v0.3.9'\n\n# Docker image to use for bedtools\nbedtools-docker: 'quay.io/biocontainers/bedtools:2.27.0--1'\n\n# Docker image to use for bedops\nbedops-docker: 'quay.io/biocontainers/bedops:2.4.35--0'\n\n\n##########################\n### vg_index Arguments ###\n\n# Name of index output files.  ex <name>.xg, <name>.gcsa etc. \nindex-name: 'genome'\n\n# Options to pass to vg prune.\n# (limit to general parameters, currently -k, -e, s.  \n# Rest decided by toil-vg via other options like prune-mode)\nprune-opts: []\n\n# Options to pass to vg gcsa indexing\ngcsa-opts: []\n\n########################\n### vg_map Arguments ###\n\n# Toggle whether reads are split into chunks\nsingle-reads-chunk: False\n\n# Number of reads per chunk to use when splitting up fastq.\n# (only applies if single-reads-chunk is False)\n# Each chunk will correspond to a vg map job\nreads-per-chunk: 50000000\n\n# Core arguments for vg mapping (do not include file names or -t/--threads)\n# Note -i/--interleaved will be ignored. use the --interleaved option \n# on the toil-vg command line instead\nmap-opts: []\n\n# Core arguments for vg multipath mapping (do not include file names or -t/--threads)\nmpmap-opts: ['--single-path-mode']\n\n#########################\n### vg_call Arguments ###\n# Overlap option that is passed into make_chunks and call_chunk\noverlap: 5000\n\n# Chunk size\ncall-chunk-size: 2000000\n\n# Context expansion used for graph chunking\nchunk_context: 50\n\n# Options to pass to vg filter when running vg call. (do not include file names or -t/--threads)\nfilter-opts: ['-r', '0.9', '-fu', '-s', '1000', '-m', '1', '-q', '15', '-D', '999']\n\n# Options to pass to vg augment. (do not include any file names or -t/--threads or -a/--augmentation-mode)\naugment-opts: ['-q', '10']\n\n# Options to pass to vg call. (do not include file/contig/sample names or -t/--threads)\ncall-opts: []\n\n# Options to pass to vg genotype. (do not include file/contig/sample names or -t/--threads)\ngenotype-opts: []\n\n# Use vg genotype instead of vg call\ngenotype: False\n\n#########################\n### vcfeval Arguments ###\n# Options to pass to rgt vcfeval. (do not include filenaems or threads or BED)\nvcfeval-opts: ['--ref-overlap', '--vcf-score-field', 'QUAL']\n\n#########################\n### sim and mapeval Arguments ###\n# Options to pass to vg sim (should not include -x, -n, -s or -a)\nsim-opts: ['--read-length', '150', '--frag-len', '570', '--frag-std-dev', '165', '--sub-rate', '0.01', '--indel-rate', '0.002']\n\n# Options to pass to bwa\nbwa-opts: []\n\n\n")

def generate_config(whole_genome=False):
    if whole_genome is True:
        return whole_genome_config
    return default_config


def make_opts_list(x_opts):
    opts_list = filter(lambda a: len(a), x_opts.split(' '))
    for t in ['-t', '--threads']:
        if t in opts_list:
            pos = opts_list.index(t)
            del opts_list[pos:pos + 2]

    return opts_list


def apply_config_file_args(args):
    """
    Merge args from the config file and the parser, giving priority to the parser.
    """
    for x_opts in ['map_opts', 'call_opts', 'filter_opts', 'genotype_opts', 'vcfeval_opts', 'sim_opts',
     'bwa_opts', 'gcsa_opts', 'mpmap_opts', 'augment_opts', 'prune_opts']:
        if x_opts in args.__dict__.keys() and type(args.__dict__[x_opts]) is str:
            args.__dict__[x_opts] = make_opts_list(args.__dict__[x_opts])

    if 'more_mpmap_opts' in args.__dict__.keys() and args.__dict__['more_mpmap_opts']:
        for i, m_opts in enumerate(args.__dict__['more_mpmap_opts']):
            if isinstance(m_opts, basestring):
                args.__dict__['more_mpmap_opts'][i] = make_opts_list(m_opts)

    wg_config = args.__dict__.has_key('whole_genome_config') and args.whole_genome_config
    if not args.__dict__.has_key('config') or args.config is None:
        config = generate_config(whole_genome=wg_config)
    else:
        if wg_config:
            raise RuntimeError('--config and --whole_genome_config cannot be used together')
        require(os.path.exists(args.config), ('Config, {}, not found. Please run "toil-vg generate-config > {}" to create.').format(args.config, args.config))
        with open(args.config) as (conf):
            config = conf.read()
    parsed_config = {x.replace('-', '_'):y for x, y in yaml.load(config).iteritems()}
    if 'prune_opts_2' in parsed_config:
        raise RuntimeError('prune-opts-2 from config no longer supported')
    options = argparse.Namespace(**parsed_config)
    for args_key in args.__dict__:
        if args.__dict__[args_key] or args_key not in options.__dict__.keys():
            options.__dict__[args_key] = args.__dict__[args_key]

    return options


def config_subparser(parser):
    """
    Create a subparser for config.  Should pass in results of subparsers.add_parser()
    """
    parser.add_argument('--whole_genome', action='store_true', help='Make config tuned to process a whole genome on 32-core instances')
    parser.add_argument('--config', type=argparse.FileType('w'), default=sys.stdout, help='config file to write to')


def config_main(options):
    """ config just prints out a file """
    options.config.write(generate_config(options.whole_genome))